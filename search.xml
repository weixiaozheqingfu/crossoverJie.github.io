<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[sbc(七)分布式限流]]></title>
    <url>%2F2018%2F04%2F28%2Fsbc%2Fsbc7-Distributed-Limit%2F</url>
    <content type="text"><![CDATA[前言本文接着上文应用限流进行讨论。 之前谈到的限流方案只能针对于单个 JVM 有效，也就是单机应用。而对于现在普遍的分布式应用也得有一个分布式限流的方案。 基于此尝试写了这个组件： https://github.com/crossoverJie/distributed-redis-tool DEMO以下采用的是 https://github.com/crossoverJie/springboot-cloud 来做演示。 在 Order 应用提供的接口中采取了限流。首先是配置了限流工具的 Bean: 12345678910111213141516171819202122@Configurationpublic class RedisLimitConfig &#123; @Value("$&#123;redis.limit&#125;") private int limit; @Autowired private JedisConnectionFactory jedisConnectionFactory; @Bean public RedisLimit build() &#123; RedisClusterConnection clusterConnection = jedisConnectionFactory.getClusterConnection(); JedisCluster jedisCluster = (JedisCluster) clusterConnection.getNativeConnection(); RedisLimit redisLimit = new RedisLimit.Builder&lt;&gt;(jedisCluster) .limit(limit) .build(); return redisLimit; &#125;&#125; 接着在 Controller 使用组件： 123456789101112131415161718192021222324252627@Autowiredprivate RedisLimit redisLimit ;@Override@CheckReqNopublic BaseResponse&lt;OrderNoResVO&gt; getOrderNo(@RequestBody OrderNoReqVO orderNoReq) &#123; BaseResponse&lt;OrderNoResVO&gt; res = new BaseResponse(); //限流 boolean limit = redisLimit.limit(); if (!limit)&#123; res.setCode(StatusEnum.REQUEST_LIMIT.getCode()); res.setMessage(StatusEnum.REQUEST_LIMIT.getMessage()); return res ; &#125; res.setReqNo(orderNoReq.getReqNo()); if (null == orderNoReq.getAppId())&#123; throw new SBCException(StatusEnum.FAIL); &#125; OrderNoResVO orderNoRes = new OrderNoResVO() ; orderNoRes.setOrderId(DateUtil.getLongTime()); res.setCode(StatusEnum.SUCCESS.getCode()); res.setMessage(StatusEnum.SUCCESS.getMessage()); res.setDataBody(orderNoRes); return res ;&#125; 为了方便使用，也提供了注解: 1234567@Override@ControllerLimitpublic BaseResponse&lt;OrderNoResVO&gt; getOrderNoLimit(@RequestBody OrderNoReqVO orderNoReq) &#123; BaseResponse&lt;OrderNoResVO&gt; res = new BaseResponse(); // 业务逻辑 return res ;&#125; 该注解拦截了 http 请求，会再请求达到阈值时直接返回。 普通方法也可使用: 12@CommonLimitpublic void doSomething()&#123;&#125; 会在调用达到阈值时抛出异常。 为了模拟并发，在 User 应用中开启了 10 个线程调用 Order(限流次数为5) 接口(也可使用专业的并发测试工具 JMeter 等)。 1234567891011121314151617181920212223242526272829303132333435363738394041@Overridepublic BaseResponse&lt;UserResVO&gt; getUserByFeign(@RequestBody UserReqVO userReq) &#123; //调用远程服务 OrderNoReqVO vo = new OrderNoReqVO(); vo.setAppId(1L); vo.setReqNo(userReq.getReqNo()); for (int i = 0; i &lt; 10; i++) &#123; executorService.execute(new Worker(vo, orderServiceClient)); &#125; UserRes userRes = new UserRes(); userRes.setUserId(123); userRes.setUserName("张三"); userRes.setReqNo(userReq.getReqNo()); userRes.setCode(StatusEnum.SUCCESS.getCode()); userRes.setMessage("成功"); return userRes;&#125;private static class Worker implements Runnable &#123; private OrderNoReqVO vo; private OrderServiceClient orderServiceClient; public Worker(OrderNoReqVO vo, OrderServiceClient orderServiceClient) &#123; this.vo = vo; this.orderServiceClient = orderServiceClient; &#125; @Override public void run() &#123; BaseResponse&lt;OrderNoResVO&gt; orderNo = orderServiceClient.getOrderNoCommonLimit(vo); logger.info("远程返回:" + JSON.toJSONString(orderNo)); &#125;&#125; 为了验证分布式效果启动了两个 Order 应用。 效果如下： 实现原理实现原理其实很简单。既然要达到分布式全局限流的效果，那自然需要一个第三方组件来记录请求的次数。 其中 Redis 就非常适合这样的场景。 每次请求时将当前时间(精确到秒)作为 Key 写入到 Redis 中，超时时间设置为 2 秒，Redis 将该 Key 的值进行自增。 当达到阈值时返回错误。 写入 Redis 的操作用 Lua 脚本来完成，利用 Redis 的单线程机制可以保证每个 Redis 请求的原子性。 Lua 脚本如下: 123456789101112131415161718--lua 下标从 1 开始-- 限流 keylocal key = KEYS[1]-- 限流大小local limit = tonumber(ARGV[1])-- 获取当前流量大小local curentLimit = tonumber(redis.call('get', key) or "0")if curentLimit + 1 &gt; limit then -- 达到限流大小 返回 return 0;else -- 没有达到阈值 value + 1 redis.call("INCRBY", key, 1) redis.call("EXPIRE", key, 2) return curentLimit + 1end Java 中的调用逻辑: 123456789101112131415161718public boolean limit() &#123; String key = String.valueOf(System.currentTimeMillis() / 1000); Object result = null; if (jedis instanceof Jedis) &#123; result = ((Jedis) this.jedis).eval(script, Collections.singletonList(key), Collections.singletonList(String.valueOf(limit))); &#125; else if (jedis instanceof JedisCluster) &#123; result = ((JedisCluster) this.jedis).eval(script, Collections.singletonList(key), Collections.singletonList(String.valueOf(limit))); &#125; else &#123; //throw new RuntimeException("instance is error") ; return false; &#125; if (FAIL_CODE != (Long) result) &#123; return true; &#125; else &#123; return false; &#125;&#125; 所以只需要在需要限流的地方调用该方法对返回值进行判断即可达到限流的目的。 当然这只是利用 Redis 做了一个粗暴的计数器，如果想实现类似于上文中的令牌桶算法可以基于 Lua 自行实现。 Builder 构建器在设计这个组件时想尽量的提供给使用者清晰、可读性、不易出错的 API。 比如第一步，如何构建一个限流对象。 最常用的方式自然就是构造函数，如果有多个域则可以采用重叠构造器的方式: 123public A()&#123;&#125;public A(int a)&#123;&#125;public A(int a,int b)&#123;&#125; 缺点也是显而易见的：如果参数过多会导致难以阅读，甚至如果参数类型一致的情况下客户端颠倒了顺序，但不会引起警告从而出现难以预测的结果。 第二种方案可以采用 JavaBean 模式，利用 setter 方法进行构建: 123A a = new A();a.setA(a);a.setB(b); 这种方式清晰易读，但却容易让对象处于不一致的状态，使对象处于线程不安全的状态。 所以这里采用了第三种创建对象的方式，构建器： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576public class RedisLimit &#123; private JedisCommands jedis; private int limit = 200; private static final int FAIL_CODE = 0; /** * lua script */ private String script; private RedisLimit(Builder builder) &#123; this.limit = builder.limit ; this.jedis = builder.jedis ; buildScript(); &#125; /** * limit traffic * @return if true */ public boolean limit() &#123; String key = String.valueOf(System.currentTimeMillis() / 1000); Object result = null; if (jedis instanceof Jedis) &#123; result = ((Jedis) this.jedis).eval(script, Collections.singletonList(key), Collections.singletonList(String.valueOf(limit))); &#125; else if (jedis instanceof JedisCluster) &#123; result = ((JedisCluster) this.jedis).eval(script, Collections.singletonList(key), Collections.singletonList(String.valueOf(limit))); &#125; else &#123; //throw new RuntimeException("instance is error") ; return false; &#125; if (FAIL_CODE != (Long) result) &#123; return true; &#125; else &#123; return false; &#125; &#125; /** * read lua script */ private void buildScript() &#123; script = ScriptUtil.getScript("limit.lua"); &#125; /** * the builder * @param &lt;T&gt; */ public static class Builder&lt;T extends JedisCommands&gt;&#123; private T jedis = null ; private int limit = 200; public Builder(T jedis)&#123; this.jedis = jedis ; &#125; public Builder limit(int limit)&#123; this.limit = limit ; return this; &#125; public RedisLimit build()&#123; return new RedisLimit(this) ; &#125; &#125;&#125; 这样客户端在使用时: 123RedisLimit redisLimit = new RedisLimit.Builder&lt;&gt;(jedisCluster) .limit(limit) .build(); 更加的简单直接，并且避免了将创建过程分成了多个子步骤。 这在有多个构造参数，但又不是必选字段时很有作用。 因此顺便将分布式锁的构建器方式也一并更新了： https://github.com/crossoverJie/distributed-redis-tool#features 更多内容可以参考 Effective Java API从上文可以看出，使用过程就是调用 limit 方法。 12345//限流 boolean limit = redisLimit.limit(); if (!limit)&#123; //具体限流逻辑 &#125; 为了减少侵入性，也为了简化客户端提供了两种注解方式。 @ControllerLimit该注解可以作用于 @RequestMapping 修饰的接口中，并会在限流后提供限流响应。 实现如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@Componentpublic class WebIntercept extends WebMvcConfigurerAdapter &#123; private static Logger logger = LoggerFactory.getLogger(WebIntercept.class); @Autowired private RedisLimit redisLimit; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(new CustomInterceptor()) .addPathPatterns("/**"); &#125; private class CustomInterceptor extends HandlerInterceptorAdapter &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; if (redisLimit == null) &#123; throw new NullPointerException("redisLimit is null"); &#125; if (handler instanceof HandlerMethod) &#123; HandlerMethod method = (HandlerMethod) handler; ControllerLimit annotation = method.getMethodAnnotation(ControllerLimit.class); if (annotation == null) &#123; //skip return true; &#125; boolean limit = redisLimit.limit(); if (!limit) &#123; logger.warn("request has bean limit"); response.sendError(500, "request limit"); return false; &#125; &#125; return true; &#125; &#125;&#125; 其实就是实现了 SpringMVC 中的拦截器，并在拦截过程中判断是否有使用注解，从而调用限流逻辑。 前提是应用需要扫描到该类，让 Spring 进行管理。 1@ComponentScan(value = "com.crossoverjie.distributed.intercept") @CommonLimit当然也可以在普通方法中使用。实现原理则是 Spring AOP (SpringMVC 的拦截器本质也是 AOP)。 12345678910111213141516171819202122232425262728@Aspect@Component@EnableAspectJAutoProxy(proxyTargetClass = true)public class CommonAspect &#123; private static Logger logger = LoggerFactory.getLogger(CommonAspect.class); @Autowired private RedisLimit redisLimit ; @Pointcut("@annotation(com.crossoverjie.distributed.annotation.CommonLimit)") private void check()&#123;&#125; @Before("check()") public void before(JoinPoint joinPoint) throws Exception &#123; if (redisLimit == null) &#123; throw new NullPointerException("redisLimit is null"); &#125; boolean limit = redisLimit.limit(); if (!limit) &#123; logger.warn("request has bean limit"); throw new RuntimeException("request has bean limit") ; &#125; &#125;&#125; 很简单，也是在拦截过程中调用限流。 当然使用时也得扫描到该包: 1@ComponentScan(value = "com.crossoverjie.distributed.intercept") 总结限流在一个高并发大流量的系统中是保护应用的一个利器，成熟的方案也很多，希望对刚了解这一块的朋友提供一些思路。 以上所有的源码： https://github.com/crossoverJie/distributed-redis-tool https://github.com/crossoverJie/springboot-cloud 感兴趣的朋友可以点个 Star 或是提交 PR。 号外最近在总结一些 Java 相关的知识点，感兴趣的朋友可以一起维护。 地址: https://github.com/crossoverJie/Java-Interview]]></content>
      <categories>
        <category>sbc</category>
        <category>Distributed Tools</category>
      </categories>
      <tags>
        <tag>Distributed Lock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【译】对于初学者什么是最好的编程语言？]]></title>
    <url>%2F2018%2F04%2F12%2Ftranslation%2Ftranslation-What%20Is%20The%20Best%20Programming%20Language%20to%20Start%2F</url>
    <content type="text"><![CDATA[原文链接Python？Java？Ruby？JavaScript？有非常多的选择。选择一种编程语言开始你的编码之旅不应该是一件艰巨的任务。 事实上：你将要学习的语言并不是特别重要，更重要的是学习编程的理念。对于任何编程语言来说知识的可传递性都是至关重要的。 我学习的第一门语言是 Java，学习了循环，while 循环，条件，函数，面向对象编程和许多编程理念。 然而，选择一门能在编程领域轻松找到工作的语言是更好的选择。对于初学者来说，我这里有一份列表推荐给你： PythonPython 在美国大学里是最受欢迎的入门型语言。 就像 JavaScript 一样，Python 也非常灵活，现在被用于构建生物信息学的 web 应用。我强烈推荐你学习 Python，它是很棒的入门选择。 JavaJava 是企业环境中使用最多的语言，根据 TIOBE 统计 Java 长年占据编程语言榜首。同时 Java 是强类型地静态语言，可以更容易地去描述一些编程理念。 Java 作为最常使用的语言，你可以很轻松地在这段编程之旅中找到 Java 的相关课程和指南来获得帮助。你还可以使用 Java 构建服务端应用、Android APP 等应用程序。 RubyRuby 是我最喜欢的编程语言，它编写简单，容易理解并且使用顺手。 就像 JavaScript 一样，它学起来简单但是不易掌握。Ruby 在很多公司中被广泛应用，比如 Airbnb, EBANX, Shopify, Twitter, GitHub 等等。它还有一个超赞的 7*24 小时的在线社区随时提供帮助。Ruby 以 Ruby on Rails 框架著称，它可以帮你很轻松的构建整个 web 应用。 JavaScriptJavaScript 是我用过的最灵活的语言之一。 你能用它构建控制台程序，桌面软件，手机 APP，前端开发，后端开发等等。它是一个很不错的编程语言，简单易学但难以掌握。 我建议你学习并掌握 JavaScript ，但不是作为第一门语言。 对于初学者来说 JavaScript 很难调试并且不容易学习编程理念比如异步，原型，面向对象等等。 不要纠结语言你需要通过选择一门语言来学习编程理念，当你学完之后你将花费较小的学习曲线来学习任何其他的语言。 如果你想要学习如何学习一门新语言的话，可以阅读我的文章 “How to Learn a New Programming Language or Framework”，将会非常有用。]]></content>
      <categories>
        <category>翻译</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[动手实现一个 LRU cache]]></title>
    <url>%2F2018%2F04%2F07%2Falgorithm%2FLRU-cache%2F</url>
    <content type="text"><![CDATA[前言LRU 是 Least Recently Used 的简写，字面意思则是最近最少使用。 通常用于缓存的淘汰策略实现，由于缓存的内存非常宝贵，所以需要根据某种规则来剔除数据保证内存不被撑满。 如常用的 Redis 就有以下几种策略： 策略 描述 volatile-lru 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰 volatile-ttl 从已设置过期时间的数据集中挑选将要过期的数据淘汰 volatile-random 从已设置过期时间的数据集中任意选择数据淘汰 allkeys-lru 从所有数据集中挑选最近最少使用的数据淘汰 allkeys-random 从所有数据集中任意选择数据进行淘汰 no-envicition 禁止驱逐数据 摘抄自:https://github.com/CyC2018/Interview-Notebook/blob/master/notes/Redis.md#%E5%8D%81%E4%B8%89%E6%95%B0%E6%8D%AE%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5 实现一之前也有接触过一道面试题，大概需求是： 实现一个 LRU 缓存，当缓存数据达到 N 之后需要淘汰掉最近最少使用的数据。 N 小时之内没有被访问的数据也需要淘汰掉。 以下是我的实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323public class LRUAbstractMap extends java.util.AbstractMap &#123; private final static Logger LOGGER = LoggerFactory.getLogger(LRUAbstractMap.class); /** * 检查是否超期线程 */ private ExecutorService checkTimePool ; /** * map 最大size */ private final static int MAX_SIZE = 1024 ; private final static ArrayBlockingQueue&lt;Node&gt; QUEUE = new ArrayBlockingQueue&lt;&gt;(MAX_SIZE) ; /** * 默认大小 */ private final static int DEFAULT_ARRAY_SIZE =1024 ; /** * 数组长度 */ private int arraySize ; /** * 数组 */ private Object[] arrays ; /** * 判断是否停止 flag */ private volatile boolean flag = true ; /** * 超时时间 */ private final static Long EXPIRE_TIME = 60 * 60 * 1000L ; /** * 整个 Map 的大小 */ private volatile AtomicInteger size ; public LRUAbstractMap() &#123; arraySize = DEFAULT_ARRAY_SIZE; arrays = new Object[arraySize] ; //开启一个线程检查最先放入队列的值是否超期 executeCheckTime(); &#125; /** * 开启一个线程检查最先放入队列的值是否超期 设置为守护线程 */ private void executeCheckTime() &#123; ThreadFactory namedThreadFactory = new ThreadFactoryBuilder() .setNameFormat("check-thread-%d") .setDaemon(true) .build(); checkTimePool = new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new ArrayBlockingQueue&lt;&gt;(1),namedThreadFactory,new ThreadPoolExecutor.AbortPolicy()); checkTimePool.execute(new CheckTimeThread()) ; &#125; @Override public Set&lt;Entry&gt; entrySet() &#123; return super.keySet(); &#125; @Override public Object put(Object key, Object value) &#123; int hash = hash(key); int index = hash % arraySize ; Node currentNode = (Node) arrays[index] ; if (currentNode == null)&#123; arrays[index] = new Node(null,null, key, value); //写入队列 QUEUE.offer((Node) arrays[index]) ; sizeUp(); &#125;else &#123; Node cNode = currentNode ; Node nNode = cNode ; //存在就覆盖 if (nNode.key == key)&#123; cNode.val = value ; &#125; while (nNode.next != null)&#123; //key 存在 就覆盖 简单判断 if (nNode.key == key)&#123; nNode.val = value ; break ; &#125;else &#123; //不存在就新增链表 sizeUp(); Node node = new Node(nNode,null,key,value) ; //写入队列 QUEUE.offer(currentNode) ; cNode.next = node ; &#125; nNode = nNode.next ; &#125; &#125; return null ; &#125; @Override public Object get(Object key) &#123; int hash = hash(key) ; int index = hash % arraySize ; Node currentNode = (Node) arrays[index] ; if (currentNode == null)&#123; return null ; &#125; if (currentNode.next == null)&#123; //更新时间 currentNode.setUpdateTime(System.currentTimeMillis()); //没有冲突 return currentNode ; &#125; Node nNode = currentNode ; while (nNode.next != null)&#123; if (nNode.key == key)&#123; //更新时间 currentNode.setUpdateTime(System.currentTimeMillis()); return nNode ; &#125; nNode = nNode.next ; &#125; return super.get(key); &#125; @Override public Object remove(Object key) &#123; int hash = hash(key) ; int index = hash % arraySize ; Node currentNode = (Node) arrays[index] ; if (currentNode == null)&#123; return null ; &#125; if (currentNode.key == key)&#123; sizeDown(); arrays[index] = null ; //移除队列 QUEUE.poll(); return currentNode ; &#125; Node nNode = currentNode ; while (nNode.next != null)&#123; if (nNode.key == key)&#123; sizeDown(); //在链表中找到了 把上一个节点的 next 指向当前节点的下一个节点 nNode.pre.next = nNode.next ; nNode = null ; //移除队列 QUEUE.poll(); return nNode; &#125; nNode = nNode.next ; &#125; return super.remove(key); &#125; /** * 增加size */ private void sizeUp()&#123; //在put值时候认为里边已经有数据了 flag = true ; if (size == null)&#123; size = new AtomicInteger() ; &#125; int size = this.size.incrementAndGet(); if (size &gt;= MAX_SIZE) &#123; //找到队列头的数据 Node node = QUEUE.poll() ; if (node == null)&#123; throw new RuntimeException("data error") ; &#125; //移除该 key Object key = node.key ; remove(key) ; lruCallback() ; &#125; &#125; /** * 数量减小 */ private void sizeDown()&#123; if (QUEUE.size() == 0)&#123; flag = false ; &#125; this.size.decrementAndGet() ; &#125; @Override public int size() &#123; return size.get() ; &#125; /** * 链表 */ private class Node&#123; private Node next ; private Node pre ; private Object key ; private Object val ; private Long updateTime ; public Node(Node pre,Node next, Object key, Object val) &#123; this.pre = pre ; this.next = next; this.key = key; this.val = val; this.updateTime = System.currentTimeMillis() ; &#125; public void setUpdateTime(Long updateTime) &#123; this.updateTime = updateTime; &#125; public Long getUpdateTime() &#123; return updateTime; &#125; @Override public String toString() &#123; return "Node&#123;" + "key=" + key + ", val=" + val + '&#125;'; &#125; &#125; /** * copy HashMap 的 hash 实现 * @param key * @return */ public int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125; private void lruCallback()&#123; LOGGER.debug("lruCallback"); &#125; private class CheckTimeThread implements Runnable&#123; @Override public void run() &#123; while (flag)&#123; try &#123; Node node = QUEUE.poll(); if (node == null)&#123; continue ; &#125; Long updateTime = node.getUpdateTime() ; if ((updateTime - System.currentTimeMillis()) &gt;= EXPIRE_TIME)&#123; remove(node.key) ; &#125; &#125; catch (Exception e) &#123; LOGGER.error("InterruptedException"); &#125; &#125; &#125; &#125;&#125; 感兴趣的朋友可以直接从: https://github.com/crossoverJie/Java-Interview/blob/master/src/main/java/com/crossoverjie/actual/LRUAbstractMap.java 下载代码本地运行。 代码看着比较多，其实实现的思路还是比较简单： 采用了与 HashMap 一样的保存数据方式，只是自己手动实现了一个简易版。 内部采用了一个队列来保存每次写入的数据。 写入的时候判断缓存是否大于了阈值 N，如果满足则根据队列的 FIFO 特性将队列头的数据删除。因为队列头的数据肯定是最先放进去的。 再开启了一个守护线程用于判断最先放进去的数据是否超期（因为就算超期也是最先放进去的数据最有可能满足超期条件。） 设置为守护线程可以更好的表明其目的（最坏的情况下，如果是一个用户线程最终有可能导致程序不能正常退出，因为该线程一直在运行，守护线程则不会有这个情况。） 以上代码大体功能满足了，但是有一个致命问题。 就是最近最少使用没有满足，删除的数据都是最先放入的数据。 不过其中的 put get 流程算是一个简易的 HashMap 实现，可以对 HashMap 加深一些理解。 实现二因此如何来实现一个完整的 LRU 缓存呢，这次不考虑过期时间的问题。 其实从上一个实现也能想到一些思路： 要记录最近最少使用，那至少需要一个有序的集合来保证写入的顺序。 在使用了数据之后能够更新它的顺序。 基于以上两点很容易想到一个常用的数据结构：链表。 每次写入数据时将数据放入链表头结点。 使用数据时候将数据移动到头结点。 缓存数量超过阈值时移除链表尾部数据。 因此有了以下实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211public class LRUMap&lt;K, V&gt; &#123; private final Map&lt;K, V&gt; cacheMap = new HashMap&lt;&gt;(); /** * 最大缓存大小 */ private int cacheSize; /** * 节点大小 */ private int nodeCount; /** * 头结点 */ private Node&lt;K, V&gt; header; /** * 尾结点 */ private Node&lt;K, V&gt; tailer; public LRUMap(int cacheSize) &#123; this.cacheSize = cacheSize; //头结点的下一个结点为空 header = new Node&lt;&gt;(); header.next = null; //尾结点的上一个结点为空 tailer = new Node&lt;&gt;(); tailer.tail = null; //双向链表 头结点的上结点指向尾结点 header.tail = tailer; //尾结点的下结点指向头结点 tailer.next = header; &#125; public void put(K key, V value) &#123; cacheMap.put(key, value); //双向链表中添加结点 addNode(key, value); &#125; public V get(K key)&#123; Node&lt;K, V&gt; node = getNode(key); //移动到头结点 moveToHead(node) ; return cacheMap.get(key); &#125; private void moveToHead(Node&lt;K,V&gt; node)&#123; //如果是最后的一个节点 if (node.tail == null)&#123; node.next.tail = null ; tailer = node.next ; nodeCount -- ; &#125; //如果是本来就是头节点 不作处理 if (node.next == null)&#123; return ; &#125; //如果处于中间节点 if (node.tail != null &amp;&amp; node.next != null)&#123; //它的上一节点指向它的下一节点 也就删除当前节点 node.tail.next = node.next ; nodeCount -- ; &#125; //最后在头部增加当前节点 //注意这里需要重新 new 一个对象，不然原本的node 还有着下面的引用，会造成内存溢出。 node = new Node&lt;&gt;(node.getKey(),node.getValue()) ; addHead(node) ; &#125; /** * 链表查询 效率较低 * @param key * @return */ private Node&lt;K,V&gt; getNode(K key)&#123; Node&lt;K,V&gt; node = tailer ; while (node != null)&#123; if (node.getKey().equals(key))&#123; return node ; &#125; node = node.next ; &#125; return null ; &#125; /** * 写入头结点 * @param key * @param value */ private void addNode(K key, V value) &#123; Node&lt;K, V&gt; node = new Node&lt;&gt;(key, value); //容量满了删除最后一个 if (cacheSize == nodeCount) &#123; //删除尾结点 delTail(); &#125; //写入头结点 addHead(node); &#125; /** * 添加头结点 * * @param node */ private void addHead(Node&lt;K, V&gt; node) &#123; //写入头结点 header.next = node; node.tail = header; header = node; nodeCount++; //如果写入的数据大于2个 就将初始化的头尾结点删除 if (nodeCount == 2) &#123; tailer.next.next.tail = null; tailer = tailer.next.next; &#125; &#125; private void delTail() &#123; //把尾结点从缓存中删除 cacheMap.remove(tailer.getKey()); //删除尾结点 tailer.next.tail = null; tailer = tailer.next; nodeCount--; &#125; private class Node&lt;K, V&gt; &#123; private K key; private V value; Node&lt;K, V&gt; tail; Node&lt;K, V&gt; next; public Node(K key, V value) &#123; this.key = key; this.value = value; &#125; public Node() &#123; &#125; public K getKey() &#123; return key; &#125; public void setKey(K key) &#123; this.key = key; &#125; public V getValue() &#123; return value; &#125; public void setValue(V value) &#123; this.value = value; &#125; &#125; @Override public String toString() &#123; StringBuilder sb = new StringBuilder() ; Node&lt;K,V&gt; node = tailer ; while (node != null)&#123; sb.append(node.getKey()).append(":") .append(node.getValue()) .append("--&gt;") ; node = node.next ; &#125; return sb.toString(); &#125;&#125; 源码：https://github.com/crossoverJie/Java-Interview/blob/master/src/main/java/com/crossoverjie/actual/LRUMap.java 实际效果，写入时： 1234567891011121314151617181920 @Test public void put() throws Exception &#123; LRUMap&lt;String,Integer&gt; lruMap = new LRUMap(3) ; lruMap.put("1",1) ; lruMap.put("2",2) ; lruMap.put("3",3) ; System.out.println(lruMap.toString()); lruMap.put("4",4) ; System.out.println(lruMap.toString()); lruMap.put("5",5) ; System.out.println(lruMap.toString()); &#125;//输出：1:1--&gt;2:2--&gt;3:3--&gt;2:2--&gt;3:3--&gt;4:4--&gt;3:3--&gt;4:4--&gt;5:5--&gt; 使用时： 12345678910111213141516171819202122 @Test public void get() throws Exception &#123; LRUMap&lt;String,Integer&gt; lruMap = new LRUMap(3) ; lruMap.put("1",1) ; lruMap.put("2",2) ; lruMap.put("3",3) ; System.out.println(lruMap.toString()); System.out.println("=============="); Integer integer = lruMap.get("1"); System.out.println(integer); System.out.println("=============="); System.out.println(lruMap.toString()); &#125; //输出1:1--&gt;2:2--&gt;3:3--&gt;==============1==============2:2--&gt;3:3--&gt;1:1--&gt; 实现思路和上文提到的一致，说下重点： 数据是直接利用 HashMap 来存放的。 内部使用了一个双向链表来存放数据，所以有一个头结点 header，以及尾结点 tailer。 每次写入头结点，删除尾结点时都是依赖于 header tailer，如果看着比较懵建议自己实现一个链表熟悉下，或结合下文的对象关系图一起理解。 使用数据移动到链表头时，第一步是需要在双向链表中找到该节点。这里就体现出链表的问题了。查找效率很低，最差需要 O(N)。之后依赖于当前节点进行移动。 在写入头结点时有判断链表大小等于 2 时需要删除初始化的头尾结点。这是因为初始化时候生成了两个双向节点，没有数据只是为了形成一个数据结构。当真实数据进来之后需要删除以方便后续的操作（这点可以继续优化）。 以上的所有操作都是线程不安全的，需要使用者自行控制。 下面是对象关系图： 初始化时 写入数据时12LRUMap&lt;String,Integer&gt; lruMap = new LRUMap(3) ;lruMap.put("1",1) ; 1lruMap.put("2",2) ; 1lruMap.put("3",3) ; 1lruMap.put("4",4) ; 获取数据时数据和上文一样： 1Integer integer = lruMap.get("2"); 通过以上几张图应该是很好理解数据是如何存放的了。 实现三其实如果对 Java 的集合比较熟悉的话，会发现上文的结构和 LinkedHashMap 非常类似。 对此不太熟悉的朋友可以先了解下 LinkedHashMap 底层分析 。 所以我们完全可以借助于它来实现： 123456789101112131415161718192021222324252627282930313233343536373839public class LRULinkedMap&lt;K,V&gt; &#123; /** * 最大缓存大小 */ private int cacheSize; private LinkedHashMap&lt;K,V&gt; cacheMap ; public LRULinkedMap(int cacheSize) &#123; this.cacheSize = cacheSize; cacheMap = new LinkedHashMap(16,0.75F,true)&#123; @Override protected boolean removeEldestEntry(Map.Entry eldest) &#123; if (cacheSize + 1 == cacheMap.size())&#123; return true ; &#125;else &#123; return false ; &#125; &#125; &#125;; &#125; public void put(K key,V value)&#123; cacheMap.put(key,value) ; &#125; public V get(K key)&#123; return cacheMap.get(key) ; &#125; public Collection&lt;Map.Entry&lt;K, V&gt;&gt; getAll() &#123; return new ArrayList&lt;Map.Entry&lt;K, V&gt;&gt;(cacheMap.entrySet()); &#125;&#125; 源码：https://github.com/crossoverJie/Java-Interview/blob/master/src/main/java/com/crossoverjie/actual/LRULinkedMap.java 这次就比较简洁了，也就几行代码（具体的逻辑 LinkedHashMap 已经帮我们实现好了） 实际效果: 123456789101112131415161718192021 @Test public void put() throws Exception &#123; LRULinkedMap&lt;String,Integer&gt; map = new LRULinkedMap(3) ; map.put("1",1); map.put("2",2); map.put("3",3); for (Map.Entry&lt;String, Integer&gt; e : map.getAll())&#123; System.out.print(e.getKey() + " : " + e.getValue() + "\t"); &#125; System.out.println(""); map.put("4",4); for (Map.Entry&lt;String, Integer&gt; e : map.getAll())&#123; System.out.print(e.getKey() + " : " + e.getValue() + "\t"); &#125; &#125; //输出1 : 1 2 : 2 3 : 3 2 : 2 3 : 3 4 : 4 使用时： 123456789101112131415161718192021222324 @Test public void get() throws Exception &#123; LRULinkedMap&lt;String,Integer&gt; map = new LRULinkedMap(4) ; map.put("1",1); map.put("2",2); map.put("3",3); map.put("4",4); for (Map.Entry&lt;String, Integer&gt; e : map.getAll())&#123; System.out.print(e.getKey() + " : " + e.getValue() + "\t"); &#125; System.out.println(""); map.get("1") ; for (Map.Entry&lt;String, Integer&gt; e : map.getAll())&#123; System.out.print(e.getKey() + " : " + e.getValue() + "\t"); &#125; &#125;&#125;//输出1 : 1 2 : 2 3 : 3 4 : 4 2 : 2 3 : 3 4 : 4 1 : 1 LinkedHashMap 内部也有维护一个双向队列，在初始化时也会给定一个缓存大小的阈值。初始化时自定义是否需要删除最近不常使用的数据，如果是则会按照实现二中的方式管理数据。 其实主要代码就是重写了 LinkedHashMap 的 removeEldestEntry 方法: 123protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) &#123; return false;&#125; 它默认是返回 false，也就是不会管有没有超过阈值。 所以我们自定义大于了阈值时返回 true，这样 LinkedHashMap 就会帮我们删除最近最少使用的数据。 总结以上就是对 LRU 缓存的实现，了解了这些至少在平时使用时可以知其所以然。 当然业界使用较多的还有 guava 的实现，并且它还支持多种过期策略。 号外最近在总结一些 Java 相关的知识点，感兴趣的朋友可以一起维护。 地址: https://github.com/crossoverJie/Java-Interview]]></content>
      <categories>
        <category>算法</category>
        <category>LRU cache</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[基于 Redis 的分布式锁]]></title>
    <url>%2F2018%2F03%2F29%2Fdistributed-lock%2Fdistributed-lock-redis%2F</url>
    <content type="text"><![CDATA[前言分布式锁在分布式应用中应用广泛，想要搞懂一个新事物首先得了解它的由来，这样才能更加的理解甚至可以举一反三。 首先谈到分布式锁自然也就联想到分布式应用。 在我们将应用拆分为分布式应用之前的单机系统中，对一些并发场景读取公共资源时如扣库存，卖车票之类的需求可以简单的使用同步或者是加锁就可以实现。 但是应用分布式了之后系统由以前的单进程多线程的程序变为了多进程多线程，这时使用以上的解决方案明显就不够了。 因此业界常用的解决方案通常是借助于一个第三方组件并利用它自身的排他性来达到多进程的互斥。如： 基于 DB 的唯一索引。 基于 ZK 的临时有序节点。 基于 Redis 的 NX EX 参数。 这里主要基于 Redis 进行讨论。 实现既然是选用了 Redis，那么它就得具有排他性才行。同时它最好也有锁的一些基本特性： 高性能(加、解锁时高性能) 可以使用阻塞锁与非阻塞锁。 不能出现死锁。 可用性(不能出现节点 down 掉后加锁失败)。 这里利用 Redis set key 时的一个 NX 参数可以保证在这个 key 不存在的情况下写入成功。并且再加上 EX 参数可以让该 key 在超时之后自动删除。 所以利用以上两个特性可以保证在同一时刻只会有一个进程获得锁，并且不会出现死锁(最坏的情况就是超时自动删除 key)。 加锁实现代码如下： 12345678910111213private static final String SET_IF_NOT_EXIST = "NX";private static final String SET_WITH_EXPIRE_TIME = "PX";public boolean tryLock(String key, String request) &#123; String result = this.jedis.set(LOCK_PREFIX + key, request, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, 10 * TIME); if (LOCK_MSG.equals(result))&#123; return true ; &#125;else &#123; return false ; &#125;&#125; 注意这里使用的 jedis 的 1String set(String key, String value, String nxxx, String expx, long time); api。 该命令可以保证 NX EX 的原子性。 一定不要把两个命令(NX EX)分开执行，如果在 NX 之后程序出现问题就有可能产生死锁。 阻塞锁同时也可以实现一个阻塞锁： 123456789101112131415161718192021222324252627282930//一直阻塞public void lock(String key, String request) throws InterruptedException &#123; for (;;)&#123; String result = this.jedis.set(LOCK_PREFIX + key, request, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, 10 * TIME); if (LOCK_MSG.equals(result))&#123; break ; &#125; //防止一直消耗 CPU Thread.sleep(DEFAULT_SLEEP_TIME) ; &#125;&#125; //自定义阻塞时间 public boolean lock(String key, String request,int blockTime) throws InterruptedException &#123; while (blockTime &gt;= 0)&#123; String result = this.jedis.set(LOCK_PREFIX + key, request, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, 10 * TIME); if (LOCK_MSG.equals(result))&#123; return true ; &#125; blockTime -= DEFAULT_SLEEP_TIME ; Thread.sleep(DEFAULT_SLEEP_TIME) ; &#125; return false ;&#125; 解锁解锁也很简单，其实就是把这个 key 删掉就万事大吉了，比如使用 del key 命令。 但现实往往没有那么 easy。 如果进程 A 获取了锁设置了超时时间，但是由于执行周期较长导致到了超时时间之后锁就自动释放了。这时进程 B 获取了该锁执行很快就释放锁。这样就会出现进程 B 将进程 A 的锁释放了。 所以最好的方式是在每次解锁时都需要判断锁是否是自己的。 这时就需要结合加锁机制一起实现了。 加锁时需要传递一个参数，将该参数作为这个 key 的 value，这样每次解锁时判断 value 是否相等即可。 所以解锁代码就不能是简单的 del了。 1234567891011121314151617181920public boolean unlock(String key,String request)&#123; //lua script String script = "if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end"; Object result = null ; if (jedis instanceof Jedis)&#123; result = ((Jedis)this.jedis).eval(script, Collections.singletonList(LOCK_PREFIX + key), Collections.singletonList(request)); &#125;else if (jedis instanceof JedisCluster)&#123; result = ((JedisCluster)this.jedis).eval(script, Collections.singletonList(LOCK_PREFIX + key), Collections.singletonList(request)); &#125;else &#123; //throw new RuntimeException("instance is error") ; return false ; &#125; if (UNLOCK_MSG.equals(result))&#123; return true ; &#125;else &#123; return false ; &#125;&#125; 这里使用了一个 lua 脚本来判断 value 是否相等，相等才执行 del 命令。 使用 lua 也可以保证这里两个操作的原子性。 因此上文提到的四个基本特性也能满足了： 使用 Redis 可以保证性能。 阻塞锁与非阻塞锁见上文。 利用超时机制解决了死锁。 Redis 支持集群部署提高了可用性。 使用我自己有撸了一个完整的实现，并且已经用于了生产，有兴趣的朋友可以开箱使用: maven 依赖： 12345&lt;dependency&gt; &lt;groupId&gt;top.crossoverjie.opensource&lt;/groupId&gt; &lt;artifactId&gt;distributed-redis-lock&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt; 配置 bean : 1234567891011121314@Configurationpublic class RedisLockConfig &#123; @Bean public RedisLock build()&#123; RedisLock redisLock = new RedisLock() ; HostAndPort hostAndPort = new HostAndPort("127.0.0.1",7000) ; JedisCluster jedisCluster = new JedisCluster(hostAndPort) ; // Jedis 或 JedisCluster 都可以 redisLock.setJedisCluster(jedisCluster) ; return redisLock ; &#125;&#125; 使用： 123456789101112131415161718192021@Autowiredprivate RedisLock redisLock ;public void use() &#123; String key = "key"; String request = UUID.randomUUID().toString(); try &#123; boolean locktest = redisLock.tryLock(key, request); if (!locktest) &#123; System.out.println("locked error"); return; &#125; //do something &#125; finally &#123; redisLock.unlock(key,request) ; &#125;&#125; 使用很简单。这里主要是想利用 Spring 来帮我们管理 RedisLock 这个单例的 bean，所以在释放锁的时候需要手动(因为整个上下文只有一个 RedisLock 实例)的传入 key 以及 request(api 看起来不是特别优雅)。 也可以在每次使用锁的时候 new 一个 RedisLock 传入 key 以及 request，这样倒是在解锁时很方便。但是需要自行管理 RedisLock 的实例。各有优劣吧。 项目源码在： https://github.com/crossoverJie/distributed-lock-redis 欢迎讨论。 单测在做这个项目的时候让我不得不想提一下单测。 因为这个应用是强依赖于第三方组件的(Redis)，但是在单测中我们需要排除掉这种依赖。比如其他伙伴 fork 了该项目想在本地跑一遍单测，结果运行不起来： 有可能是 Redis 的 ip、端口和单测里的不一致。 Redis 自身可能也有问题。 也有可能是该同学的环境中并没有 Redis。 所以最好是要把这些外部不稳定的因素排除掉，单测只测我们写好的代码。 于是就可以引入单测利器 Mock 了。 它的想法很简答，就是要把你所依赖的外部资源统统屏蔽掉。如：数据库、外部接口、外部文件等等。 使用方式也挺简单，可以参考该项目的单测： 12345678910111213141516@Testpublic void tryLock() throws Exception &#123; String key = "test"; String request = UUID.randomUUID().toString(); Mockito.when(jedisCluster.set(Mockito.anyString(), Mockito.anyString(), Mockito.anyString(), Mockito.anyString(), Mockito.anyLong())).thenReturn("OK"); boolean locktest = redisLock.tryLock(key, request); System.out.println("locktest=" + locktest); Assert.assertTrue(locktest); //check Mockito.verify(jedisCluster).set(Mockito.anyString(), Mockito.anyString(), Mockito.anyString(), Mockito.anyString(), Mockito.anyLong());&#125; 这里只是简单演示下，可以的话下次仔细分析分析。 它的原理其实也挺简单，debug 的话可以很直接的看出来： 这里我们所依赖的 JedisCluster 其实是一个 cglib 代理对象。所以也不难想到它是如何工作的。 比如这里我们需要用到 JedisCluster 的 set 函数并需要它的返回值。 Mock 就将该对象代理了，并在实际执行 set 方法后给你返回了一个你自定义的值。 这样我们就可以随心所欲的测试了，完全把外部依赖所屏蔽了。 总结至此一个基于 Redis 的分布式锁完成，但是依然有些问题。 如在 key 超时之后业务并没有执行完毕但却自动释放锁了，这样就会导致并发问题。 就算 Redis 是集群部署的，如果每个节点都只是 master 没有 slave，那么 master 宕机时该节点上的所有 key 在那一时刻都相当于是释放锁了，这样也会出现并发问题。就算是有 slave 节点，但如果在数据同步到 salve 之前 master 宕机也是会出现上面的问题。 感兴趣的朋友还可以参考 Redisson 的实现。 号外最近在总结一些 Java 相关的知识点，感兴趣的朋友可以一起维护。 地址: https://github.com/crossoverJie/Java-Interview]]></content>
      <categories>
        <category>Distributed Tools</category>
      </categories>
      <tags>
        <tag>Distributed Lock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Bean 生命周期]]></title>
    <url>%2F2018%2F03%2F21%2Fspring%2Fspring-bean-lifecycle%2F</url>
    <content type="text"><![CDATA[前言Spring Bean 的生命周期在整个 Spring 中占有很重要的位置，掌握这些可以加深对 Spring 的理解。 首先看下生命周期图： 再谈生命周期之前有一点需要先明确： Spring 只帮我们管理单例模式 Bean 的完整生命周期，对于 prototype 的 bean ，Spring 在创建好交给使用者之后则不会再管理后续的生命周期。 注解方式在 bean 初始化时会经历几个阶段，首先可以使用注解 @PostConstruct, @PreDestroy 来在 bean 的创建和销毁阶段进行调用: 1234567891011121314@Componentpublic class AnnotationBean &#123; private final static Logger LOGGER = LoggerFactory.getLogger(AnnotationBean.class); @PostConstruct public void start()&#123; LOGGER.info("AnnotationBean start"); &#125; @PreDestroy public void destroy()&#123; LOGGER.info("AnnotationBean destroy"); &#125;&#125; InitializingBean, DisposableBean 接口还可以实现 InitializingBean,DisposableBean 这两个接口，也是在初始化以及销毁阶段调用： 12345678910111213@Servicepublic class SpringLifeCycleService implements InitializingBean,DisposableBean&#123; private final static Logger LOGGER = LoggerFactory.getLogger(SpringLifeCycleService.class); @Override public void afterPropertiesSet() throws Exception &#123; LOGGER.info("SpringLifeCycleService start"); &#125; @Override public void destroy() throws Exception &#123; LOGGER.info("SpringLifeCycleService destroy"); &#125;&#125; 自定义初始化和销毁方法也可以自定义方法用于在初始化、销毁阶段调用: 123456789101112131415161718192021222324@Configurationpublic class LifeCycleConfig &#123; @Bean(initMethod = "start", destroyMethod = "destroy") public SpringLifeCycle create()&#123; SpringLifeCycle springLifeCycle = new SpringLifeCycle() ; return springLifeCycle ; &#125;&#125;public class SpringLifeCycle&#123; private final static Logger LOGGER = LoggerFactory.getLogger(SpringLifeCycle.class); public void start()&#123; LOGGER.info("SpringLifeCycle start"); &#125; public void destroy()&#123; LOGGER.info("SpringLifeCycle destroy"); &#125;&#125; 以上是在 SpringBoot 中可以这样配置，如果是原始的基于 XML 也是可以使用: 12&lt;bean class="com.crossoverjie.spring.SpringLifeCycle" init-method="start" destroy-method="destroy"&gt;&lt;/bean&gt; 来达到同样的效果。 实现 *Aware 接口*Aware 接口可以用于在初始化 bean 时获得 Spring 中的一些对象，如获取 Spring 上下文等。 123456789101112@Componentpublic class SpringLifeCycleAware implements ApplicationContextAware &#123; private final static Logger LOGGER = LoggerFactory.getLogger(SpringLifeCycleAware.class); private ApplicationContext applicationContext ; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; this.applicationContext = applicationContext ; LOGGER.info("SpringLifeCycleAware start"); &#125;&#125; 这样在 springLifeCycleAware 这个 bean 初始化会就会调用 setApplicationContext 方法，并可以获得 applicationContext 对象。 BeanPostProcessor 增强处理器实现 BeanPostProcessor 接口，Spring 中所有 bean 在做初始化时都会调用该接口中的两个方法，可以用于对一些特殊的 bean 进行处理： 12345678910111213141516171819202122232425262728293031323334@Componentpublic class SpringLifeCycleProcessor implements BeanPostProcessor &#123; private final static Logger LOGGER = LoggerFactory.getLogger(SpringLifeCycleProcessor.class); /** * 预初始化 初始化之前调用 * @param bean * @param beanName * @return * @throws BeansException */ @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; if ("annotationBean".equals(beanName))&#123; LOGGER.info("SpringLifeCycleProcessor start beanName=&#123;&#125;",beanName); &#125; return bean; &#125; /** * 后初始化 bean 初始化完成调用 * @param bean * @param beanName * @return * @throws BeansException */ @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; if ("annotationBean".equals(beanName))&#123; LOGGER.info("SpringLifeCycleProcessor end beanName=&#123;&#125;",beanName); &#125; return bean; &#125;&#125; 执行之后观察结果： 123456789101112131415018-03-21 00:40:24.856 [restartedMain] INFO c.c.s.p.SpringLifeCycleProcessor - SpringLifeCycleProcessor start beanName=annotationBean2018-03-21 00:40:24.860 [restartedMain] INFO c.c.spring.annotation.AnnotationBean - AnnotationBean start2018-03-21 00:40:24.861 [restartedMain] INFO c.c.s.p.SpringLifeCycleProcessor - SpringLifeCycleProcessor end beanName=annotationBean2018-03-21 00:40:24.864 [restartedMain] INFO c.c.s.aware.SpringLifeCycleAware - SpringLifeCycleAware start2018-03-21 00:40:24.867 [restartedMain] INFO c.c.s.service.SpringLifeCycleService - SpringLifeCycleService start2018-03-21 00:40:24.887 [restartedMain] INFO c.c.spring.SpringLifeCycle - SpringLifeCycle start2018-03-21 00:40:25.062 [restartedMain] INFO o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 357292018-03-21 00:40:25.122 [restartedMain] INFO o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup2018-03-21 00:40:25.140 [restartedMain] INFO com.crossoverjie.Application - Started Application in 2.309 seconds (JVM running for 3.681)2018-03-21 00:40:25.143 [restartedMain] INFO com.crossoverjie.Application - start ok!2018-03-21 00:40:25.153 [Thread-8] INFO o.s.c.a.AnnotationConfigApplicationContext - Closing org.springframework.context.annotation.AnnotationConfigApplicationContext@3913adad: startup date [Wed Mar 21 00:40:23 CST 2018]; root of context hierarchy2018-03-21 00:40:25.155 [Thread-8] INFO o.s.j.e.a.AnnotationMBeanExporter - Unregistering JMX-exposed beans on shutdown2018-03-21 00:40:25.156 [Thread-8] INFO c.c.spring.SpringLifeCycle - SpringLifeCycle destroy2018-03-21 00:40:25.156 [Thread-8] INFO c.c.s.service.SpringLifeCycleService - SpringLifeCycleService destroy2018-03-21 00:40:25.156 [Thread-8] INFO c.c.spring.annotation.AnnotationBean - AnnotationBean destroy 直到 Spring 上下文销毁时则会调用自定义的销毁方法以及实现了 DisposableBean 的 destroy() 方法。 号外最近在总结一些 Java 相关的知识点，感兴趣的朋友可以一起维护。 地址: https://github.com/crossoverJie/Java-Interview]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解线程通信]]></title>
    <url>%2F2018%2F03%2F16%2Fjava-senior%2Fthread-communication%2F</url>
    <content type="text"><![CDATA[前言开发中不免会遇到需要所有子线程执行完毕通知主线程处理某些逻辑的场景。 或者是线程 A 在执行到某个条件通知线程 B 执行某个操作。 可以通过以下几种方式实现： 等待通知机制 等待通知模式是 Java 中比较经典的线程通信方式。 两个线程通过对同一对象调用等待 wait() 和通知 notify() 方法来进行通讯。 如两个线程交替打印奇偶数： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091public class TwoThreadWaitNotify &#123; private int start = 1; private boolean flag = false; public static void main(String[] args) &#123; TwoThreadWaitNotify twoThread = new TwoThreadWaitNotify(); Thread t1 = new Thread(new OuNum(twoThread)); t1.setName("A"); Thread t2 = new Thread(new JiNum(twoThread)); t2.setName("B"); t1.start(); t2.start(); &#125; /** * 偶数线程 */ public static class OuNum implements Runnable &#123; private TwoThreadWaitNotify number; public OuNum(TwoThreadWaitNotify number) &#123; this.number = number; &#125; @Override public void run() &#123; while (number.start &lt;= 100) &#123; synchronized (TwoThreadWaitNotify.class) &#123; System.out.println("偶数线程抢到锁了"); if (number.flag) &#123; System.out.println(Thread.currentThread().getName() + "+-+偶数" + number.start); number.start++; number.flag = false; TwoThreadWaitNotify.class.notify(); &#125;else &#123; try &#123; TwoThreadWaitNotify.class.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; &#125; &#125; /** * 奇数线程 */ public static class JiNum implements Runnable &#123; private TwoThreadWaitNotify number; public JiNum(TwoThreadWaitNotify number) &#123; this.number = number; &#125; @Override public void run() &#123; while (number.start &lt;= 100) &#123; synchronized (TwoThreadWaitNotify.class) &#123; System.out.println("奇数线程抢到锁了"); if (!number.flag) &#123; System.out.println(Thread.currentThread().getName() + "+-+奇数" + number.start); number.start++; number.flag = true; TwoThreadWaitNotify.class.notify(); &#125;else &#123; try &#123; TwoThreadWaitNotify.class.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; &#125; &#125;&#125; 输出结果： 12345678t2+-+奇数93t1+-+偶数94t2+-+奇数95t1+-+偶数96t2+-+奇数97t1+-+偶数98t2+-+奇数99t1+-+偶数100 这里的线程 A 和线程 B 都对同一个对象 TwoThreadWaitNotify.class 获取锁，A 线程调用了同步对象的 wait() 方法释放了锁并进入 WAITING 状态。 B 线程调用了 notify() 方法，这样 A 线程收到通知之后就可以从 wait() 方法中返回。 这里利用了 TwoThreadWaitNotify.class 对象完成了通信。 有一些需要注意: wait() 、nofify() 、nofityAll() 调用的前提都是获得了对象的锁(也可称为对象监视器)。 调用 wait() 方法后线程会释放锁，进入 WAITING 状态，该线程也会被移动到等待队列中。 调用 notify() 方法会将等待队列中的线程移动到同步队列中，线程状态也会更新为 BLOCKED 从 wait() 方法返回的前提是调用 notify() 方法的线程释放锁，wait() 方法的线程获得锁。 等待通知有着一个经典范式： 线程 A 作为消费者： 获取对象的锁。 进入 while(判断条件)，并调用 wait() 方法。 当条件满足跳出循环执行具体处理逻辑。 线程 B 作为生产者: 获取对象锁。 更改与线程 A 共用的判断条件。 调用 notify() 方法。 伪代码如下: 1234567891011121314//Thread Asynchronized(Object)&#123; while(条件)&#123; Object.wait(); &#125; //do something&#125;//Thread Bsynchronized(Object)&#123; 条件=false;//改变条件 Object.notify();&#125; join() 方法1234567891011121314151617181920212223242526272829303132333435private static void join() throws InterruptedException &#123; Thread t1 = new Thread(new Runnable() &#123; @Override public void run() &#123; LOGGER.info("running"); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;) ; Thread t2 = new Thread(new Runnable() &#123; @Override public void run() &#123; LOGGER.info("running2"); try &#123; Thread.sleep(4000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;) ; t1.start(); t2.start(); //等待线程1终止 t1.join(); //等待线程2终止 t2.join(); LOGGER.info("main over");&#125; 输出结果: 1232018-03-16 20:21:30.967 [Thread-1] INFO c.c.actual.ThreadCommunication - running22018-03-16 20:21:30.967 [Thread-0] INFO c.c.actual.ThreadCommunication - running2018-03-16 20:21:34.972 [main] INFO c.c.actual.ThreadCommunication - main over 在 t1.join() 时会一直阻塞到 t1 执行完毕，所以最终主线程会等待 t1 和 t2 线程执行完毕。 其实从源码可以看出，join() 也是利用的等待通知机制： 核心逻辑: 123while (isAlive()) &#123; wait(0);&#125; 在 join 线程完成后会调用 notifyAll() 方法，是在 JVM 实现中调用，所以这里看不出来。 volatile 共享内存因为 Java 是采用共享内存的方式进行线程通信的，所以可以采用以下方式用主线程关闭 A 线程: 1234567891011121314151617181920212223242526272829public class Volatile implements Runnable&#123; private static volatile boolean flag = true ; @Override public void run() &#123; while (flag)&#123; System.out.println(Thread.currentThread().getName() + "正在运行。。。"); &#125; System.out.println(Thread.currentThread().getName() +"执行完毕"); &#125; public static void main(String[] args) throws InterruptedException &#123; Volatile aVolatile = new Volatile(); new Thread(aVolatile,"thread A").start(); System.out.println("main 线程正在运行") ; TimeUnit.MILLISECONDS.sleep(100) ; aVolatile.stopThread(); &#125; private void stopThread()&#123; flag = false ; &#125;&#125; 输出结果：12345thread A正在运行。。。thread A正在运行。。。thread A正在运行。。。thread A正在运行。。。thread A执行完毕 这里的 flag 存放于主内存中，所以主线程和线程 A 都可以看到。 flag 采用 volatile 修饰主要是为了内存可见性，更多内容可以查看这里。 CountDownLatch 并发工具CountDownLatch 可以实现 join 相同的功能，但是更加的灵活。 12345678910111213141516171819202122232425private static void countDownLatch() throws Exception&#123; int thread = 3 ; long start = System.currentTimeMillis(); final CountDownLatch countDown = new CountDownLatch(thread); for (int i= 0 ;i&lt;thread ; i++)&#123; new Thread(new Runnable() &#123; @Override public void run() &#123; LOGGER.info("thread run"); try &#123; Thread.sleep(2000); countDown.countDown(); LOGGER.info("thread end"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); &#125; countDown.await(); long stop = System.currentTimeMillis(); LOGGER.info("main over total time=&#123;&#125;",stop-start);&#125; 输出结果: 12345672018-03-16 20:19:44.126 [Thread-0] INFO c.c.actual.ThreadCommunication - thread run2018-03-16 20:19:44.126 [Thread-2] INFO c.c.actual.ThreadCommunication - thread run2018-03-16 20:19:44.126 [Thread-1] INFO c.c.actual.ThreadCommunication - thread run2018-03-16 20:19:46.136 [Thread-2] INFO c.c.actual.ThreadCommunication - thread end2018-03-16 20:19:46.136 [Thread-1] INFO c.c.actual.ThreadCommunication - thread end2018-03-16 20:19:46.136 [Thread-0] INFO c.c.actual.ThreadCommunication - thread end2018-03-16 20:19:46.136 [main] INFO c.c.actual.ThreadCommunication - main over total time=2012 CountDownLatch 也是基于 AQS(AbstractQueuedSynchronizer) 实现的，更多实现参考 ReentrantLock 实现原理 初始化一个 CountDownLatch 时告诉并发的线程，然后在每个线程处理完毕之后调用 countDown() 方法。 该方法会将 AQS 内置的一个 state 状态 -1 。 最终在主线程调用 await() 方法，它会阻塞直到 state == 0 的时候返回。 CyclicBarrier 并发工具123456789101112131415161718192021222324252627282930313233343536373839404142434445464748private static void cyclicBarrier() throws Exception &#123; CyclicBarrier cyclicBarrier = new CyclicBarrier(3) ; new Thread(new Runnable() &#123; @Override public void run() &#123; LOGGER.info("thread run"); try &#123; cyclicBarrier.await() ; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; LOGGER.info("thread end do something"); &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; LOGGER.info("thread run"); try &#123; cyclicBarrier.await() ; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; LOGGER.info("thread end do something"); &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; LOGGER.info("thread run"); try &#123; Thread.sleep(5000); cyclicBarrier.await() ; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; LOGGER.info("thread end do something"); &#125; &#125;).start(); LOGGER.info("main thread");&#125; CyclicBarrier 中文名叫做屏障或者是栅栏，也可以用于线程间通信。 它可以等待 N 个线程都达到某个状态后继续运行的效果。 首先初始化线程参与者。 调用 await() 将会在所有参与者线程都调用之前等待。 直到所有参与者都调用了 await() 后，所有线程从 await() 返回继续后续逻辑。 运行结果: 12345672018-03-18 22:40:00.731 [Thread-0] INFO c.c.actual.ThreadCommunication - thread run2018-03-18 22:40:00.731 [Thread-1] INFO c.c.actual.ThreadCommunication - thread run2018-03-18 22:40:00.731 [Thread-2] INFO c.c.actual.ThreadCommunication - thread run2018-03-18 22:40:00.731 [main] INFO c.c.actual.ThreadCommunication - main thread2018-03-18 22:40:05.741 [Thread-0] INFO c.c.actual.ThreadCommunication - thread end do something2018-03-18 22:40:05.741 [Thread-1] INFO c.c.actual.ThreadCommunication - thread end do something2018-03-18 22:40:05.741 [Thread-2] INFO c.c.actual.ThreadCommunication - thread end do something 可以看出由于其中一个线程休眠了五秒，所有其余所有的线程都得等待这个线程调用 await() 。 该工具可以实现 CountDownLatch 同样的功能，但是要更加灵活。甚至可以调用 reset() 方法重置 CyclicBarrier (需要自行捕获 BrokenBarrierException 处理) 然后重新执行。 线程响应中断12345678910111213141516171819202122232425public class StopThread implements Runnable &#123; @Override public void run() &#123; while ( !Thread.currentThread().isInterrupted()) &#123; // 线程执行具体逻辑 System.out.println(Thread.currentThread().getName() + "运行中。。"); &#125; System.out.println(Thread.currentThread().getName() + "退出。。"); &#125; public static void main(String[] args) throws InterruptedException &#123; Thread thread = new Thread(new StopThread(), "thread A"); thread.start(); System.out.println("main 线程正在运行") ; TimeUnit.MILLISECONDS.sleep(10) ; thread.interrupt(); &#125;&#125; 输出结果: 123thread A运行中。。thread A运行中。。thread A退出。。 可以采用中断线程的方式来通信，调用了 thread.interrupt() 方法其实就是将 thread 中的一个标志属性置为了 true。 并不是说调用了该方法就可以中断线程，如果不对这个标志进行响应其实是没有什么作用(这里对这个标志进行了判断)。 但是如果抛出了 InterruptedException 异常，该标志就会被 JVM 重置为 false。 线程池 awaitTermination() 方法如果是用线程池来管理线程，可以使用以下方式来让主线程等待线程池中所有任务执行完毕: 1234567891011121314151617181920212223242526272829303132private static void executorService() throws Exception&#123; BlockingQueue&lt;Runnable&gt; queue = new LinkedBlockingQueue&lt;&gt;(10) ; ThreadPoolExecutor poolExecutor = new ThreadPoolExecutor(5,5,1, TimeUnit.MILLISECONDS,queue) ; poolExecutor.execute(new Runnable() &#123; @Override public void run() &#123; LOGGER.info("running"); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); poolExecutor.execute(new Runnable() &#123; @Override public void run() &#123; LOGGER.info("running2"); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); poolExecutor.shutdown(); while (!poolExecutor.awaitTermination(1,TimeUnit.SECONDS))&#123; LOGGER.info("线程还在执行。。。"); &#125; LOGGER.info("main over");&#125; 输出结果: 123452018-03-16 20:18:01.273 [pool-1-thread-2] INFO c.c.actual.ThreadCommunication - running22018-03-16 20:18:01.273 [pool-1-thread-1] INFO c.c.actual.ThreadCommunication - running2018-03-16 20:18:02.273 [main] INFO c.c.actual.ThreadCommunication - 线程还在执行。。。2018-03-16 20:18:03.278 [main] INFO c.c.actual.ThreadCommunication - 线程还在执行。。。2018-03-16 20:18:04.278 [main] INFO c.c.actual.ThreadCommunication - main over 使用这个 awaitTermination() 方法的前提需要关闭线程池，如调用了 shutdown() 方法。 调用了 shutdown() 之后线程池会停止接受新任务，并且会平滑的关闭线程池中现有的任务。 管道通信12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public static void piped() throws IOException &#123; //面向于字符 PipedInputStream 面向于字节 PipedWriter writer = new PipedWriter(); PipedReader reader = new PipedReader(); //输入输出流建立连接 writer.connect(reader); Thread t1 = new Thread(new Runnable() &#123; @Override public void run() &#123; LOGGER.info("running"); try &#123; for (int i = 0; i &lt; 10; i++) &#123; writer.write(i+""); Thread.sleep(10); &#125; &#125; catch (Exception e) &#123; &#125; finally &#123; try &#123; writer.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;); Thread t2 = new Thread(new Runnable() &#123; @Override public void run() &#123; LOGGER.info("running2"); int msg = 0; try &#123; while ((msg = reader.read()) != -1) &#123; LOGGER.info("msg=&#123;&#125;", (char) msg); &#125; &#125; catch (Exception e) &#123; &#125; &#125; &#125;); t1.start(); t2.start();&#125; 输出结果: 1234567891011122018-03-16 19:56:43.014 [Thread-0] INFO c.c.actual.ThreadCommunication - running2018-03-16 19:56:43.014 [Thread-1] INFO c.c.actual.ThreadCommunication - running22018-03-16 19:56:43.130 [Thread-1] INFO c.c.actual.ThreadCommunication - msg=02018-03-16 19:56:43.132 [Thread-1] INFO c.c.actual.ThreadCommunication - msg=12018-03-16 19:56:43.132 [Thread-1] INFO c.c.actual.ThreadCommunication - msg=22018-03-16 19:56:43.133 [Thread-1] INFO c.c.actual.ThreadCommunication - msg=32018-03-16 19:56:43.133 [Thread-1] INFO c.c.actual.ThreadCommunication - msg=42018-03-16 19:56:43.133 [Thread-1] INFO c.c.actual.ThreadCommunication - msg=52018-03-16 19:56:43.133 [Thread-1] INFO c.c.actual.ThreadCommunication - msg=62018-03-16 19:56:43.134 [Thread-1] INFO c.c.actual.ThreadCommunication - msg=72018-03-16 19:56:43.134 [Thread-1] INFO c.c.actual.ThreadCommunication - msg=82018-03-16 19:56:43.134 [Thread-1] INFO c.c.actual.ThreadCommunication - msg=9 Java 虽说是基于内存通信的，但也可以使用管道通信。 需要注意的是，输入流和输出流需要首先建立连接。这样线程 B 就可以收到线程 A 发出的消息了。 实际开发中可以灵活根据需求选择最适合的线程通信方式。 号外最近在总结一些 Java 相关的知识点，感兴趣的朋友可以一起维护。 地址: https://github.com/crossoverJie/Java-Interview]]></content>
      <categories>
        <category>Java 进阶</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[你应该知道的 volatile 关键字]]></title>
    <url>%2F2018%2F03%2F09%2Fvolatile%2F</url>
    <content type="text"><![CDATA[前言不管是在面试还是实际开发中 volatile 都是一个应该掌握的技能。 首先来看看为什么会出现这个关键字。 内存可见性由于 Java 内存模型(JMM)规定，所有的变量都存放在主内存中，而每个线程都有着自己的工作内存(高速缓存)。 线程在工作时，需要将主内存中的数据拷贝到工作内存中。这样对数据的任何操作都是基于工作内存(效率提高)，并且不能直接操作主内存以及其他线程工作内存中的数据，之后再将更新之后的数据刷新到主内存中。 这里所提到的主内存可以简单认为是堆内存，而工作内存则可以认为是栈内存。 如下图所示： 所以在并发运行时可能会出现线程 B 所读取到的数据是线程 A 更新之前的数据。 显然这肯定是会出问题的，因此 volatile 的作用出现了： 当一个变量被 volatile 修饰时，任何线程对它的写操作都会立即刷新到主内存中，并且会强制让缓存了该变量的线程中的数据清空，必须从主内存重新读取最新数据。 volatile 修饰之后并不是让线程直接从主内存中获取数据，依然需要将变量拷贝到工作内存中。 内存可见性的应用当我们需要在两个线程间依据主内存通信时，通信的那个变量就必须的用 volatile 来修饰： 1234567891011121314151617181920212223242526272829public class Volatile implements Runnable&#123; private static volatile boolean flag = true ; @Override public void run() &#123; while (flag)&#123; System.out.println(Thread.currentThread().getName() + "正在运行。。。"); &#125; System.out.println(Thread.currentThread().getName() +"执行完毕"); &#125; public static void main(String[] args) throws InterruptedException &#123; Volatile aVolatile = new Volatile(); new Thread(aVolatile,"thread A").start(); System.out.println("main 线程正在运行") ; TimeUnit.MILLISECONDS.sleep(100) ; aVolatile.stopThread(); &#125; private void stopThread()&#123; flag = false ; &#125;&#125; 主线程在修改了标志位使得线程 A 立即停止，如果没有用 volatile 修饰，就有可能出现延迟。 但这里有个误区，这样的使用方式容易给人的感觉是： 对 volatile 修饰的变量进行并发操作是线程安全的。 这里要重点强调，volatile 并不能保证线程安全性！ 如下程序: 1234567891011121314151617181920212223242526272829303132public class VolatileInc implements Runnable&#123; private static volatile int count = 0 ; //使用 volatile 修饰基本数据内存不能保证原子性 //private static AtomicInteger count = new AtomicInteger() ; @Override public void run() &#123; for (int i=0;i&lt;10000 ;i++)&#123; count ++ ; //count.incrementAndGet() ; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; VolatileInc volatileInc = new VolatileInc() ; Thread t1 = new Thread(volatileInc,"t1") ; Thread t2 = new Thread(volatileInc,"t2") ; t1.start(); //t1.join(); t2.start(); //t2.join(); for (int i=0;i&lt;10000 ;i++)&#123; count ++ ; //count.incrementAndGet(); &#125; System.out.println("最终Count="+count); &#125;&#125; 当我们三个线程(t1,t2,main)同时对一个 int 进行累加时会发现最终的值都会小于 30000。 这是因为虽然 volatile 保证了内存可见性，每个线程拿到的值都是最新值，但 count ++ 这个操作并不是原子的，这里面涉及到获取值、自增、赋值的操作并不能同时完成。 所以想到达到线程安全可以使这三个线程串行执行(其实就是单线程，没有发挥多线程的优势)。 也可以使用 synchronize 或者是锁的方式来保证原子性。 还可以用 Atomic 包中 AtomicInteger 来替换 int，它利用了 CAS 算法来保证了原子性。 指令重排内存可见性只是 volatile 的其中一个语义，它还可以防止 JVM 进行指令重排优化。 举一个伪代码: 123int a=10 ;//1int b=20 ;//2int c= a+b ;//3 一段特别简单的代码，理想情况下它的执行顺序是：1&gt;2&gt;3。但有可能经过 JVM 优化之后的执行顺序变为了 2&gt;1&gt;3。 可以发现不管 JVM 怎么优化，前提都是保证单线程中最终结果不变的情况下进行的。 可能这里还看不出有什么问题，那看下一段伪代码: 12345678910111213141516171819private static Map&lt;String,String&gt; value ;private static volatile boolean flag = fasle ;//以下方法发生在线程 A 中 初始化 Mappublic void initMap()&#123; //耗时操作 value = getMapValue() ;//1 flag = true ;//2&#125;//发生在线程 B中 等到 Map 初始化成功进行其他操作public void doSomeThing()&#123; while(!flag)&#123; sleep() ; &#125; //dosomething doSomeThing(value);&#125; 这里就能看出问题了，当 flag 没有被 volatile 修饰时，JVM 对 1 和 2 进行重排，导致 value 都还没有被初始化就有可能被线程 B 使用了。 所以加上 volatile 之后可以防止这样的重排优化，保证业务的正确性。 指令重排的的应用一个经典的使用场景就是双重懒加载的单例模式了: 12345678910111213141516171819public class Singleton &#123; private static volatile Singleton singleton; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; //防止指令重排 singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125;&#125; 这里的 volatile 关键字主要是为了防止指令重排。 如果不用 ，singleton = new Singleton();，这段代码其实是分为三步： 分配内存空间。(1) 初始化对象。(2) 将 singleton 对象指向分配的内存地址。(3) 加上 volatile 是为了让以上的三步操作顺序执行，反之有可能第二步在第三步之前被执行就有可能某个线程拿到的单例对象是还没有初始化的，以致于报错。 总结volatile 在 Java 并发中用的很多，比如像 Atomic 包中的 value、以及 AbstractQueuedLongSynchronizer 中的 state 都是被定义为 volatile 来用于保证内存可见性。 将这块理解透彻对我们编写并发程序时可以提供很大帮助。 号外最近在总结一些 Java 相关的知识点，感兴趣的朋友可以一起维护。 地址: https://github.com/crossoverJie/Java-Interview]]></content>
      <categories>
        <category>Java 进阶</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>volatile</tag>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LinkedHashMap 底层分析]]></title>
    <url>%2F2018%2F02%2F06%2FLinkedHashMap%2F</url>
    <content type="text"><![CDATA[众所周知 HashMap 是一个无序的 Map，因为每次根据 key 的 hashcode 映射到 Entry 数组上，所以遍历出来的顺序并不是写入的顺序。 因此 JDK 推出一个基于 HashMap 但具有顺序的 LinkedHashMap 来解决有排序需求的场景。 它的底层是继承于 HashMap 实现的，由一个双向链表所构成。 LinkedHashMap 的排序方式有两种： 根据写入顺序排序。 根据访问顺序排序。 其中根据访问顺序排序时，每次 get 都会将访问的值移动到链表末尾，这样重复操作就能的到一个按照访问顺序排序的链表。 数据结构1234567891011@Testpublic void test()&#123; Map&lt;String, Integer&gt; map = new LinkedHashMap&lt;String, Integer&gt;(); map.put("1",1) ; map.put("2",2) ; map.put("3",3) ; map.put("4",4) ; map.put("5",5) ; System.out.println(map.toString());&#125; 调试可以看到 map 的组成： 打开源码可以看到： 123456789101112131415161718192021/** * The head of the doubly linked list. */private transient Entry&lt;K,V&gt; header;/** * The iteration ordering method for this linked hash map: &lt;tt&gt;true&lt;/tt&gt; * for access-order, &lt;tt&gt;false&lt;/tt&gt; for insertion-order. * * @serial */private final boolean accessOrder;private static class Entry&lt;K,V&gt; extends HashMap.Entry&lt;K,V&gt; &#123; // These fields comprise the doubly linked list used for iteration. Entry&lt;K,V&gt; before, after; Entry(int hash, K key, V value, HashMap.Entry&lt;K,V&gt; next) &#123; super(hash, key, value, next); &#125;&#125; 其中 Entry 继承于 HashMap 的 Entry，并新增了上下节点的指针，也就形成了双向链表。 还有一个 header 的成员变量，是这个双向链表的头结点。 上边的 demo 总结成一张图如下： 第一个类似于 HashMap 的结构，利用 Entry 中的 next 指针进行关联。 下边则是 LinkedHashMap 如何达到有序的关键。 就是利用了头节点和其余的各个节点之间通过 Entry 中的 after 和 before 指针进行关联。 其中还有一个 accessOrder 成员变量，默认是 false，默认按照插入顺序排序，为 true 时按照访问顺序排序，也可以调用: 123456public LinkedHashMap(int initialCapacity, float loadFactor, boolean accessOrder) &#123; super(initialCapacity, loadFactor); this.accessOrder = accessOrder;&#125; 这个构造方法可以显示的传入 accessOrder。 构造方法LinkedHashMap 的构造方法: 1234public LinkedHashMap() &#123; super(); accessOrder = false;&#125; 其实就是调用的 HashMap 的构造方法: HashMap 实现： 123456789101112131415public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); this.loadFactor = loadFactor; threshold = initialCapacity; //HashMap 只是定义了改方法，具体实现交给了 LinkedHashMap init();&#125; 可以看到里面有一个空的 init()，具体是由 LinkedHashMap 来实现的： 12345@Overridevoid init() &#123; header = new Entry&lt;&gt;(-1, null, null, null); header.before = header.after = header;&#125; 其实也就是对 header 进行了初始化。 put 方法看 LinkedHashMap 的 put() 方法之前先看看 HashMap 的 put 方法： 123456789101112131415161718192021222324252627282930313233343536373839404142public V put(K key, V value) &#123; if (table == EMPTY_TABLE) &#123; inflateTable(threshold); &#125; if (key == null) return putForNullKey(value); int hash = hash(key); int i = indexFor(hash, table.length); for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; //空实现，交给 LinkedHashMap 自己实现 e.recordAccess(this); return oldValue; &#125; &#125; modCount++; // LinkedHashMap 对其重写 addEntry(hash, key, value, i); return null;&#125;// LinkedHashMap 对其重写void addEntry(int hash, K key, V value, int bucketIndex) &#123; if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); &#125; createEntry(hash, key, value, bucketIndex);&#125;// LinkedHashMap 对其重写void createEntry(int hash, K key, V value, int bucketIndex) &#123; Entry&lt;K,V&gt; e = table[bucketIndex]; table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); size++;&#125; 主体的实现都是借助于 HashMap 来完成的，只是对其中的 recordAccess(), addEntry(), createEntry() 进行了重写。 LinkedHashMap 的实现： 1234567891011121314151617181920212223242526272829303132333435363738 //就是判断是否是根据访问顺序排序，如果是则需要将当前这个 Entry 移动到链表的末尾 void recordAccess(HashMap&lt;K,V&gt; m) &#123; LinkedHashMap&lt;K,V&gt; lm = (LinkedHashMap&lt;K,V&gt;)m; if (lm.accessOrder) &#123; lm.modCount++; remove(); addBefore(lm.header); &#125; &#125; //调用了 HashMap 的实现，并判断是否需要删除最少使用的 Entry(默认不删除) void addEntry(int hash, K key, V value, int bucketIndex) &#123; super.addEntry(hash, key, value, bucketIndex); // Remove eldest entry if instructed Entry&lt;K,V&gt; eldest = header.after; if (removeEldestEntry(eldest)) &#123; removeEntryForKey(eldest.key); &#125;&#125;void createEntry(int hash, K key, V value, int bucketIndex) &#123; HashMap.Entry&lt;K,V&gt; old = table[bucketIndex]; Entry&lt;K,V&gt; e = new Entry&lt;&gt;(hash, key, value, old); //就多了这一步，将新增的 Entry 加入到 header 双向链表中 table[bucketIndex] = e; e.addBefore(header); size++;&#125; //写入到双向链表中 private void addBefore(Entry&lt;K,V&gt; existingEntry) &#123; after = existingEntry; before = existingEntry.before; before.after = this; after.before = this; &#125; get 方法LinkedHashMap 的 get() 方法也重写了： 123456789101112131415161718192021public V get(Object key) &#123; Entry&lt;K,V&gt; e = (Entry&lt;K,V&gt;)getEntry(key); if (e == null) return null; //多了一个判断是否是按照访问顺序排序，是则将当前的 Entry 移动到链表头部。 e.recordAccess(this); return e.value;&#125;void recordAccess(HashMap&lt;K,V&gt; m) &#123; LinkedHashMap&lt;K,V&gt; lm = (LinkedHashMap&lt;K,V&gt;)m; if (lm.accessOrder) &#123; lm.modCount++; //删除 remove(); //添加到头部 addBefore(lm.header); &#125;&#125; clear() 清空就要比较简单了： 12345//只需要把指针都指向自己即可，原本那些 Entry 没有引用之后就会被 JVM 自动回收。public void clear() &#123; super.clear(); header.before = header.after = header;&#125; 总结总的来说 LinkedHashMap 其实就是对 HashMap 进行了拓展，使用了双向链表来保证了顺序性。 因为是继承与 HashMap 的，所以一些 HashMap 存在的问题 LinkedHashMap 也会存在，比如不支持并发等。 号外最近在总结一些 Java 相关的知识点，感兴趣的朋友可以一起维护。 地址: https://github.com/crossoverJie/Java-Interview]]></content>
      <categories>
        <category>Java 进阶</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>LinkedHashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ReentrantLock 实现原理]]></title>
    <url>%2F2018%2F01%2F25%2FReentrantLock%2F</url>
    <content type="text"><![CDATA[使用 synchronize 来做同步处理时，锁的获取和释放都是隐式的，实现的原理是通过编译后加上不同的机器指令来实现。 而 ReentrantLock 就是一个普通的类，它是基于 AQS(AbstractQueuedSynchronizer)来实现的。 是一个重入锁：一个线程获得了锁之后仍然可以反复的加锁，不会出现自己阻塞自己的情况。 AQS 是 Java 并发包里实现锁、同步的一个重要的基础框架。 锁类型ReentrantLock 分为公平锁和非公平锁，可以通过构造方法来指定具体类型： 123456789//默认非公平锁public ReentrantLock() &#123; sync = new NonfairSync();&#125;//公平锁public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; 默认一般使用非公平锁，它的效率和吞吐量都比公平锁高的多(后面会分析具体原因)。 获取锁通常的使用方式如下: 1234567891011private ReentrantLock lock = new ReentrantLock();public void run() &#123; lock.lock(); try &#123; //do bussiness &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125;&#125; 公平锁获取锁首先看下获取锁的过程： 123public void lock() &#123; sync.lock();&#125; 可以看到是使用 sync的方法，而这个方法是一个抽象方法，具体是由其子类(FairSync)来实现的，以下是公平锁的实现: 12345678910 final void lock() &#123; acquire(1); &#125; //AbstractQueuedSynchronizer 中的 acquire() public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 第一步是尝试获取锁(tryAcquire(arg)),这个也是由其子类实现： 1234567891011121314151617181920 protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false; &#125;&#125; 首先会判断 AQS 中的 state 是否等于 0，0 表示目前没有其他线程获得锁，当前线程就可以尝试获取锁。 注意:尝试之前会利用 hasQueuedPredecessors() 方法来判断 AQS 的队列中中是否有其他线程，如果有则不会尝试获取锁(这是公平锁特有的情况)。 如果队列中没有线程就利用 CAS 来将 AQS 中的 state 修改为1，也就是获取锁，获取成功则将当前线程置为获得锁的独占线程(setExclusiveOwnerThread(current))。 如果 state 大于 0 时，说明锁已经被获取了，则需要判断获取锁的线程是否为当前线程(ReentrantLock 支持重入)，是则需要将 state + 1，并将值更新。 写入队列如果 tryAcquire(arg) 获取锁失败，则需要用 addWaiter(Node.EXCLUSIVE) 将当前线程写入队列中。 写入之前需要将当前线程包装为一个 Node 对象(addWaiter(Node.EXCLUSIVE))。 AQS 中的队列是由 Node 节点组成的双向链表实现的。 包装代码: 1234567891011121314private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node;&#125; 首先判断队列是否为空，不为空时则将封装好的 Node 利用 CAS 写入队尾，如果出现并发写入失败就需要调用 enq(node); 来写入了。 123456789101112131415private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; 这个处理逻辑就相当于自旋加上 CAS 保证一定能写入队列。 挂起等待线程写入队列之后需要将当前线程挂起(利用acquireQueued(addWaiter(Node.EXCLUSIVE), arg))： 123456789101112131415161718192021final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 首先会根据 node.predecessor() 获取到上一个节点是否为头节点，如果是则尝试获取一次锁，获取成功就万事大吉了。 如果不是头节点，或者获取锁失败，则会根据上一个节点的 waitStatus 状态来处理(shouldParkAfterFailedAcquire(p, node))。 waitStatus 用于记录当前节点的状态，如节点取消、节点等待等。 shouldParkAfterFailedAcquire(p, node) 返回当前线程是否需要挂起，如果需要则调用 parkAndCheckInterrupt()： 1234private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; 他是利用 LockSupport 的 part 方法来挂起当前线程的，直到被唤醒。 非公平锁获取锁公平锁与非公平锁的差异主要在获取锁： 公平锁就相当于买票，后来的人需要排到队尾依次买票，不能插队。 而非公平锁则没有这些规则，是抢占模式，每来一个人不会去管队列如何，直接尝试获取锁。 非公平锁:1234567final void lock() &#123; //直接尝试获取锁 if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1);&#125; 公平锁:123final void lock() &#123; acquire(1);&#125; 还要一个重要的区别是在尝试获取锁时tryAcquire(arg)，非公平锁是不需要判断队列中是否还有其他线程，也是直接尝试获取锁： 12345678910111213141516171819final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; //没有 !hasQueuedPredecessors() 判断 if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false;&#125; 释放锁公平锁和非公平锁的释放流程都是一样的： 12345678910111213141516171819202122232425262728public void unlock() &#123; sync.release(1);&#125;public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) //唤醒被挂起的线程 unparkSuccessor(h); return true; &#125; return false;&#125;//尝试释放锁protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; 首先会判断当前线程是否为获得锁的线程，由于是重入锁所以需要将 state 减到 0 才认为完全释放锁。 释放之后需要调用 unparkSuccessor(h) 来唤醒被挂起的线程。 总结由于公平锁需要关心队列的情况，得按照队列里的先后顺序来获取锁(会造成大量的线程上下文切换)，而非公平锁则没有这个限制。 所以也就能解释非公平锁的效率会被公平锁更高。 号外最近在总结一些 Java 相关的知识点，感兴趣的朋友可以一起维护。 地址: https://github.com/crossoverJie/Java-Interview]]></content>
      <categories>
        <category>Java 进阶</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>ReentrantLock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对象的创建与内存分配]]></title>
    <url>%2F2018%2F01%2F18%2FnewObject%2F</url>
    <content type="text"><![CDATA[创建对象当 JVM 收到一个 new 指令时，会检查指令中的参数在常量池是否有这个符号的引用，还会检查该类是否已经被加载过了，如果没有的话则要进行一次类加载。 接着就是分配内存了，通常有两种方式： 指针碰撞 空闲列表 使用指针碰撞的前提是堆内存是完全工整的，用过的内存和没用的内存各在一边每次分配的时候只需要将指针向空闲内存一方移动一段和内存大小相等区域即可。 当堆中已经使用的内存和未使用的内存互相交错时，指针碰撞的方式就行不通了，这时就需要采用空闲列表的方式。虚拟机会维护一个空闲的列表，用于记录哪些内存是可以进行分配的，分配时直接从可用内存中直接分配即可。 堆中的内存是否工整是有垃圾收集器来决定的，如果带有压缩功能的垃圾收集器就是采用指针碰撞的方式来进行内存分配的。 分配内存时也会出现并发问题: 这样可以在创建对象的时候使用 CAS 这样的乐观锁来保证。 也可以将内存分配安排在每个线程独有的空间进行，每个线程首先在堆内存中分配一小块内存，称为本地分配缓存(TLAB : Thread Local Allocation Buffer)。 分配内存时，只需要在自己的分配缓存中分配即可，由于这个内存区域是线程私有的，所以不会出现并发问题。 可以使用 -XX:+/-UseTLAB 参数来设定 JVM 是否开启 TLAB 。 内存分配之后需要对该对象进行设置，如对象头。对象头的一些应用可以查看 Synchronize 关键字原理。 对象访问一个对象被创建之后自然是为了使用，在 Java 中是通过栈来引用堆内存中的对象来进行操作的。 对于我们常用的 HotSpot 虚拟机来说，这样引用关系是通过直接指针来关联的。 如图: 这样的好处就是：在 Java 里进行频繁的对象访问可以提升访问速度(相对于使用句柄池来说)。 内存分配Eden 区分配简单的来说对象都是在堆内存中分配的，往细一点看则是优先在 Eden 区分配。 这里就涉及到堆内存的划分了，为了方便垃圾回收，JVM 将对内存分为新生代和老年代。 而新生代中又会划分为 Eden 区，from Survivor、to Survivor 区。 其中 Eden 和 Survivor 区的比例默认是 8:1:1，当然也支持参数调整 -XX:SurvivorRatio=8。 当在 Eden 区分配内存不足时，则会发生 minorGC ，由于 Java 对象多数是朝生夕灭的特性，所以 minorGC 通常会比较频繁，效率也比较高。 当发生 minorGC 时，JVM 会根据复制算法将存活的对象拷贝到另一个未使用的 Survivor 区，如果 Survivor 区内存不足时，则会使用分配担保策略将对象移动到老年代中。 谈到 minorGC 时，就不得不提到 fullGC(majorGC) ，这是指发生在老年代的 GC ，不论是效率还是速度都比 minorGC 慢的多，回收时还会发生 stop the world 使程序发生停顿，所以应当尽量避免发生 fullGC 。 老年代分配也有一些情况会导致对象直接在老年代分配，比如当分配一个大对象时(大的数组，很长的字符串)，由于 Eden 区没有足够大的连续空间来分配时，会导致提前触发一次 GC，所以尽量别频繁的创建大对象。 因此 JVM 会根据一个阈值来判断大于该阈值对象直接分配到老年代，这样可以避免在新生代频繁的发生 GC。 对于一些在新生代的老对象 JVM 也会根据某种机制移动到老年代中。 JVM 是根据记录对象年龄的方式来判断该对象是否应该移动到老年代，根据新生代的复制算法，当一个对象被移动到 Survivor 区之后 JVM 就给该对象的年龄记为1，每当熬过一次 minorGC 后对象的年龄就 +1 ，直到达到阈值(默认为15)就移动到老年代中。 可以使用 -XX:MaxTenuringThreshold=15 来配置这个阈值。 总结虽说这些内容略显枯燥，但当应用发生不正常的 GC 时，可以方便更快的定位问题。 号外最近在总结一些 Java 相关的知识点，感兴趣的朋友可以一起维护。 地址: https://github.com/crossoverJie/Java-Interview]]></content>
      <categories>
        <category>Java 进阶</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Synchronize 关键字原理]]></title>
    <url>%2F2018%2F01%2F14%2FSynchronize%2F</url>
    <content type="text"><![CDATA[众所周知 Synchronize 关键字是解决并发问题常用解决方案，有以下三种使用方式: 同步普通方法，锁的是当前对象。 同步静态方法，锁的是当前 Class 对象。 同步块，锁的是 {} 中的对象。 实现原理：JVM 是通过进入、退出对象监视器( Monitor )来实现对方法、同步块的同步的。 具体实现是在编译之后在同步方法调用前加入一个 monitor.enter 指令，在退出方法和异常处插入 monitor.exit 的指令。 其本质就是对一个对象监视器( Monitor )进行获取，而这个获取过程具有排他性从而达到了同一时刻只能一个线程访问的目的。 而对于没有获取到锁的线程将会阻塞到方法入口处，直到获取锁的线程 monitor.exit 之后才能尝试继续获取锁。 流程图如下: 通过一段代码来演示: 12345public static void main(String[] args) &#123; synchronized (Synchronize.class)&#123; System.out.println("Synchronize"); &#125;&#125; 使用 javap -c Synchronize 可以查看编译之后的具体信息。 123456789101112131415161718192021222324252627282930public class com.crossoverjie.synchronize.Synchronize &#123; public com.crossoverjie.synchronize.Synchronize(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return public static void main(java.lang.String[]); Code: 0: ldc #2 // class com/crossoverjie/synchronize/Synchronize 2: dup 3: astore_1 **4: monitorenter** 5: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream; 8: ldc #4 // String Synchronize 10: invokevirtual #5 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 13: aload_1 **14: monitorexit** 15: goto 23 18: astore_2 19: aload_1 20: monitorexit 21: aload_2 22: athrow 23: return Exception table: from to target type 5 15 18 any 18 21 18 any&#125; 可以看到在同步块的入口和出口分别有 monitorenter,monitorexit指令。 锁优化synchronize 很多都称之为重量锁，JDK1.6 中对 synchronize 进行了各种优化，为了能减少获取和释放锁带来的消耗引入了偏向锁和轻量锁。 轻量锁当代码进入同步块时，如果同步对象为无锁状态时，当前线程会在栈帧中创建一个锁记录(Lock Record)区域，同时将锁对象的对象头中 Mark Word 拷贝到锁记录中，再尝试使用 CAS 将 Mark Word 更新为指向锁记录的指针。 如果更新成功，当前线程就获得了锁。 如果更新失败 JVM 会先检查锁对象的 Mark Word 是否指向当前线程的锁记录。 如果是则说明当前线程拥有锁对象的锁，可以直接进入同步块。 不是则说明有其他线程抢占了锁，如果存在多个线程同时竞争一把锁，轻量锁就会膨胀为重量锁。 解锁轻量锁的解锁过程也是利用 CAS 来实现的，会尝试锁记录替换回锁对象的 Mark Word 。如果替换成功则说明整个同步操作完成，失败则说明有其他线程尝试获取锁，这时就会唤醒被挂起的线程(此时已经膨胀为重量锁) 轻量锁能提升性能的原因是：认为大多数锁在整个同步周期都不存在竞争，所以使用 CAS 比使用互斥开销更少。但如果锁竞争激烈，轻量锁就不但有互斥的开销，还有 CAS 的开销，甚至比重量锁更慢。 偏向锁为了进一步的降低获取锁的代价，JDK1.6 之后还引入了偏向锁。 偏向锁的特征是:锁不存在多线程竞争，并且应由一个线程多次获得锁。 当线程访问同步块时，会使用 CAS 将线程 ID 更新到锁对象的 Mark Word 中，如果更新成功则获得偏向锁，并且之后每次进入这个对象锁相关的同步块时都不需要再次获取锁了。 释放锁当有另外一个线程获取这个锁时，持有偏向锁的线程就会释放锁，释放时会等待全局安全点(这一时刻没有字节码运行)，接着会暂停拥有偏向锁的线程，根据锁对象目前是否被锁来判定将对象头中的 Mark Word 设置为无锁或者是轻量锁状态。 偏向锁可以提高带有同步却没有竞争的程序性能，但如果程序中大多数锁都存在竞争时，那偏向锁就起不到太大作用。可以使用 -XX:-userBiasedLocking=false 来关闭偏向锁，并默认进入轻量锁。 其他优化适应性自旋在使用 CAS 时，如果操作失败，CAS 会自旋再次尝试。由于自旋是需要消耗 CPU 资源的，所以如果长期自旋就白白浪费了 CPU。JDK1.6加入了适应性自旋: 如果某个锁自旋很少成功获得，那么下一次就会减少自旋。 号外最近在总结一些 Java 相关的知识点，感兴趣的朋友可以一起维护。 地址: https://github.com/crossoverJie/Java-Interview]]></content>
      <categories>
        <category>Java 进阶</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>synchronize</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一致 Hash 算法分析]]></title>
    <url>%2F2018%2F01%2F08%2FConsistent-Hash%2F</url>
    <content type="text"><![CDATA[当我们在做数据库分库分表或者是分布式缓存时，不可避免的都会遇到一个问题: 如何将数据均匀的分散到各个节点中，并且尽量的在加减节点时能使受影响的数据最少。 Hash 取模随机放置就不说了，会带来很多问题。通常最容易想到的方案就是 hash 取模了。 可以将传入的 Key 按照 index = hash(key) % N 这样来计算出需要存放的节点。其中 hash 函数是一个将字符串转换为正整数的哈希映射方法，N 就是节点的数量。 这样可以满足数据的均匀分配，但是这个算法的容错性和扩展性都较差。 比如增加或删除了一个节点时，所有的 Key 都需要重新计算，显然这样成本较高，为此需要一个算法满足分布均匀同时也要有良好的容错性和拓展性。 一致 Hash 算法一致 Hash 算法是将所有的哈希值构成了一个环，其范围在 0 ~ 2^32-1。如下图： 之后将各个节点散列到这个环上，可以用节点的 IP、hostname 这样的唯一性字段作为 Key 进行 hash(key)，散列之后如下： 之后需要将数据定位到对应的节点上，使用同样的 hash 函数 将 Key 也映射到这个环上。 这样按照顺时针方向就可以把 k1 定位到 N1节点，k2 定位到 N3节点，k3 定位到 N2节点。 容错性这时假设 N1 宕机了： 依然根据顺时针方向，k2 和 k3 保持不变，只有 k1 被重新映射到了 N3。这样就很好的保证了容错性，当一个节点宕机时只会影响到少少部分的数据。 拓展性当新增一个节点时: 在 N2 和 N3 之间新增了一个节点 N4 ，这时会发现受印象的数据只有 k3，其余数据也是保持不变，所以这样也很好的保证了拓展性。 虚拟节点到目前为止该算法依然也有点问题: 当节点较少时会出现数据分布不均匀的情况： 这样会导致大部分数据都在 N1 节点，只有少量的数据在 N2 节点。 为了解决这个问题，一致哈希算法引入了虚拟节点。将每一个节点都进行多次 hash，生成多个节点放置在环上称为虚拟节点: 计算时可以在 IP 后加上编号来生成哈希值。 这样只需要在原有的基础上多一步由虚拟节点映射到实际节点的步骤即可让少量节点也能满足均匀性。 号外最近在总结一些 Java 相关的知识点，感兴趣的朋友可以一起维护。 地址: https://github.com/crossoverJie/Java-Interview]]></content>
      <categories>
        <category>算法</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[sbc(六) Zuul GateWay 网关应用]]></title>
    <url>%2F2017%2F11%2F28%2Fsbc6%2F</url>
    <content type="text"><![CDATA[前言看过之前SBC系列的小伙伴应该都可以搭建一个高可用、分布式的微服务了。 目前的结构图应该如下所示: 各个微服务之间都不存在单点，并且都注册于 Eureka ，基于此进行服务的注册于发现，再通过 Ribbon 进行服务调用，并具有客户端负载功能。 一切看起来都比较美好，但这里却忘了一个重要的细节： 当我们需要对外提供服务时怎么处理？ 这当然也能实现，无非就是将我们具体的微服务地址加端口暴露出去即可。 那又如何来实现负载呢？ 简单！可以通过 Nginx F5 之类的工具进行负载。 但是如果系统庞大，服务拆分的足够多那又有谁来维护这些路由关系呢？ 当然这是运维的活，不过这时候运维可能就要发飙了！ 并且还有一系列的问题: 服务调用之间的一些鉴权、签名校验怎么做？ 由于服务端地址较多，客户端请求难以维护。 针对于这一些问题 SpringCloud 全家桶自然也有对应的解决方案: Zuul。当我们系统整合 Zuul 网关之后架构图应该如下所示: 我们在所有的请求进来之前抽出一层网关应用，将服务提供的所有细节都进行了包装，这样所有的客户端都是和网关进行交互，简化了客户端开发。 同时具有如下功能: Zuul 注册于 Eureka 并集成了 Ribbon 所以自然也是可以从注册中心获取到服务列表进行客户端负载。 功能丰富的路由功能，解放运维。 具有过滤器，所以鉴权、验签都可以集成。 基于此我们来看看之前的架构中如何集成 Zuul 。 集成 Zuul为此我新建了一个项目 sbc-gateway-zuul 就是一个基础的 SpringBoot 结构。其中加入了 Zuul 的依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zuul&lt;/artifactId&gt;&lt;/dependency&gt; 由于需要将网关也注册到 Eureka 中，所以自然也需要: 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;&lt;/dependency&gt; 紧接着配置一些项目基本信息: 12345678# 项目配置spring.application.name=sbc-gateway-zuulserver.context-path=/server.port=8383# eureka地址eureka.client.serviceUrl.defaultZone=http://node1:8888/eureka/eureka.instance.prefer-ip-address=true 在启动类中加入开启 Zuul 的注解，一个网关应用就算是搭好了。 123456@SpringBootApplication//开启zuul代理@EnableZuulProxypublic class SbcGateWayZuulApplication &#123;&#125; 启动 Eureka 和网关看到已经注册成功那就大功告成了: 路由路由是网关的核心功能之一，可以使系统有一个统一的对外接口，下面来看看具体的应用。 传统路由传统路由非常简单，和 Nginx 类似，由开发、运维人员来维护请求地址和对应服务的映射关系，类似于: 12zuul.routes.user-service.path=/user-service/**zuul.routes.user-sercice.url=http://localhost:8080/ 这样当我们访问 http://localhost:8383/user-service/getUserInfo/1 网关就会自动给我们路由到 http://localhost:8080/getUserInfo/1 上。 可见只要我们维护好这个映射关系即可自由的配置路由信息(user-sercice 可自定义)，但是很明显这种方式不管是对运维还是开发都不友好。由于实际这种方式用的不多就再过多展开。 服务路由对此 Zuul 提供了一种基于服务的路由方式。我们只需要维护请求地址与服务 ID 之间的映射关系即可，并且由于集成了 Ribbon , Zuul 还可以在路由的时候通过 Eureka 实现负载调用。 具体配置： 12zuul.routes.sbc-user.path=/api/user/**zuul.routes.sbc-user.serviceId=sbc-user 这样当输入 http://localhost:8383/api/user/getUserInfo/1 时就会路由到注册到 Eureka 中服务 ID 为 sbc-user 的服务节点，如果有多节点就会按照 Ribbon 的负载算法路由到其中一台上。 以上配置还可以简写为: 12# 服务路由 简化配置zuul.routes.sbc-user=/api/user/** 这样让我们访问 http://127.0.0.1:8383/api/user/userService/getUserByHystrix 时候就会根据负载算法帮我们路由到 sbc-user 应用上，如下图所示: 启动了两个 sbc-user 服务。 请求结果: 一次路由就算完成了。 在上面的配置中有看到 /api/user/** 这样的通配符配置，具体有以下三种配置需要了解: ? 只能匹配任意的单个字符，如 /api/user/? 就只能匹配 /api/user/x /api/user/y /api/user/z 这样的路径。 * 只能匹配任意字符，如 /api/user/* 就只能匹配 /api/user/x /api/user/xy /api/user/xyz。 ** 可以匹配任意字符、任意层级。结合了以上两种通配符的特点，如 /api/user/** 则可以匹配 /api/user/x /api/user/x/y /api/user/x/y/zzz这样的路径，最简单粗暴！ 谈到通配符匹配就不得不提到一个问题，如上面的 sbc-user 服务由于后期迭代更新，将 sbc-user 中的一部分逻辑抽成了另一个服务 sbc-user-pro。新应用的路由规则是 /api/user/pro/**,如果我们按照: 12zuul.routes.sbc-user=/api/user/**zuul.routes.sbc-user-pro=/api/user/pro/** 进行配置的话，我们想通过 /api/user/pro/ 来访问 sbc-user-pro 应用，却由于满足第一个路由规则，所以会被 Zuul 路由到 sbc-user 这个应用上，这显然是不对的。该怎么解决这个问题呢？ 翻看路由源码 org.springframework.cloud.netflix.zuul.filters.SimpleRouteLocator 中的 locateRoutes() 方法: 1234567891011/** * Compute a map of path pattern to route. The default is just a static map from the * &#123;@link ZuulProperties&#125;, but subclasses can add dynamic calculations. */protected Map&lt;String, ZuulRoute&gt; locateRoutes() &#123; LinkedHashMap&lt;String, ZuulRoute&gt; routesMap = new LinkedHashMap&lt;String, ZuulRoute&gt;(); for (ZuulRoute route : this.properties.getRoutes().values()) &#123; routesMap.put(route.getPath(), route); &#125; return routesMap;&#125; 发现路由规则是遍历配置文件并放入 LinkedHashMap 中，由于 LinkedHashMap 是有序的，所以为了达到上文的效果，配置文件的加载顺序非常重要，因此我们只需要将优先匹配的路由规则放前即可解决。 过滤器过滤器可以说是整个 Zuul 最核心的功能，包括上文提到路由功能也是由过滤器来实现的。 摘抄官方的解释: Zuul 的核心就是一系列的过滤器，他能够在整个 HTTP 请求、响应过程中执行各样的操作。 其实总结下来就是四个特征: 过滤类型 过滤顺序 执行条件 具体实现 其实就是 ZuulFilter 接口中所定义的四个接口: 1234567String filterType();int filterOrder();boolean shouldFilter();Object run(); 官方流程图(生命周期): 简单理解下就是: 当一个请求进来时，首先是进入 pre 过滤器，可以做一些鉴权，记录调试日志等操作。之后进入 routing 过滤器进行路由转发，转发可以使用 Apache HttpClient 或者是 Ribbon 。post 过滤器呢则是处理服务响应之后的数据，可以进行一些包装来返回客户端。 error 则是在有异常发生时才会调用，相当于是全局异常拦截器。 自定义过滤器接下来实现一个文初所提到的鉴权操作: 新建一个 RequestFilter 类继承与 ZuulFilter 接口 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * Function: 请求拦截 * * @author crossoverJie * Date: 2017/11/20 00:33 * @since JDK 1.8 */public class RequestFilter extends ZuulFilter &#123; private Logger logger = LoggerFactory.getLogger(RequestFilter.class) ; /** * 请求路由之前被拦截 实现 pre 拦截器 * @return */ @Override public String filterType() &#123; return "pre"; &#125; @Override public int filterOrder() &#123; return 0; &#125; @Override public boolean shouldFilter() &#123; return true; &#125; @Override public Object run() &#123; RequestContext currentContext = RequestContext.getCurrentContext(); HttpServletRequest request = currentContext.getRequest(); String token = request.getParameter("token"); if (StringUtil.isEmpty(token))&#123; logger.warn("need token"); //过滤请求 currentContext.setSendZuulResponse(false); currentContext.setResponseStatusCode(400); return null ; &#125; logger.info("token =&#123;&#125;",token) ; return null; &#125;&#125; 非常 easy，就简单校验下请求中是否包含 token，不包含就返回 401 code。 不但如此，还需要将该类加入到 Spring 进行管理: 新建了 FilterConf 类: 123456789@Configuration@Componentpublic class FilterConf &#123; @Bean public RequestFilter filter()&#123; return new RequestFilter() ; &#125;&#125; 这样重启之后就可以看到效果了: 不传 token 时： 传入 token 时： 可见一些鉴权操作是可以放到这里来进行统一处理的。 其余几个过滤器也是大同小异，可以根据实际场景来自定义。 Zuul 高可用Zuul 现在既然作为了对外的第一入口，那肯定不能是单节点，对于 Zuul 的高可用有以下两种方式实现。 Eureka 高可用第一种最容易想到和实现:我们可以部署多个 Zuul 节点，并且都注册于 Eureka ，如下图： 这样虽然简单易维护，但是有一个严重的缺点：那就是客户端也得注册到 Eureka 上才能对 Zuul 的调用做到负载，这显然是不现实的。 所以下面这种做法更为常见。 基于 Nginx 高可用在调用 Zuul 之前使用 Nginx 之类的负载均衡工具进行负载，这样 Zuul 既能注册到 Eureka ，客户端也能实现对 Zuul 的负载，如下图： 总结这样在原有的微服务架构的基础上加上网关之后另整个系统更加完善了，从网关的设计来看：大多数系统架构都有分层的概念，不能解决问题那就多分几层🤓。 项目：https://github.com/crossoverJie/springboot-cloud 博客：http://crossoverjie.top。]]></content>
      <categories>
        <category>sbc</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>SpringBoot</tag>
        <tag>SpringCloud</tag>
        <tag>Zuul</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【译】你可以用GitHub做的12件 Cool 事情]]></title>
    <url>%2F2017%2F11%2F05%2Ftranslation1-12%20cool%20things%20you%20can%20do%20with%20GitHub%2F</url>
    <content type="text"><![CDATA[原文链接1 在 GitHub.com 编辑代码我将从我认为大家都知道的一件事情开始(尽管我是直到一周前才知道)。 当你在 GitHub 查看文件时(任何文本文件，任何仓库中)，右上角会有一个小铅笔图标，点击它就可以编辑文件了。完成之后点击 Propose file change 按钮 GitHub 将会自动帮你 fork 该项目并且创建一个 pull request 。 很厉害吧！他自动帮你 fork 了该 repo。 不再需要 fork , pull ,本地编辑再 push 以及创建一个 PR 这样的流程了。 这非常适合修复编写代码中出现的拼写错误和修正一个不太理想的想法。 2 粘贴图片你不仅仅受限于输入文本和描述问题，你知道你可以直接从粘贴板中粘贴图片吗？当你粘贴时，你会看到图片已经被上传了(毫无疑问被上传到云端)之后会变成 Markdown 语法来显示图片。 3 格式化代码如果你想写一段代码，你可以三个反引号开始 —— 就像你在研究MarkDown时所学到的 —— 之后 GitHub 会试着猜测你写的语言。 但如果你写了一些类似于 Vue, Typescript, JSX 这样的语言，你可以明确指定得到正确的高亮。 注意第一行中的1```jsx 这意味着代码段将会呈现出: (这个扩展于 gists 。顺便说一句，如果你使用 .jsx 后缀，就会得到JSX的语法高亮) 这是一个所有受支持的语法列表。 4 在 PR 中用关键词关闭 Issues假设你创建了一个用于修复 Issues #234 的 PR ,你可以在你 PR 的描述中填写 fixes #234 (或是在你 PR 任意评论中填写都是可以的)。之后合并这个 PR 时将会自动关闭填写的 Issues。怎么样,很 cool 吧。 了解是更多相关的内容。 5 链接到评论你是否有过想要链接到特殊 comment 的想法但却无法实现？那是因为你不知道怎么做。朋友那都是过去式了，现在我就告诉你，点击用户名旁边的日期/时间即可链接到该 comment 。 6 链接到代码我知道你想链接到具体的代码行上。 尝试:查看文件时，点击代码旁边的行号。 看到了吧，浏览器的 URL 已经被更新为行号了。如果你按住 shift,同时点击其他行号，URL 再次被更新，并且你也高亮显示页面中的一段代码。 分享这个 URL ，访问时将会链接到该文件已经选中的那些代码段。 但等一下，那指向的是当前的分支，如果文件发生了改变呢？也许一个在当前状态连接到文件的永久连接正是你想要的。 我很懒，所以用一张截图展示以上的所有操作。 谈到网址。。。 7 像命令行一样使用 GitHub 链接使用 GitHub 自带的 UI 浏览也还不错，但有时直接在 URL 中输入是最快的方法。比如，我想跳转到我正在编辑的分支并和 master 进行对比，就可以在项目名称后面接上 /compare/branch-name 。 与选中分支的对比页将会显示出来: 以上就是和 master 分支的差异，如果想要合并分支的话，只需要输入 /compare/integration-branch...my-branch 即可。 你还可以利用快捷键达到同样的效果，使用 ctrl + L 或者 cmd + L 可以将光标移动到 URL 上(至少在 Chrome 中可以)。 加上浏览器的自动补全 —— 你就可以在两个分支之间轻松切换了。 8 在Issues创建列表你想在你的 issue 中看到复选框列表吗? 你想在查看 issue 列表是它们以好看的 2 of 5 进度条呈现吗？ 太好了！你可以用以下语法来创建一个交互性的复选框: 12345- [ ] Screen width (integer)- [x] Service worker support- [x] Fetch support- [ ] CSS flexbox support- [ ] Custom elements 是由一个空格、中横线、空格、左括号、空格(或者是 X )、右括号、空格以及一些文本组成。 你甚至可以真正的 选中/取消 这些复选框！基于某些原因，对于我来说你看起来像是技术魔力。是真的能够选中这些复选框！甚至它还更新了底层源码。 ps：以下包括第九点 基于GitHub的项目面板 由于用的不多就没有翻译。 10 GitHub wiki作为一个像维基百科那样的非结构化的页面集合， GitHub Wiki的供给(我把它称之为 Gwiki ) 是一个非常棒的功能。 对于结构化的页面来说 —— 例如你的文档：不能说这个页面是其他页面的子页面，或则是有 “下一节”，“上一节” 这样的便捷按钮。并且 Hansel 和 Gretel 也没有，因为结构化页面并没有 breadcrumbs 这样的设计。 我们继续，让 Gwiki 动起来，我从 NodeJS 的文档中复制了几页来作为 wiki 页面。然后创建了一个自定义侧边栏，帮助我更好地模拟一些实际的目录结构。尽管它不会突出显示你当前的页面位置，但侧边栏会一直存在。 这些链接需要你手动维护，但总的来说，我认为它可以做得很好。 如果需要的话可以看看。 虽然它与 GitBook ( Redux 文档所使用的)或者是定制网站相比仍有差距。但在你的 repo 中它有 80% 完全值得信赖的。 我的建议是: 如果你已经有多个 README.md 文件，并且想要一些关于用户指南或更详细的文档的不同的页面，那么你应该选择 Gwiki。 如果缺乏结构化/导航开始让你不爽的话，那就试试其他的吧。 11 GitHub Pages你可能已经知道使用 GitHub Pages 来托管一个静态网站。如果你不知道，现在就来学习，这一节是专门用于讨论使用 Jekyll 来构建一个站点的。 最简单的就是： GitHub Pages + Jekyll会通过一个漂亮的主题来渲染你的 README.md 文件。例如:通过 about-github 来查看的我的 README 页面。 如果我在 GitHub 中点击了 settings选项，切换到 Github Pages 设置，然后选择一个 Jekyll theme。。。 我就可以得到 Jekyll-themed 页面。 从这点上我可以主要依据易编辑的 Markdown 文件来构建一个完整的静态站点。本质上是把 GitHub 变成了 CMS。 虽然我没有实际使用过，但是 React Bootstrap 的网站都是使用它来构建的。所以它不会糟糕。 注意:它要求 Ruby 运行本地环境( Windows 自行安装， macOS 自带)。 12 把 GitHub 当做 CRM 使用假设你有一个存有一些文本内容的网站，你不想将文本内容存储于真正的 HTML 源码中。 相反的，你想要将这些文本块存储于非开发人员能轻松的进行编辑的地方。可能是一个版本控制系统，甚至是一个审核流程。 我的建议是:使用 GitHub 厂库中的 Markdown 文件来存储这些文本内容，然后使用前端组件来拉取这些文本块并展示在页面上。 我是搞 React 的，所以这有一个 解析 Markdown 的组件例子，给定一些 Markdown 文件路径，它将会自动拉取并作为 HTML 显示出来。 1234567891011121314151617181920212223242526class Markdown extends React.Component &#123; constructor(props) &#123; super(props); // replace with your URL, obviously this.baseUrl = &apos;https://raw.githubusercontent.com/davidgilbertson/about-github/master/text-snippets&apos;; this.state = &#123; markdown: &apos;&apos;, &#125;; &#125; componentDidMount() &#123; fetch(`$&#123;this.baseUrl&#125;/$&#123;this.props.url&#125;`) .then(response =&gt; response.text()) .then((markdown) =&gt; &#123; this.setState(&#123;markdown&#125;); &#125;); &#125; render() &#123; return ( &lt;div dangerouslySetInnerHTML=&#123;&#123;__html: marked(this.state.markdown)&#125;&#125; /&gt; ); &#125;&#125; 奖励环节 —— GitHub 工具我已经使用了 Octotree Chrome extension 有段时间了，现在我向大家推荐它！无论你是在查看哪个 repo 它都会在左侧给你一个树状面板。 通过这个视频我了解到了 octobox，它是用于管理你的 GitHub Issues 收件箱，看起来相当不错！以上就是我针对于octobox的全部想法。 其他就是这样了！我希望这里至少有三件事是你还不知道的。 最后: hava a nice day！]]></content>
      <categories>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM(十七) MQ应用]]></title>
    <url>%2F2017%2F10%2F20%2FSSM17%2F</url>
    <content type="text"><![CDATA[前言写这篇文章的起因是由于之前的一篇关于Kafka异常消费，当时为了解决问题不得不使用临时的方案。 总结起来归根结底还是对Kafka不熟悉导致的，加上平时工作的需要，之后就花些时间看了Kafka相关的资料。 何时使用MQ谈到Kafka就不得不提到MQ，是属于消息队列的一种。作为一种基础中间件在互联网项目中有着大量的使用。 一种技术的产生自然是为了解决某种需求，通常来说是以下场景： 需要跨进程通信：B系统需要A系统的输出作为输入参数。 当A系统的输出能力远远大于B系统的处理能力。 针对于第一种情况有两种方案: 使用RPC远程调用,A直接调用B。 使用MQ,A发布消息到MQ,B订阅该消息。 当我们的需求是:A调用B实时响应，并且实时关心响应结果则使用RPC，这种情况就得使用同步调用。 反之当我们并不关心调用之后的执行结果，并且有可能被调用方的执行非常耗时，这种情况就非常适合用MQ来达到异步调用目的。 比如常见的登录场景就只能用同步调用的方式，因为这个过程需要实时的响应结果，总不能在用户点了登录之后排除网络原因之外再额外的等几秒吧。 但类似于用户登录需要奖励积分的情况则使用MQ会更好，因为登录并不关系积分的情况，只需要发个消息到MQ,处理积分的服务订阅处理即可，这样还可以解决积分系统故障带来的雪崩效应。 MQ还有一个基础功能则是限流削峰，这对于大流量的场景如果将请求直接调用到B系统则非常有可能使B系统出现不可用的情况。这种场景就非常适合将请求放入MQ，不但可以利用MQ削峰还尽可能的保证系统的高可用。 Kafka简介本次重点讨论下Kafka。简单来说Kafka是一个支持水平扩展，高吞吐率的分布式消息系统。 Kafka的常用知识: Topic:生产者和消费者的交互都是围绕着一个Topic进行的，通常来说是由业务来进行区分，由生产消费者协商之后进行创建。 Partition(分区):是Topic下的组成，通常一个Topic下有一个或多个分区，消息生产之后会按照一定的算法负载到每个分区，所以分区也是Kafka性能的关键。当发现性能不高时便可考虑新增分区。 结构图如下: 创建TopicKafka的安装官网有非常详细的讲解。这里谈一下在日常开发中常见的一些操作，比如创建Topic： 1sh bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 3 --topic `test` 创建了三个分区的test主题。 使用 1sh bin/kafka-topics.sh --list --zookeeper localhost:2181 可以列出所有的Topic。 Kafka生产者使用kafka官方所提供的Java API来进行消息生产，实际使用中编码实现更为常用: 12345678910111213141516171819202122232425262728293031323334353637383940/** Kafka生产者 * @author crossoverJie */public class Producer &#123; private static final Logger LOGGER = LoggerFactory.getLogger(Producer.class); /** * 消费配置文件 */ private static String consumerProPath; public static void main(String[] args) throws IOException &#123; // set up the producer consumerProPath = System.getProperty("product_path"); KafkaProducer&lt;String, String&gt; producer = null; try &#123; FileInputStream inputStream = new FileInputStream(new File(consumerProPath)); Properties properties = new Properties(); properties.load(inputStream); producer = new KafkaProducer&lt;String, String&gt;(properties); &#125; catch (IOException e) &#123; LOGGER.error("load config error", e); &#125; try &#123; // send lots of messages for (int i=0 ;i&lt;100 ; i++)&#123; producer.send(new ProducerRecord&lt;String, String&gt;( "topic_optimization", i+"", i+"")); &#125; &#125; catch (Throwable throwable) &#123; System.out.printf("%s", throwable.getStackTrace()); &#125; finally &#123; producer.close(); &#125; &#125;&#125; 再配合以下启动参数即可发送消息:1-Dproduct_path=/xxx/producer.properties 以及生产者的配置文件:12345678910#集群地址，可以多个bootstrap.servers=10.19.13.51:9094acks=allretries=0batch.size=16384auto.commit.interval.ms=1000linger.ms=0key.serializer=org.apache.kafka.common.serialization.StringSerializervalue.serializer=org.apache.kafka.common.serialization.StringSerializerblock.on.buffer.full=true 具体的配置说明详见此处:https://kafka.apache.org/0100/documentation.html#theproducer 流程非常简单，其实就是一些API的调用。 消息发完之后可以通过以下命令查看队列内的情况:1sh kafka-consumer-groups.sh --bootstrap-server localhost:9094 --describe --group group1 其中的lag便是队列里的消息数量。 Kafka消费者有了生产者自然也少不了消费者，这里首先针对单线程消费: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106/** * Function:kafka官方消费 * * @author crossoverJie * Date: 2017/10/19 01:11 * @since JDK 1.8 */public class KafkaOfficialConsumer &#123; private static final Logger LOGGER = LoggerFactory.getLogger(KafkaOfficialConsumer.class); /** * 日志文件地址 */ private static String logPath; /** * 主题名称 */ private static String topic; /** * 消费配置文件 */ private static String consumerProPath ; /** * 初始化参数校验 * @return */ private static boolean initCheck() &#123; topic = System.getProperty("topic") ; logPath = System.getProperty("log_path") ; consumerProPath = System.getProperty("consumer_pro_path") ; if (StringUtil.isEmpty(topic) || logPath.isEmpty()) &#123; LOGGER.error("system property topic ,consumer_pro_path, log_path is required !"); return true; &#125; return false; &#125; /** * 初始化kafka配置 * @return */ private static KafkaConsumer&lt;String, String&gt; initKafkaConsumer() &#123; KafkaConsumer&lt;String, String&gt; consumer = null; try &#123; FileInputStream inputStream = new FileInputStream(new File(consumerProPath)) ; Properties properties = new Properties(); properties.load(inputStream); consumer = new KafkaConsumer&lt;String, String&gt;(properties); consumer.subscribe(Arrays.asList(topic)); &#125; catch (IOException e) &#123; LOGGER.error("加载consumer.props文件出错", e); &#125; return consumer; &#125; public static void main(String[] args) &#123; if (initCheck())&#123; return; &#125; int totalCount = 0 ; long totalMin = 0L ; int count = 0; KafkaConsumer&lt;String, String&gt; consumer = initKafkaConsumer(); long startTime = System.currentTimeMillis() ; //消费消息 while (true) &#123; ConsumerRecords&lt;String, String&gt; records = consumer.poll(200); if (records.count() &lt;= 0)&#123; continue ; &#125; LOGGER.debug("本次获取:"+records.count()); count += records.count() ; long endTime = System.currentTimeMillis() ; LOGGER.debug("count=" +count) ; if (count &gt;= 10000 )&#123; totalCount += count ; LOGGER.info("this consumer &#123;&#125; record，use &#123;&#125; milliseconds",count,endTime-startTime); totalMin += (endTime-startTime) ; startTime = System.currentTimeMillis() ; count = 0 ; &#125; LOGGER.debug("end totalCount=&#123;&#125;,min=&#123;&#125;",totalCount,totalMin); /*for (ConsumerRecord&lt;String, String&gt; record : records) &#123; record.value() ; JsonNode msg = null; try &#123; msg = mapper.readTree(record.value()); &#125; catch (IOException e) &#123; LOGGER.error("消费消息出错", e); &#125; LOGGER.info("kafka receive = "+msg.toString()); &#125;*/ &#125; &#125;&#125; 配合以下启动参数:1-Dlog_path=/log/consumer.log -Dtopic=test -Dconsumer_pro_path=consumer.properties 其中采用了轮询的方式获取消息，并且记录了消费过程中的数据。 消费者采用的配置:1234567891011121314151617bootstrap.servers=192.168.1.2:9094group.id=group1# 自动提交enable.auto.commit=truekey.deserializer=org.apache.kafka.common.serialization.StringDeserializervalue.deserializer=org.apache.kafka.common.serialization.StringDeserializer# fast session timeout makes it more fun to play with failoversession.timeout.ms=10000# These buffer sizes seem to be needed to avoid consumer switching to# a mode where it processes one bufferful every 5 seconds with multiple# timeouts along the way. No idea why this happens.fetch.min.bytes=50000receive.buffer.bytes=262144max.partition.fetch.bytes=2097152 为了简便我采用的是自动提交offset。 消息存放机制谈到offset就必须得谈谈Kafka的消息存放机制. Kafka的消息不会因为消费了就会立即删除，所有的消息都会持久化到日志文件，并配置有过期时间，到了时间会自动删除过期数据，并且不会管其中的数据是否被消费过。 由于这样的机制就必须的有一个标志来表明哪些数据已经被消费过了，offset(偏移量)就是这样的作用，它类似于指针指向某个数据，当消费之后offset就会线性的向前移动，这样一来的话消息是可以被任意消费的，只要我们修改offset的值即可。 消费过程中还有一个值得注意的是: 同一个consumer group(group.id相等)下只能有一个消费者可以消费，这个刚开始确实会让很多人踩坑。 多线程消费针对于单线程消费实现起来自然是比较简单，但是效率也是要大打折扣的。 为此我做了一个测试，使用之前的单线程消费120009条数据的结果如下: 总共花了12450毫秒。 那么换成多线程消费怎么实现呢？ 我们可以利用partition的分区特性来提高消费能力，单线程的时候等于是一个线程要把所有分区里的数据都消费一遍，如果换成多线程就可以让一个线程只消费一个分区,这样效率自然就提高了，所以线程数coreSize&lt;=partition。 首先来看下入口: 1234567891011121314151617public class ConsumerThreadMain &#123; private static String brokerList = &quot;localhost:9094&quot;; private static String groupId = &quot;group1&quot;; private static String topic = &quot;test&quot;; /** * 线程数量 */ private static int threadNum = 3; public static void main(String[] args) &#123; ConsumerGroup consumerGroup = new ConsumerGroup(threadNum, groupId, topic, brokerList); consumerGroup.execute(); &#125;&#125; 其中的ConsumerGroup类:12345678910111213141516171819202122232425262728293031323334353637383940public class ConsumerGroup &#123; private static Logger LOGGER = LoggerFactory.getLogger(ConsumerGroup.class); /** * 线程池 */ private ExecutorService threadPool; private List&lt;ConsumerCallable&gt; consumers ; public ConsumerGroup(int threadNum, String groupId, String topic, String brokerList) &#123; ThreadFactory namedThreadFactory = new ThreadFactoryBuilder() .setNameFormat(&quot;consumer-pool-%d&quot;).build(); threadPool = new ThreadPoolExecutor(threadNum, threadNum, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(1024), namedThreadFactory, new ThreadPoolExecutor.AbortPolicy()); consumers = new ArrayList&lt;ConsumerCallable&gt;(threadNum); for (int i = 0; i &lt; threadNum; i++) &#123; ConsumerCallable consumerThread = new ConsumerCallable(brokerList, groupId, topic); consumers.add(consumerThread); &#125; &#125; /** * 执行任务 */ public void execute() &#123; long startTime = System.currentTimeMillis() ; for (ConsumerCallable runnable : consumers) &#123; Future&lt;ConsumerFuture&gt; future = threadPool.submit(runnable) ; &#125; if (threadPool.isShutdown())&#123; long endTime = System.currentTimeMillis() ; LOGGER.info(&quot;main thread use &#123;&#125; Millis&quot; ,endTime -startTime) ; &#125; threadPool.shutdown(); &#125;&#125; 最后真正的执行逻辑ConsumerCallable:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980public class ConsumerCallable implements Callable&lt;ConsumerFuture&gt; &#123; private static Logger LOGGER = LoggerFactory.getLogger(ConsumerCallable.class); private AtomicInteger totalCount = new AtomicInteger() ; private AtomicLong totalTime = new AtomicLong() ; private AtomicInteger count = new AtomicInteger() ; /** * 每个线程维护KafkaConsumer实例 */ private final KafkaConsumer&lt;String, String&gt; consumer; public ConsumerCallable(String brokerList, String groupId, String topic) &#123; Properties props = new Properties(); props.put(&quot;bootstrap.servers&quot;, brokerList); props.put(&quot;group.id&quot;, groupId); //自动提交位移 props.put(&quot;enable.auto.commit&quot;, &quot;true&quot;); props.put(&quot;auto.commit.interval.ms&quot;, &quot;1000&quot;); props.put(&quot;session.timeout.ms&quot;, &quot;30000&quot;); props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); this.consumer = new KafkaConsumer&lt;&gt;(props); consumer.subscribe(Arrays.asList(topic)); &#125; /** * Computes a result, or throws an exception if unable to do so. * * @return computed result * @throws Exception if unable to compute a result */ @Override public ConsumerFuture call() throws Exception &#123; boolean flag = true; int failPollTimes = 0 ; long startTime = System.currentTimeMillis() ; while (flag) &#123; // 使用200ms作为获取超时时间 ConsumerRecords&lt;String, String&gt; records = consumer.poll(200); if (records.count() &lt;= 0)&#123; failPollTimes ++ ; if (failPollTimes &gt;= 20)&#123; LOGGER.debug(&quot;达到&#123;&#125;次数，退出 &quot;,failPollTimes); flag = false ; &#125; continue ; &#125; //获取到之后则清零 failPollTimes = 0 ; LOGGER.debug(&quot;本次获取:&quot;+records.count()); count.addAndGet(records.count()) ; totalCount.addAndGet(count.get()) ; long endTime = System.currentTimeMillis() ; if (count.get() &gt;= 10000 )&#123; LOGGER.info(&quot;this consumer &#123;&#125; record，use &#123;&#125; milliseconds&quot;,count,endTime-startTime); totalTime.addAndGet(endTime-startTime) ; startTime = System.currentTimeMillis() ; count = new AtomicInteger(); &#125; LOGGER.debug(&quot;end totalCount=&#123;&#125;,min=&#123;&#125;&quot;,totalCount,totalTime); /*for (ConsumerRecord&lt;String, String&gt; record : records) &#123; // 简单地打印消息 LOGGER.debug(record.value() + &quot; consumed &quot; + record.partition() + &quot; message with offset: &quot; + record.offset()); &#125;*/ &#125; ConsumerFuture consumerFuture = new ConsumerFuture(totalCount.get(),totalTime.get()) ; return consumerFuture ; &#125;&#125; 理一下逻辑: 其实就是初始化出三个消费者实例，用于三个线程消费。其中加入了一些统计，最后也是消费120009条数据结果如下。 由于是并行运行，可见消费120009条数据可以提高2秒左右，当数据以更高的数量级提升后效果会更加明显。 但这也有一些弊端: 灵活度不高，当分区数量变更之后不能自适应调整。 消费逻辑和处理逻辑在同一个线程，如果处理逻辑较为复杂会影响效率，耦合也较高。当然这个处理逻辑可以再通过一个内部队列发出去由另外的程序来处理也是可以的。 总结Kafka的知识点还是较多，Kafka的使用也远不这些。之后会继续分享一些关于Kafka监控等相关内容。 项目地址：https://github.com/crossoverJie/SSM.git 个人博客：http://crossoverjie.top。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sbc(五)Hystrix-服务容错与保护]]></title>
    <url>%2F2017%2F09%2F20%2Fsbc5%2F</url>
    <content type="text"><![CDATA[前言看过 应用限流的朋友应该知道，限流的根本目的就是为了保障服务的高可用。 本次再借助SpringCloud中的集成的Hystrix组件来谈谈服务容错。 其实产生某项需求的原因都是为了解决某个需求。当我们将应用进行分布式模块部署之后,各个模块之间通过远程调用的方式进行交互(RPC)。拿我们平时最常见的下单买商品来说，点击下单按钮的一瞬间可能会向发送的请求包含： 请求订单系统创建订单。 请求库存系统扣除库存。 请求用户系统更新用户交易记录。 这其中的每一步都有可能因为网络、资源、服务器等原因造成延迟响应甚至是调用失败。当后面的请求源源不断的过来时延迟的资源也没有的到释放，这样的堆积很有可能把其中一个模块拖垮，其中的依赖关系又有可能把整个调用链中的应用Over最后导致整个系统不可能。这样就会产生一种现象:雪崩效应。 之前讲到的限流也能起到一定的保护作用，但还远远不够。我们需要从各个方面来保障服务的高可用。 比如： 超时重试。 断路器模式。 服务降级。等各个方面来保障。 使用HystrixSpringCloud中已经为我们集成了Netflix开源的Hystrix框架，使用该框架可以很好的帮我们做到服务容错。 Hystrix简介下面是一张官方的流程图: 简单介绍下: 在远程调用时，将请求封装到HystrixCommand进行同步或是异步调用，在调用过程中判断熔断器是否打开、线程池或是信号量是否饱和、执行过程中是否抛出异常，如果是的话就会进入回退逻辑。并且整个过程中都会收集运行状态来控制断路器的状态。 不但如此该框架还拥有自我恢复功能，当断路器打开后，每次请求都会进入回退逻辑。当我们的应用恢复正常后也不能再进入回退逻辑吧。 所以hystrix会在断路器打开后的一定时间将请求发送到服务提供者，如果正常响应就关闭断路器，反之则继续打开，这样就能很灵活的自我修复了。 Feign整合Hystrix在之前的章节中已经使用Feign来进行声明式调用了，并且在实际开发中也是如此，所以这次我们就直接用Feign来整合Hystrix。 使用了项目原有的sbc-user,sbc-order来进行演示，调用关系如下图: User应用通过Order提供出来的order-client依赖调用了Order中的创建订单服务。 其中主要修改的就是order-client，在之前的OrderServiceClient接口中增加了以下注解: 12345678910111213@RequestMapping(value="/orderService")@FeignClient(name="sbc-order", // fallbackFactory = OrderServiceFallbackFactory.class, // FIXME: 2017/9/4 如果配置了fallback 那么fallbackFactory将会无效 fallback = OrderServiceFallBack.class, configuration = OrderConfig.class)@RibbonClientpublic interface OrderServiceClient extends OrderService&#123; @ApiOperation("获取订单号") @RequestMapping(value = "/getOrderNo", method = RequestMethod.POST) BaseResponse&lt;OrderNoResVO&gt; getOrderNo(@RequestBody OrderNoReqVO orderNoReq) ;&#125; 由于Feign已经默认整合了Hystrix所以不需要再额外加入依赖。 服务降级对应的@FeignClient中的fallback属性则是服务容错中很关键的服务降级的具体实现，来看看OrderServiceFallBack类: 123456789101112public class OrderServiceFallBack implements OrderServiceClient &#123; @Override public BaseResponse&lt;OrderNoResVO&gt; getOrderNo(@RequestBody OrderNoReqVO orderNoReq) &#123; BaseResponse&lt;OrderNoResVO&gt; baseResponse = new BaseResponse&lt;&gt;() ; OrderNoResVO vo = new OrderNoResVO() ; vo.setOrderId(123456L); baseResponse.setDataBody(vo); baseResponse.setMessage(StatusEnum.FALLBACK.getMessage()); baseResponse.setCode(StatusEnum.FALLBACK.getCode()); return baseResponse; &#125;&#125; 该类实现了OrderServiceClient接口，可以很明显的看出其中的getOrderNo()方法就是服务降级时所触发的逻辑。 光有实现还不够，我们需要将改类加入到Spring中管理起来。这样上文中@FeignClient的configuration属性就起到作用了，来看看对应的OrderConfig的代码: 123456789101112@Configurationpublic class OrderConfig &#123; @Bean public OrderServiceFallBack fallBack()&#123; return new OrderServiceFallBack(); &#125; @Bean public OrderServiceFallbackFactory factory()&#123; return new OrderServiceFallbackFactory(); &#125;&#125; 其中new OrderServiceFallBack()并用了@Bean注解，等同于: 12&lt;bean id=&quot;orderServiceFallBack&quot; class=&quot;com.crossoverJie.order.feign.config.OrderServiceFallBack&quot;&gt;&lt;/bean&gt; 这样每当请求失败就会执行回退逻辑，如下图: 值得注意的是即便是执行了回退逻辑断路器也不一定打开了，我们可以通过应用的health端点来查看Hystrix的状态。 ps:想要查看该端点需要加入以下依赖: 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; 就拿刚才的例子来说，先关闭Order应用，在Swagger访问下面这个接口，肯定是会进入回退逻辑: 12345678910@RestController@Api("用户服务API")@RequestMapping(value = "/userService")@Validatedpublic interface UserService &#123; @ApiOperation("hystrix容错调用") @RequestMapping(value = "/getUserByHystrix", method = RequestMethod.POST) BaseResponse&lt;OrderNoResVO&gt; getUserByHystrix(@RequestBody UserReqVO userReqVO) ;&#125; 查看health端点: 发现Hystrix的状态依然是UP状态，表明当前断路器并没有打开。 反复调用多次接口之后再次查看health端点: 发现这个时候断路器已经打开了。 这是因为断路器只有在达到了一定的失败阈值之后才会打开。 输出异常进入回退逻辑之后还不算完，大部分场景我们都需要记录为什么回退，也就是具体的异常。这些信息对我们后续的系统监控，应用调优也有很大帮助。 实现起来也很简单:上文中在@FeignClient注解中加入的fallbackFactory = OrderServiceFallbackFactory.class属性则是用于处理回退逻辑以及包含异常信息： 123456789101112131415161718192021222324252627282930/** * Function:查看fallback原因 * * @author crossoverJie * Date: 2017/9/4 00:45 * @since JDK 1.8 */public class OrderServiceFallbackFactory implements FallbackFactory&lt;OrderServiceClient&gt;&#123; private final static Logger LOGGER = LoggerFactory.getLogger(OrderServiceFallbackFactory.class); @Override public OrderServiceClient create(Throwable throwable) &#123; return new OrderServiceClient() &#123; @Override public BaseResponse&lt;OrderNoResVO&gt; getOrderNo(@RequestBody OrderNoReqVO orderNoReq) &#123; LOGGER.error("fallback:" + throwable); BaseResponse&lt;OrderNoResVO&gt; baseResponse = new BaseResponse&lt;&gt;() ; OrderNoResVO vo = new OrderNoResVO() ; vo.setOrderId(123456L); baseResponse.setDataBody(vo); baseResponse.setMessage(StatusEnum.FALLBACK.getMessage()); baseResponse.setCode(StatusEnum.FALLBACK.getCode()); return baseResponse; &#125; &#125;; &#125;&#125; 代码很简单，实现了FallbackFactory接口中的create()方法，该方法的入参就是异常信息，可以按照我们的需要自行处理，后面则是和之前一样的回退处理。 2017-09-21 13:22:30.307 ERROR 27838 --- [rix-sbc-order-1] c.c.o.f.f.OrderServiceFallbackFactory : fallback:java.lang.RuntimeException: com.netflix.client.ClientException: Load balancer does not have available server for client: sbc-order。 Note: fallbackFactory和fallback属性不可共用。 Hystrix监控Hystrix还自带了一套监控组件，只要依赖了spring-boot-starter-actuator即可通过/hystrix.stream端点来获得监控信息。 冰冷的数据肯定没有实时的图表来的直观，所以Hystrix也自带Dashboard。 Hystrix与Turbine聚合监控为此我们新建了一个应用sbc-hystrix-turbine来显示hystrix-dashboard。目录结构和普通的springboot应用没有差异，看看主类: 1234567891011//开启EnableTurbine@EnableTurbine@SpringBootApplication@EnableHystrixDashboardpublic class SbcHystrixTurbineApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SbcHystrixTurbineApplication.class, args); &#125;&#125; 其中使用@EnableHystrixDashboard开启Dashboard @EnableTurbine开启Turbine支持。 以上这些注解需要以下这些依赖:12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-turbine&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-netflix-turbine&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix-dashboard&lt;/artifactId&gt;&lt;/dependency&gt; 实际项目中，我们的应用都是多节点部署以达到高可用的目的，单个监控显然不现实，所以需要使用Turbine来进行聚合监控。 关键的application.properties配置文件: 123456789101112# 项目配置spring.application.name=sbc-hystrix-trubineserver.context-path=/server.port=8282# eureka地址eureka.client.serviceUrl.defaultZone=http://node1:8888/eureka/eureka.instance.prefer-ip-address=true# 需要加入的实例turbine.appConfig=sbc-user,sbc-orderturbine.cluster-name-expression=&quot;default&quot; 其中turbine.appConfig配置我们需要监控的应用，这样当多节点部署的时候就非常方便了(同一个应用的多个节点spring.application.name值是相同的)。 将该应用启动访问http://ip:port/hystrix.stream： 由于我们的turbine和Dashboard是一个应用所以输入http://localhost:8282/turbine.stream即可。 详细指标如官方描述: 通过该面板我们就可以及时的了解到应用当前的各个状态，如果再加上一些报警措施就能帮我们及时的响应生产问题。 总结服务容错的整个还是比较大的,博主也是摸着石头过河，关于本次的Hystrix只是一个入门版，后面会持续分析它的线程隔离、信号量隔离等原理。 项目：https://github.com/crossoverJie/springboot-cloud 博客：http://crossoverjie.top。]]></content>
      <categories>
        <category>sbc</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>SpringBoot</tag>
        <tag>SpringCloud</tag>
        <tag>Hystrix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM(十六) 曲线救国-Kafka消费异常]]></title>
    <url>%2F2017%2F09%2F05%2FSSM16%2F</url>
    <content type="text"><![CDATA[前言最近线上遇到一个问题:在消费kafka消息的时候如果长时间(大概半天到一天的时间)队列里没有消息就可能再也消费不了。针对这个问题我们反复调试多次。线下模拟，调整代码，但貌似还是没有找到原因。但是只要重启消费进程就又可以继续消费。 解决方案由于线上业务非常依赖kafka的消费，但一时半会也没有找到原因，所以最后只能想一个临时的替换方案： 基于重启就可以消费这个特点，我们在每次消费的时候都记下当前的时间点，当这个时间点在十分钟之内都没有更新我们就认为当前队列中没有消息了，就需要重启下消费进程。 既然是需要重启，由于目前还没有上分布式调度中心所以需要crontab来配合调度：每隔一分钟会调用一个shell脚本，该脚本会判断当前进程是否存在，如果存在则什么都不作，不存在则启动消费进程。 具体实现消费程序:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106/** * kafka消费 * * @author crossoverJie * @date 2017年6月19日 下午3:15:16 */public class KafkaMsgConsumer &#123; private static final Logger LOGGER = LoggerFactory.getLogger(KafkaMsgConsumer.class); private static final int CORE_POOL_SIZE = 4; private static final int MAXIMUM_POOL_SIZE = 4; private static final int BLOCKING_QUEUE_CAPACITY = 4000; private static final String KAFKA_CONFIG = "kafkaConfig"; private static final ExecutorService fixedThreadPool = new ThreadPoolExecutor(CORE_POOL_SIZE, MAXIMUM_POOL_SIZE, 0L, TimeUnit.MILLISECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(BLOCKING_QUEUE_CAPACITY)); //最后更新时间 private static AtomicLong LAST_MESSAGE_TIME = new AtomicLong(DateUtil.getLongTime()); private static MsgIterator iter = null; private static String topic;//主题名称 static &#123; Properties properties = new Properties(); String path = System.getProperty(KAFKA_CONFIG); checkArguments(!StringUtils.isBlank(path), "启动参数中没有配置kafka_easyframe_msg参数来指定kafka启动参数，请使用-DkafkaConfig=/path/fileName/easyframe-msg.properties"); try &#123; properties.load(new FileInputStream(new File(path))); &#125; catch (IOException e) &#123; LOGGER.error("IOException" ,e); &#125; EasyMsgConfig.setProperties(properties); &#125; private static void iteratorTopic() &#123; if (iter == null) &#123; iter = MsgUtil.consume(topic); &#125; long i = 0L; while (iter.hasNext()) &#123; i++; if (i % 10000 == 0) &#123; LOGGER.info("consume i:" + i); &#125; try &#123; String message = iter.next(); if (StringUtils.isEmpty(message)) &#123; continue; &#125; LAST_MESSAGE_TIME = new AtomicLong(DateUtil.getLongTime()); //处理消息 LOGGER.debug("msg = " + JSON.toJSONString(message)); &#125; catch (Exception e) &#123; LOGGER.error("KafkaMsgConsumer err:", e); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e1) &#123; LOGGER.error("Thread InterruptedException", e1); &#125; break; &#125; &#125; &#125; public static void main(String[] args) &#123; topic = System.getProperty("topic"); checkArguments(!StringUtils.isBlank(topic), "system property topic or log_path is must!"); while (true) &#123; try &#123; iteratorTopic(); &#125; catch (Exception e) &#123; MsgUtil.shutdownConsummer(); iter = null; LOGGER.error("KafkaMsgConsumer err:", e); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e1) &#123; LOGGER.error("Thread InterruptedException", e1); &#125; &#125; finally &#123; //此处关闭之后，由crontab每分钟检查一次，挂掉的话会重新拉起来 if (DateUtil.getLongTime() - LAST_MESSAGE_TIME.get() &gt; 10 * 60) &#123; //10分钟 fixedThreadPool.shutdown(); LOGGER.info("线程池是否关闭：" + fixedThreadPool.isShutdown()); try &#123; //当前线程阻塞10ms后，去检测线程池是否终止，终止则返回true while (!fixedThreadPool.awaitTermination(10, TimeUnit.MILLISECONDS)) &#123; LOGGER.info("检测线程池是否终止：" + fixedThreadPool.isTerminated()); &#125; &#125; catch (InterruptedException e) &#123; LOGGER.error("等待线程池关闭错误", e); &#125; LOGGER.info("线程池是否终止：" + fixedThreadPool.isTerminated()); LOGGER.info("in 10 min dont have data break"); break; &#125; &#125; &#125; LOGGER.info("app shutdown"); System.exit(0); &#125;&#125; 在线代码 需要配合以下这个shell脚本运行: 1234567891011121314151617181920#!/bin/sh#crontab# * * * * * sh /data/schedule/kafka/run-kafka-consumer.sh &gt;&gt;/data/schedule/kafka/run-sms-log.log# 如果进程存在就不启动a1=`ps -ef|grep &apos;KafkaMsgConsumer&apos;|grep -v grep|wc -l`if [ $a1 -gt 0 ];then echo &quot;======= `date +&apos;%Y-%m-%d %H:%M:%S&apos;` KafkaMsgConsumer is EXIT...======= &quot; exitfiLANG=&quot;zh_CN.UTF-8&quot;nohup /opt/java/jdk1.7.0_80/bin/java -d64 -Djava.security.egd=file:/dev/./urandom-Djava.ext.dirs=/opt/tomcat/webapps/ROOT/WEB-INF/lib-Dtopic=TOPIC_A-Dlogback.configurationFile=/data/schedule/kafka/logback.xml-DkafkaConfig=/opt/tomcat/iopconf/easyframe-msg.properties-classpath /opt/tomcat/webapps/ROOT/WEB-INF/classes com.crossoverJie.kafka.SMSMsgConsumer &gt;&gt; /data/schedule/kafka/smslog/kafka.log 2&gt;&amp;1 &amp;echo &quot;`date +&apos;%Y-%m-%d %H:%M:%S&apos;` KafkaMsgConsumer running....&quot; 在线代码 再配合crontab的调度:1* * * * * sh /data/schedule/kafka/run-kafka-consumer.sh &gt;&gt;/data/schedule/kafka/run-sms-log.log 即可。 总结虽说处理起来很简单，但依然是治标不治本，依赖的东西比较多(shell脚本，调度)。所以也问问各位有没有什么思路： 消费程序用的:https://github.com/linzhaoming/easyframe-msg 生产配置: 三台kafka、ZK组成的集群。 其中也有其他团队的消费程序在正常运行，应该和kafka的配置没有关系。 项目地址：https://github.com/crossoverJie/SSM.git 个人博客：http://crossoverjie.top。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Kafka</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sbc(四)应用限流]]></title>
    <url>%2F2017%2F08%2F11%2Fsbc4%2F</url>
    <content type="text"><![CDATA[前言 在一个高并发系统中对流量的把控是非常重要的，当巨大的流量直接请求到我们的服务器上没多久就可能造成接口不可用，不处理的话甚至会造成整个应用不可用。 比如最近就有个这样的需求，我作为客户端要向kafka生产数据，而kafka的消费者则再源源不断的消费数据，并将消费的数据全部请求到web服务器，虽说做了负载(有4台web服务器)但业务数据的量也是巨大的，每秒钟可能有上万条数据产生。如果生产者直接生产数据的话极有可能把web服务器拖垮。 对此就必须要做限流处理，每秒钟生产一定限额的数据到kafka，这样就能极大程度的保证web的正常运转。 其实不管处理何种场景，本质都是降低流量保证应用的高可用。 常见算法对于限流常见有两种算法: 漏桶算法 令牌桶算法 漏桶算法比较简单，就是将流量放入桶中，漏桶同时也按照一定的速率流出，如果流量过快的话就会溢出(漏桶并不会提高流出速率)。溢出的流量则直接丢弃。 如下图所示: 这种做法简单粗暴。 漏桶算法虽说简单，但却不能应对实际场景，比如突然暴增的流量。 这时就需要用到令牌桶算法: 令牌桶会以一个恒定的速率向固定容量大小桶中放入令牌，当有流量来时则取走一个或多个令牌。当桶中没有令牌则将当前请求丢弃或阻塞。 相比之下令牌桶可以应对一定的突发流量. RateLimiter实现对于令牌桶的代码实现，可以直接使用Guava包中的RateLimiter。 12345678910111213141516171819202122232425@Overridepublic BaseResponse&lt;UserResVO&gt; getUserByFeignBatch(@RequestBody UserReqVO userReqVO) &#123; //调用远程服务 OrderNoReqVO vo = new OrderNoReqVO() ; vo.setReqNo(userReqVO.getReqNo()); RateLimiter limiter = RateLimiter.create(2.0) ; //批量调用 for (int i = 0 ;i&lt; 10 ; i++)&#123; double acquire = limiter.acquire(); logger.debug("获取令牌成功!,消耗=" + acquire); BaseResponse&lt;OrderNoResVO&gt; orderNo = orderServiceClient.getOrderNo(vo); logger.debug("远程返回:"+JSON.toJSONString(orderNo)); &#125; UserRes userRes = new UserRes() ; userRes.setUserId(123); userRes.setUserName("张三"); userRes.setReqNo(userReqVO.getReqNo()); userRes.setCode(StatusEnum.SUCCESS.getCode()); userRes.setMessage("成功"); return userRes ;&#125; 详见此。 调用结果如下: 代码可以看出以每秒向桶中放入两个令牌，请求一次消耗一个令牌。所以每秒钟只能发送两个请求。按照图中的时间来看也确实如此(返回值是获取此令牌所消耗的时间，差不多也是每500ms一个)。 使用RateLimiter有几个值得注意的地方: 允许先消费，后付款，意思就是它可以来一个请求的时候一次性取走几个或者是剩下所有的令牌甚至多取，但是后面的请求就得为上一次请求买单，它需要等待桶中的令牌补齐之后才能继续获取令牌。 总结针对于单个应用的限流 RateLimiter 够用了，如果是分布式环境可以借助 Redis 来完成。 最近也怼了一个，可以参考。 项目：https://github.com/crossoverJie/springboot-cloud 博客：http://crossoverjie.top。]]></content>
      <categories>
        <category>sbc</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>SpringBoot</tag>
        <tag>SpringCloud</tag>
        <tag>RateLimiter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sbc(三)自定义Starter-SpringBoot重构去重插件]]></title>
    <url>%2F2017%2F08%2F01%2Fsbc3%2F</url>
    <content type="text"><![CDATA[前言之前看过SSM(十四) 基于annotation的http防重插件的朋友应该记得我后文说过之后要用SpringBoot来进行重构。 这次采用自定义的starter的方式来进行重构。 关于starter(起步依赖)其实在第一次使用SpringBoot的时候就已经用到了，比如其中的: 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; 我们只需要引入这一个依赖SpringBoot就会把相关的依赖都加入进来，自己也不需要再去担心各个版本之间的兼容问题(具体使用哪个版本由使用的spring-boot-starter-parent版本决定)，这些SpringBoot都已经帮我们做好了。 Spring自动化配置先加入需要的一些依赖: 123456789101112131415161718192021222324252627282930&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--aop相关--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--redis相关--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--配置相关--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt;&lt;!--通用依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;com.crossoverJie&lt;/groupId&gt; &lt;artifactId&gt;sbc-common&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 创建了CheckReqConf配置类用于在应用启动的时候自动配置。当然前提还得在resources目录下创建META-INF/spring.factories配置文件用于指向当前类，才能在应用启动时进行自动配置。 spring.factories: 12org.springframework.boot.autoconfigure.EnableAutoConfiguration=\com.crossoverJie.request.check.conf.CheckReqConf 使用条件化配置试着考虑下如下情况: 因为该插件是使用redis来存储请求信息的，外部就依赖了redis。如果使用了该插件的应用没有配置或者忘了配置redis的一些相关连接，那么在应用使用过程中肯定会出现写入redis异常。 如果异常没有控制好的话还有可能影响项目的正常运行。 那么怎么解决这个情况呢，可以使用Spring4.0新增的条件化配置来解决。 解决思路是:可以简单的通过判断应用中是否配置有spring.redis.hostredis连接，如果没有我们的这个配置就会被忽略掉。 实现代码: 1234567891011import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.Conditional;import org.springframework.context.annotation.Configuration;@Configuration@ComponentScan("com.crossoverJie.request.check.interceptor,com.crossoverJie.request.check.properties")//是否有redis配置的校验，如果没有配置则不会加载改配置，也就是当前插件并不会生效@Conditional(CheckReqCondition.class)public class CheckReqConf &#123;&#125; 具体校验的代码CheckReqCondition: 12345678910111213141516171819public class CheckReqCondition implements Condition &#123; private static Logger logger = LoggerFactory.getLogger(CheckReqCondition.class); @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata annotatedTypeMetadata) &#123; //如果没有加入redis配置的就返回false String property = context.getEnvironment().getProperty("spring.redis.host"); if (StringUtils.isEmpty(property))&#123; logger.warn("Need to configure redis!"); return false ; &#125;else &#123; return true; &#125; &#125;&#125; 只需要实现org.springframework.context.annotation.Condition并重写matches()方法,即可实现个人逻辑。 可以在使用了该依赖的配置文件中配置或者是不配置spring.redis.host这个配置,来看我们的切面类(ReqNoDrcAspect)中53行的日志是否有打印来判断是否生效。 这样只有在存在该key的情况下才会应用这个配置。 当然最好的做法是直接尝试读、写redis,看是否连接畅通来进行判断。 AOP切面最核心的其实就是这个切面类，里边主要逻辑和之前是一模一样的就不在多说,只是这里应用到了自定义配置。 切面类ReqNoDrcAspect: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172//切面注解@Aspect//扫描@Component//开启cglib代理@EnableAspectJAutoProxy(proxyTargetClass = true)public class ReqNoDrcAspect &#123; private static Logger logger = LoggerFactory.getLogger(ReqNoDrcAspect.class); @Autowired private CheckReqProperties properties ; private String prefixReq ; private long day ; @Autowired private RedisTemplate&lt;String, String&gt; redisTemplate; @PostConstruct public void init() throws Exception &#123; prefixReq = properties.getRedisKey() == null ? "reqNo" : properties.getRedisKey() ; day = properties.getRedisTimeout() == null ? 1L : properties.getRedisTimeout() ; logger.info("sbc-request-check init......"); logger.info(String.format("redis prefix is [%s],timeout is [%s]", prefixReq, day)); &#125; /** * 切面该注解 */ @Pointcut("@annotation(com.crossoverJie.request.check.anotation.CheckReqNo)") public void checkRepeat()&#123; &#125; @Before("checkRepeat()") public void before(JoinPoint joinPoint) throws Exception &#123; BaseRequest request = getBaseRequest(joinPoint); if(request != null)&#123; final String reqNo = request.getReqNo(); if(StringUtil.isEmpty(reqNo))&#123; throw new SBCException(StatusEnum.REPEAT_REQUEST); &#125;else&#123; try &#123; String tempReqNo = redisTemplate.opsForValue().get(prefixReq +reqNo); logger.debug("tempReqNo=" + tempReqNo); if((StringUtil.isEmpty(tempReqNo)))&#123; redisTemplate.opsForValue().set(prefixReq + reqNo, reqNo, day, TimeUnit.DAYS); &#125;else&#123; throw new SBCException("请求号重复,"+ prefixReq +"=" + reqNo); &#125; &#125; catch (RedisConnectionFailureException e)&#123; logger.error("redis操作异常",e); throw new SBCException("need redisService") ; &#125; &#125; &#125; &#125; public static BaseRequest getBaseRequest(JoinPoint joinPoint) throws Exception &#123; BaseRequest returnRequest = null; Object[] arguments = joinPoint.getArgs(); if(arguments != null &amp;&amp; arguments.length &gt; 0)&#123; returnRequest = (BaseRequest) arguments[0]; &#125; return returnRequest; &#125;&#125; 这里我们的写入rediskey的前缀和过期时间改为从CheckReqProperties类中读取: 12345678910111213141516171819202122232425262728293031@Component//定义配置前缀@ConfigurationProperties(prefix = "sbc.request.check")public class CheckReqProperties &#123; private String redisKey ;//写入redis中的前缀 private Long redisTimeout ;//redis的过期时间 默认是天 public String getRedisKey() &#123; return redisKey; &#125; public void setRedisKey(String redisKey) &#123; this.redisKey = redisKey; &#125; public Long getRedisTimeout() &#123; return redisTimeout; &#125; public void setRedisTimeout(Long redisTimeout) &#123; this.redisTimeout = redisTimeout; &#125; @Override public String toString() &#123; return "CheckReqProperties&#123;" + "redisKey='" + redisKey + '\'' + ", redisTimeout=" + redisTimeout + '&#125;'; &#125;&#125; 这样如果是需要很多配置的情况下就可以将内容封装到该对象中，方便维护和读取。 使用的时候只需要在自己应用的application.properties中加入 123# 去重配置sbc.request.check.redis-key = reqsbc.request.check.redis-timeout= 2 应用插件使用方法也和之前差不多(在sbc-order应用)： 加入依赖： 123456&lt;!--防重插件--&gt;&lt;dependency&gt; &lt;groupId&gt;com.crossoverJie.request.check&lt;/groupId&gt; &lt;artifactId&gt;request-check&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 在接口上加上注解: 12345678910111213141516171819202122@RestController@Api(value = "orderApi", description = "订单API", tags = &#123;"订单服务"&#125;)public class OrderController implements OrderService&#123; private final static Logger logger = LoggerFactory.getLogger(OrderController.class); @Override @CheckReqNo public BaseResponse&lt;OrderNoResVO&gt; getOrderNo(@RequestBody OrderNoReqVO orderNoReq) &#123; BaseResponse&lt;OrderNoResVO&gt; res = new BaseResponse(); res.setReqNo(orderNoReq.getReqNo()); if (null == orderNoReq.getAppId())&#123; throw new SBCException(StatusEnum.FAIL); &#125; OrderNoResVO orderNoRes = new OrderNoResVO() ; orderNoRes.setOrderId(DateUtil.getLongTime()); res.setCode(StatusEnum.SUCCESS.getCode()); res.setMessage(StatusEnum.SUCCESS.getMessage()); res.setDataBody(orderNoRes); return res ; &#125;&#125; 使用效果如下: 总结注意一点是spring.factories的路径不要搞错了,之前就是因为路径写错了，导致自动配置没有加载，AOP也就没有生效，排查了好久。。 项目：https://github.com/crossoverJie/springboot-cloud 博客：http://crossoverjie.top。]]></content>
      <categories>
        <category>sbc</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>重构</tag>
        <tag>AOP</tag>
        <tag>SpringBoot</tag>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sbc(二)高可用Eureka+声明式服务调用]]></title>
    <url>%2F2017%2F07%2F19%2Fsbc2%2F</url>
    <content type="text"><![CDATA[前言 上一篇简单入门了SpringBoot+SpringCloud 构建微服务。但只能算是一个demo级别的应用。这次会按照实际生产要求来搭建这套服务。 Swagger应用上次提到我们调用自己的http接口的时候采用的是PostMan来模拟请求，这个在平时调试时自然没有什么问题，但当我们需要和前端联调开发的时候效率就比较低了。 通常来说现在前后端分离的项目一般都是后端接口先行。 后端大大们先把接口定义好(入参和出参),前端大大们来确定是否满足要求，可以了之后后端才开始着手写实现，这样整体效率要高上许多。 但也会带来一个问题:在接口定义阶段频繁变更接口定义而没有一个文档或类似的东西来记录，那么双方的沟通加上前端的调试都是比较困难的。 基于这个需求网上有各种解决方案，比如阿里的rap就是一个不错的例子。 但是springCould为我们在提供了一种在开发springCloud项目下更方便的工具swagger。 实际效果如下: 配置swagger以sbc-order为例我将项目分为了三个模块: 123456789├── order // Order服务实现 │ ├── src/main├── order-api // 对内API│ ├── src/main├── order-client // 对外的clientAPI│ ├── src/main├── .gitignore ├── LICENSE ├── README.md 因为实现都写在order模块中，所以只需要在该模块中配置即可。 首先需要加入依赖，由于我在order模块中依赖了: 12345&lt;dependency&gt; &lt;groupId&gt;com.crossoverJie&lt;/groupId&gt; &lt;artifactId&gt;order-api&lt;/artifactId&gt; &lt;version&gt;$&#123;target.version&#125;&lt;/version&gt;&lt;/dependency&gt; order-api又依赖了： 12345678910&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;scope&gt;compile&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;scope&gt;compile&lt;/scope&gt;&lt;/dependency&gt; 接着需要配置一个SwaggerConfig 12345678910111213141516171819202122232425262728@Configuration@EnableSwagger2/** 是否打开swagger **/@ConditionalOnExpression(&quot;&apos;$&#123;swagger.enable&#125;&apos; == &apos;true&apos;&quot;)public class SwaggerConfig &#123; @Bean public Docket createRestApi() &#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors.basePackage(&quot;com.crossoverJie.sbcorder.controller&quot;)) .paths(PathSelectors.any()) .build(); &#125; private ApiInfo apiInfo() &#123; return new ApiInfoBuilder() .title(&quot;sbc order api&quot;) .description(&quot;sbc order api&quot;) .termsOfServiceUrl(&quot;http://crossoverJie.top&quot;) .contact(&quot;crossoverJie&quot;) .version(&quot;1.0.0&quot;) .build(); &#125; &#125; 其实就是配置swagger的一些基本信息。之后启动项目，在地址栏输入http://ip:port/swagger-ui.html#/即可进入。可以看到如上图所示的接口列表,点击如下图所示的参数例子即可进行接口调用。 自定义开关Swagger swagger的便利能给我们带来很多好处，但稍有不慎也可能出现问题。 比如如果在生产环境还能通过IP访问swagger的话那后果可是不堪设想的。所以我们需要灵活控制swagger的开关。 这点可以利用spring的条件化配置(条件化配置可以配置存在于应用中,一旦满足一些特定的条件时就取消这些配置)来实现这一功能: 1@ConditionalOnExpression("'$&#123;swagger.enable&#125;' == 'true'") 该注解的意思是给定的SpEL表达式计算结果为true时才会创建swagger的bean。 swagger.enable这个配置则是配置在application.properties中: 12# 是否打开swaggerswagger.enable = true 这样当我们在生产环境时只需要将该配置改为false即可。 ps:更多spring条件化配置: 123456789101112@ConditionalOnBean //配置了某个特定Bean@ConditionalOnMissingBean //没有配置特定的Bean@ConditionalOnClass //Classpath里有指定的类@ConditionalOnMissingClass //Classpath里缺少指定的类@ConditionalOnExpression //给定的Spring Expression Language(SpEL)表达式计算结果为true@ConditionalOnJava //Java的版本匹配特定值或者一个范围值@ConditionalOnJndi //参数中给定的JNDI位置必须存在一个，如果没有给参数，则要有JNDI InitialContext@ConditionalOnProperty //指定的配置属性要有一个明确的值@ConditionalOnResource //Classpath里有指定的资源@ConditionalOnWebApplication //这是一个Web应用程序@ConditionalOnNotWebApplication //这不是一个Web应用程序(参考SpringBoot实战) 高可用Eureka在上一篇中是用Eureka来做了服务注册中心，所有的生产者都往它注册服务，消费者又通过它来获取服务。 但是之前讲到的都是单节点，这在生产环境风险巨大，我们必须做到注册中心的高可用，搭建Eureka集群。 这里简单起见就搭建两个Eureka,思路则是这两个Eureka都把自己当成应用向对方注册，这样就可以构成一个高可用的服务注册中心。 在实际生产环节中会是每个注册中心一台服务器，为了演示起见，我就在本地启动两个注册中心，但是端口不一样。 首先需要在本地配置一个host: 1127.0.0.1 node1 node2 这样不论是访问node1还是node2都可以在本机调用的到(当然不配置host也可以，只是需要通过IP来访问，这样看起来不是那么明显)。 并给sbc-service新增了两个配置文件: application-node1.properties: 12345678910spring.application.name=sbc-serviceserver.port=8888eureka.instance.hostname=node1## 不向注册中心注册自己#eureka.client.register-with-eureka=false### 不需要检索服务#eureka.client.fetch-registry=falseeureka.client.serviceUrl.defaultZone=http://node2:9999/eureka/ application-node2.properties: 12345678910spring.application.name=sbc-serviceserver.port=9999eureka.instance.hostname=node2## 不向注册中心注册自己#eureka.client.register-with-eureka=false### 不需要检索服务#eureka.client.fetch-registry=falseeureka.client.serviceUrl.defaultZone=http://node1:8888/eureka/ 其中最重要的就是: 12eureka.client.serviceUrl.defaultZone=http://node2:9999/eureka/eureka.client.serviceUrl.defaultZone=http://node1:8888/eureka/ 两个应用互相注册。 启动的时候我们按照:java -jar sbc-service-1.0.0-SNAPSHOT.jar --spring.profiles.active=node1启动，就会按照传入的node1或者是node2去读取application-node1.properties,application-node2.properties这两个配置文件(配置文件必须按照application-{name}.properties的方式命名)。 分别启动两个注册中心可以看到以下: 可以看到两个注册中心以及互相注册了。在服务注册的时候只需要将两个地址都加上即可:eureka.client.serviceUrl.defaultZone=http://node1:8888/eureka/,http://node2:9999/eureka/ 在服务调用的时候可以尝试关闭其中一个，正常情况下依然是可以调用到服务的。 Feign声明式调用接下来谈谈服务调用，上次提到可以用ribbon来进行服务调用，但是明显很不方便，不如像之前rpc调用那样简单直接。 为此这次使用Feign来进行声明式调用，就像调用一个普通方法那样简单。 order-client片头说到我将应用分成了三个模块order、order-api、order-client，其中的client模块就是关键。 来看看其中的内容,只有一个接口: 12345678910@RequestMapping(value="/orderService")@FeignClient(name="sbc-order")@RibbonClientpublic interface OrderServiceClient extends OrderService&#123; @ApiOperation("获取订单号") @RequestMapping(value = "/getOrderNo", method = RequestMethod.POST) BaseResponse&lt;OrderNoResVO&gt; getOrderNo(@RequestBody OrderNoReqVO orderNoReq) ;&#125; @FeignClient这个注解要注意下，其中的name的是自己应用的应用名称，在application.properties中的spring.application.name配置。 其中继承了一个OrderService在order-api模块中，来看看order-api中的内容。 order-api其中也只有一个接口: 12345678910@RestController@Api("订单服务API")@RequestMapping(value = "/orderService")@Validatedpublic interface OrderService &#123; @ApiOperation("获取订单号") @RequestMapping(value = "/getOrderNo", method = RequestMethod.POST) BaseResponse&lt;OrderNoResVO&gt; getOrderNo(@RequestBody OrderNoReqVO orderNoReq) ;&#125; 这个接口有两个目的。 给真正的controller来进行实现。 给client接口进行继承。 类关系如下: 注解这些都没什么好说的，一看就懂。 orderorder则是具体接口实现的模块，就和平时写controller一样。来看看如何使用client进行声明式调用: 这次看看sbc-user这个项目，在里边调用了sbc-order的服务。其中的user模块依赖了order-client: 1234&lt;dependency&gt; &lt;groupId&gt;com.crossoverJie&lt;/groupId&gt; &lt;artifactId&gt;order-client&lt;/artifactId&gt;&lt;/dependency&gt; 具体调用: 12345678910111213141516171819202122@Autowiredprivate OrderServiceClient orderServiceClient ;@Overridepublic BaseResponse&lt;UserResVO&gt; getUserByFeign(@RequestBody UserReqVO userReq) &#123; //调用远程服务 OrderNoReqVO vo = new OrderNoReqVO() ; vo.setReqNo(userReq.getReqNo()); BaseResponse&lt;OrderNoResVO&gt; orderNo = orderServiceClient.getOrderNo(vo); logger.info("远程返回:"+JSON.toJSONString(orderNo)); UserRes userRes = new UserRes() ; userRes.setUserId(123); userRes.setUserName("张三"); userRes.setReqNo(userReq.getReqNo()); userRes.setCode(StatusEnum.SUCCESS.getCode()); userRes.setMessage("成功"); return userRes ;&#125; 可以看到只需要将order-client包中的Order服务注入进来即可。 在sbc-client的swagger中进行调用: 由于我并没传appId所以order服务返回的错误。 总结 当一个应用需要对外暴露接口时着需要按照以上方式提供一个client包更消费者使用。 其实应用本身也是需要做高可用的，和Eureka高可用一样，再不同的服务器上再启一个或多个服务并注册到Eureka集群中即可。 后续还会继续谈到zuul网关，容错，断路器等内容，欢迎拍砖讨论。 项目：https://github.com/crossoverJie/springboot-cloud 博客：http://crossoverjie.top。]]></content>
      <categories>
        <category>sbc</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>SpringBoot</tag>
        <tag>SpringCloud</tag>
        <tag>swagger</tag>
        <tag>Eureka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM(十五) 乐观锁与悲观锁的实际应用]]></title>
    <url>%2F2017%2F07%2F09%2FSSM15%2F</url>
    <content type="text"><![CDATA[前言随着互联网的兴起，现在三高(高可用、高性能、高并发)项目是越来越流行。 本次来谈谈高并发。首先假设一个业务场景：数据库中有一条数据，需要获取到当前的值，在当前值的基础上+10，然后再更新回去。如果此时有两个线程同时并发处理，第一个线程拿到数据是10，+10=20更新回去。第二个线程原本是要在第一个线程的基础上再+20=40,结果由于并发访问取到更新前的数据为10，+20=30。 这就是典型的存在中间状态，导致数据不正确。来看以下的例子： 并发所带来的问题和上文提到的类似，这里有一张price表，表结构如下： 1234567CREATE TABLE `price` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT &apos;主键&apos;, `total` decimal(12,2) DEFAULT &apos;0.00&apos; COMMENT &apos;总值&apos;, `front` decimal(12,2) DEFAULT &apos;0.00&apos; COMMENT &apos;消费前&apos;, `end` decimal(12,2) DEFAULT &apos;0.00&apos; COMMENT &apos;消费后&apos;, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=1268 DEFAULT CHARSET=utf8 我这里写了一个单测：就一个主线程，循环100次，每次把front的值减去10，再写入一次流水记录，正常情况是写入的每条记录都会每次减去10。 12345678910111213141516171819/** * 单线程消费 */@Testpublic void singleCounsumerTest1()&#123; for (int i=0 ;i&lt;100 ;i++)&#123; Price price = priceMapper.selectByPrimaryKey(1); int ron = 10 ; price.setFront(price.getFront().subtract(new BigDecimal(ron))); price.setEnd(price.getEnd().add(new BigDecimal(ron))); price.setTotal(price.getFront().add(price.getEnd())); priceMapper.updateByPrimaryKey(price) ; price.setId(null); priceMapper.insertSelective(price) ; &#125;&#125; 执行结果如下： 可以看到确实是每次都递减10。 但是如果是多线程的情况下会是如何呢： 我这里新建了一个PriceController 1234567891011121314151617181920212223242526272829303132333435363738394041424344 /** * 线程池 无锁 * @param redisContentReq * @return */@RequestMapping(value = "/threadPrice",method = RequestMethod.POST)@ResponseBodypublic BaseResponse&lt;NULLBody&gt; threadPrice(@RequestBody RedisContentReq redisContentReq)&#123; BaseResponse&lt;NULLBody&gt; response = new BaseResponse&lt;NULLBody&gt;() ; try &#123; for (int i=0 ;i&lt;10 ;i++)&#123; Thread t = new Thread(new Runnable() &#123; @Override public void run() &#123; Price price = priceMapper.selectByPrimaryKey(1); int ron = 10 ; price.setFront(price.getFront().subtract(new BigDecimal(ron))); price.setEnd(price.getEnd().add(new BigDecimal(ron))); priceMapper.updateByPrimaryKey(price) ; price.setId(null); priceMapper.insertSelective(price) ; &#125; &#125;); config.submit(t); &#125; response.setReqNo(redisContentReq.getReqNo()); response.setCode(StatusEnum.SUCCESS.getCode()); response.setMessage(StatusEnum.SUCCESS.getMessage()); &#125;catch (Exception e)&#123; logger.error("system error",e); response.setReqNo(response.getReqNo()); response.setCode(StatusEnum.FAIL.getCode()); response.setMessage(StatusEnum.FAIL.getMessage()); &#125; return response ;&#125; 其中为了节省资源使用了一个线程池: 1234567891011121314151617@Componentpublic class ThreadPoolConfig &#123; private static final int MAX_SIZE = 10 ; private static final int CORE_SIZE = 5; private static final int SECOND = 1000; private ThreadPoolExecutor executor ; public ThreadPoolConfig()&#123; executor = new ThreadPoolExecutor(CORE_SIZE,MAX_SIZE,SECOND, TimeUnit.MICROSECONDS,new LinkedBlockingQueue&lt;Runnable&gt;()) ; &#125; public void submit(Thread thread)&#123; executor.submit(thread) ; &#125;&#125; 关于线程池的使用今后会仔细探讨。这里就简单理解为有10个线程并发去处理上面单线程的逻辑，来看看结果怎么样： 会看到明显的数据错误，导致错误的原因自然就是有线程读取到了中间状态进行了错误的更新。 进而有了以下两种解决方案：悲观锁和乐观锁。 悲观锁简单理解下悲观锁：当一个事务锁定了一些数据之后，只有当当前锁提交了事务，释放了锁，其他事务才能获得锁并执行操作。 使用方式如下：首先要关闭MySQL的自动提交：set autocommit = 0; 123456bigen --开启事务select id, total, front, end from price where id=1 for update insert into price values(?,?,?,?,?)commit --提交事务 这里使用select for update的方式利用数据库开启了悲观锁，锁定了id=1的这条数据(注意:这里除非是使用了索引会启用行级锁，不然是会使用表锁，将整张表都锁住。)。之后使用commit提交事务并释放锁，这样下一个线程过来拿到的就是正确的数据。 悲观锁一般是用于并发不是很高，并且不允许脏读等情况。但是对数据库资源消耗较大。 乐观锁那么有没有性能好，支持的并发也更多的方式呢？ 那就是乐观锁。 乐观锁是首先假设数据冲突很少，只有在数据提交修改的时候才进行校验，如果冲突了则不会进行更新。 通常的实现方式增加一个version字段，为每一条数据加上版本。每次更新的时候version+1，并且更新时候带上版本号。实现方式如下： 新建了一张price_version表： 12345678CREATE TABLE `price_version` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT &apos;主键&apos;, `total` decimal(12,2) DEFAULT &apos;0.00&apos; COMMENT &apos;总值&apos;, `front` decimal(12,2) DEFAULT &apos;0.00&apos; COMMENT &apos;消费前&apos;, `end` decimal(12,2) DEFAULT &apos;0.00&apos; COMMENT &apos;消费后&apos;, `version` int(11) DEFAULT &apos;0&apos; COMMENT &apos;并发版本控制&apos;, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=1268 DEFAULT CHARSET=utf8 更新数据的SQL： 1234567&lt;update id="updateByVersion" parameterType="com.crossoverJie.pojo.PriceVersion"&gt; UPDATE price_version SET front = #&#123;front,jdbcType=DECIMAL&#125;, version= version + 1 WHERE id = #&#123;id,jdbcType=INTEGER&#125; AND version = #&#123;version,jdbcType=INTEGER&#125; &lt;/update&gt; 调用方式： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * 线程池，乐观锁 * @param redisContentReq * @return */@RequestMapping(value = "/threadPriceVersion",method = RequestMethod.POST)@ResponseBodypublic BaseResponse&lt;NULLBody&gt; threadPriceVersion(@RequestBody RedisContentReq redisContentReq)&#123; BaseResponse&lt;NULLBody&gt; response = new BaseResponse&lt;NULLBody&gt;() ; try &#123; for (int i=0 ;i&lt;3 ;i++)&#123; Thread t = new Thread(new Runnable() &#123; @Override public void run() &#123; PriceVersion priceVersion = priceVersionMapper.selectByPrimaryKey(1); int ron = new Random().nextInt(20); logger.info("本次消费="+ron); priceVersion.setFront(new BigDecimal(ron)); int count = priceVersionMapper.updateByVersion(priceVersion); if (count == 0)&#123; logger.error("更新失败"); &#125;else &#123; logger.info("更新成功"); &#125; &#125; &#125;); config.submit(t); &#125; response.setReqNo(redisContentReq.getReqNo()); response.setCode(StatusEnum.SUCCESS.getCode()); response.setMessage(StatusEnum.SUCCESS.getMessage()); &#125;catch (Exception e)&#123; logger.error("system error",e); response.setReqNo(response.getReqNo()); response.setCode(StatusEnum.FAIL.getCode()); response.setMessage(StatusEnum.FAIL.getMessage()); &#125; return response ;&#125; 处理逻辑：开了三个线程生成了20以内的随机数更新到front字段。 当调用该接口时日志如下： 可以看到线程1、4、5分别生成了15，2，11三个随机数。最后线程4、5都更新失败了，只有线程1更新成功了。 查看数据库： 发现也确实是更新的15。 乐观锁在实际应用相对较多，它可以提供更好的并发访问，并且数据库开销较少，但是有可能存在脏读的情况。 总结以上两种各有优劣，大家可以根据具体的业务场景来判断具体使用哪种方式来保证数据的一致性。 项目地址：https://github.com/crossoverJie/SSM.git 个人博客：http://crossoverjie.top。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>lock</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sbc(一)SpringBoot+SpringCloud初探]]></title>
    <url>%2F2017%2F06%2F15%2Fsbc1%2F</url>
    <content type="text"><![CDATA[前言 有看过我之前的SSM系列的朋友应该有一点印象是非常深刻的。 那就是需要配置的配置文件非常多，什么Spring、mybatis、redis、mq之类的配置文件非常多，并且还存在各种版本，甚至有些版本还互不兼容。其中有很多可能就是刚开始整合的时候需要配置，之后压根就不会再动了。 鉴于此，Spring又推出了又一神器SpringBoot. 它可以让我们更加快速的开发Spring应用，甚至做到了开箱即用。由于在实际开发中我们使用SpringBoot+SpringCloud进行了一段时间的持续交付，并在生产环境得到了验证，其中也有不少踩坑的地方，借此机会和大家分享交流一下。 本篇我们首先会用利用SpringBoot构建出一个简单的REST API.接着会创建另一个SpringBoot项目，基于SpringCloud部署，并在两个应用之间进行调用。 使用SpringBoot构建REST API我们可以使用Spring官方提供的初始化工具帮我们生成一个基础项目：http://start.spring.io/,如下图所示： 填入相应信息即可。由于只是要实现REST API所以这里只需要引用web依赖即可。 将生成好的项目导入IDE(我使用的是idea)中,目录结构如下; 其中的SbcUserApplication是整个应用的入口。 resource/application.properties这里是存放整个应用的配置文件。 其中的static和templates是存放静态资源以及前端模板的地方，由于我们采用了前后端分离，所以这些目录基本上用不上了。 通过运行SbcUserApplication类的main方法可以启动SpringBoot项目。 接着在PostMan中进行调用，看到以下结果表明启动成功了： 这样一看是不是要比之前用Spring+SpringMVC来整合要方便快捷很多。 创建另一个SpringBoot项目当我们的项目采用微服务构建之后自然就会被拆分成N多个独立的应用。比如上文中的sbc-user用于用户管理。这里再创建一个sbc-order用户生成订单。 为了方便之后的代码复用，我将common包中的一些枚举值、工具类单独提到sbc-common应用中了，这样有其他应用要使用这些基础类直接引入这个依赖即可。 12345&lt;dependency&gt; &lt;groupId&gt;com.crossoverJie&lt;/groupId&gt; &lt;artifactId&gt;sbc-common&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 创建步骤和上文差不多，这里就不再赘述了。其中有一个order/getOrderNo的服务，调用结果如下： 之后会利用SpringCloud来将两个服务关联起来，并可以互相调用。 使用SpringCloud进行分布式调用搭建eureka注册中心既然是要搭建微服务那自然少不了注册中心了，之前讲的dubbo采用的是zookeeper作为注册中心，SpringCloud则采用的是Netflix Eureka来做服务的注册与发现。 新建一个项目sbc-service,目录结构如下： 核心的pom.xml 123456789101112131415161718192021222324&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;1.2.1&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Brixton.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 非常easy，只需要引入eureka的依赖即可。然后在入口类加入一个注解@EnableEurekaServer，即可将该项目作为服务注册中心： 12345678910111213141516171819package com.crossoverJie.service;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;@EnableEurekaServer@SpringBootApplicationpublic class EurekaApplication &#123; private final static Logger logger = LoggerFactory.getLogger(EurekaApplication.class); public static void main(String[] args) &#123; SpringApplication.run(EurekaApplication.class, args); logger.info("SpringBoot Start Success"); &#125;&#125; 接着修改配置文件application.properties: 123456789server.port=8888# 不向注册中心注册自己eureka.client.register-with-eureka=false# 不需要检索服务eureka.client.fetch-registry=falseeureka.client.serviceUrl.defaultZone=http://localhost:$&#123;server.port&#125;/eureka/ 配置一下端口以及注册中心的地址即可。然后按照正常启动springBoot项目一样启动即可。 在地址栏输入http://localhost:8888看到一下界面： 当然现在在注册中心还看不到任何一个应用，下面需要将上文的sbc-user,sbc-order注册进来。 向注册中心注册服务提供者只需要在application.properties配置文件中加上注册中心的配置： 1eureka.client.serviceUrl.defaultZone=http://localhost:8888/eureka/ 并在sbc-order的主类中加入@EnableDiscoveryClient注解即可完成注册服务。 启动注册中心以及应用，在注册中心看到一下界面则成功注册: 消费注册中心的服务服务是注册上去了，自然是需要消费了，这里就简单模拟了在调用http://localhost:8080/user/getUser这个接口的时候getUser接口会去调用order的getOrder服务。 这里会用到另一个依赖: 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt;&lt;/dependency&gt; 他可以帮我们做到客户端负载，具体使用如下： 加入ribbon依赖。 在主类中开启@LoadBalanced客户端负载。 创建restTemplate类的实例 12345@Bean @LoadBalanced public RestTemplate restTemplate() &#123; return new RestTemplate(); &#125; 使用restTemplate调用远程服务: 123456789101112131415161718192021222324@Autowired private RestTemplate restTemplate; @RequestMapping(value = "/getUser",method = RequestMethod.POST) public UserRes getUser(@RequestBody UserReq userReq)&#123; OrderNoReq req = new OrderNoReq() ; req.setReqNo("1213"); //调用远程服务 ResponseEntity&lt;Object&gt; res = restTemplate.postForEntity("http://sbc-order/order/getOrderNo", req, Object.class); logger.info("res="+JSON.toJSONString(res)); logger.debug("入参="+ JSON.toJSONString(userReq)); UserRes userRes = new UserRes() ; userRes.setUserId(123); userRes.setUserName("张三"); userRes.setReqNo(userReq.getReqNo()); userRes.setCode(StatusEnum.SUCCESS.getCode()); userRes.setMessage("成功"); return userRes ; &#125; 由于我的远程接口是post,所以使用了postForEntity()方法，如果是get就换成getForEntity()即可。 注意这里是使用应用名sbc-order(配置于sbc-order的application.properties中)来进行调用的，并不是一个IP地址。 启动注册中心、两个应用。用PostMan调用getUser接口时控制台打印: 12017-06-27 00:18:04.534 INFO 63252 --- [nio-8080-exec-3] c.c.sbcuser.controller.UserController : res=&#123;&quot;body&quot;:&#123;&quot;code&quot;:&quot;4000&quot;,&quot;message&quot;:&quot;appID不能为空&quot;,&quot;reqNo&quot;:&quot;1213&quot;&#125;,&quot;headers&quot;:&#123;&quot;X-Application-Context&quot;:[&quot;sbc-order:8181&quot;],&quot;Content-Type&quot;:[&quot;application/xml;charset=UTF-8&quot;],&quot;Transfer-Encoding&quot;:[&quot;chunked&quot;],&quot;Date&quot;:[&quot;Mon, 26 Jun 2017 16:18:04 GMT&quot;]&#125;,&quot;statusCode&quot;:&quot;OK&quot;,&quot;statusCodeValue&quot;:200&#125; 由于并没有传递appId所以order服务返回了一个错误，也正说明是远程调用到了该服务。 总结 ps:这里只是简单使用了ribbon来进行服务调用，但在实际的开发中还是比较少的使用这种方式来调用远程服务，而是使用Feign进行声明式调用，可以简化客户端代码，具体使用方式请持续关注。 本次算是springBoot+springCloud的入门，还有很多东西没有讲到，之后我将会根据实际使用的一些经验继续分享SpringCloud这个新兴框架。 项目：https://github.com/crossoverJie/springboot-cloud 博客：http://crossoverjie.top。]]></content>
      <categories>
        <category>sbc</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>SpringBoot</tag>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM(十四) 基于annotation的http防重插件]]></title>
    <url>%2F2017%2F05%2F24%2FSSM14%2F</url>
    <content type="text"><![CDATA[前言针对于我们现在常用的RESTful API通常我们需要对请求进行唯一标识，也就是每次都要带上一个请求号,如reqNO。 对于入库这种操作数据库的请求我们一般要保证他的唯一性，一个请求号通常只能用一次，所以需要我们对这种请求加上校验机制。 该需求的实现思路是通过自定义annotation，只给需要进行校验的接口加上注解。然后通过切面使用了注解的接口将每次请求号存进Redis，每次都进行判断是否存在这个请求号即可。 来看下加上本次插件的实际效果： 自定义注解首先我们要自定义一个注解： 1234567@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface CheckReqNo &#123; String desc() default "";&#125; (ps:这里并不过多的讲解注解相关的知识)。 首先使用@interface来声明一个注解。接着利用Java为我们提供的三个元注解来定义CheckReqNo注解。 其中@Target表明这个注解被用于什么地方，使用ElementType.METHOD表明被应用到方法上，还有一些其他值可以查看java.lang.annotation.ElementType这个枚举类型。 @Retention注解表明我们的注解在什么范围内有效，这里配置的RetentionPolicy.RUNTIME表明在运行时可以通过反射来获取。 @Documented看字面意思应该也能猜到是用于生成JavaDoc文档的。 其中定义了一个desc()的方法其实并没有用到，但如果需要在使用注解的时候需要自定义一些filed(域)的需求可以按照这样的方式写到这里，通过反射都可以获取到具体的值。如：@CheckReqNo(desc = &quot;abc&quot;)就可以获取到&quot;abc&quot;的值。 切面注解按照之前的想法是在对所有使用了该注解的方法进行切面：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364@Aspect@Componentpublic class ReqNoDrcAspect &#123; private static Logger logger = LoggerFactory.getLogger(ReqNoDrcAspect.class); @Value("$&#123;redis.prefixReq:reqNo&#125;") private String prefixReq ; @Value("$&#123;redis.day:1&#125;") private long day ; @Autowired private RedisTemplate&lt;String, String&gt; redisTemplate; @PostConstruct public void init() throws Exception &#123; logger.info("SSM-REQUEST-CHECK init......"); &#125; @Pointcut("@annotation(com.crossoverJie.request.anotation.CheckReqNo)") public void checkRepeat()&#123; &#125; @Before("checkRepeat()") public void before(JoinPoint joinPoint) throws Exception &#123; BaseRequest request; request = getBaseRequest(joinPoint); if(request != null)&#123; final String reqNo = request.getReqNo(); if(StringUtil.isEmpty(reqNo))&#123; throw new RuntimeException("reqNo不能为空"); &#125;else&#123; try &#123; String tempReqNo = redisTemplate.opsForValue().get(prefixReq +reqNo); logger.debug("tempReqNo="+tempReqNo); if((StringUtil.isEmpty(tempReqNo)))&#123; redisTemplate.opsForValue().set(prefixReq + reqNo, reqNo, day, TimeUnit.DAYS); &#125;else&#123; throw new RuntimeException("请求号重复,reqNo="+reqNo); &#125; &#125; catch (RedisConnectionFailureException e)&#123; logger.error("redis操作异常",e); throw new RuntimeException("need redisService") ; &#125; &#125; &#125; &#125; public static BaseRequest getBaseRequest(JoinPoint joinPoint) throws Exception &#123; BaseRequest returnRequest = null; Object[] arguments = joinPoint.getArgs(); if(arguments != null &amp;&amp; arguments.length &gt; 0)&#123; returnRequest = (BaseRequest) arguments[0]; &#125; return returnRequest; &#125;&#125; 使用@Aspect来定义了一个切面。其中prefixReq,day域可以自定义缓存请求号时的key前缀以及缓存的时间。 最关键的一点是用@Pointcut(&quot;@annotation(com.crossoverJie.request.anotation.CheckReqNo)&quot;)定义了一个切入点，这样所有使用@CheckReqNo的注解都会被拦截。 接下来的逻辑就比较简单了，在每次请求之前进行拦截。 先去Redis中查看这个请求号(ps:反射获取)是否存在，如果不存在则通过并将本次的请求号缓存起来。如果存在则抛出异常。 使用注解可以在jdbc.properties配置文件中自定义前缀和缓存时间 1234#redis前缀redis.prefixReq=reqNo#redis缓存时间 默认单位为天redis.day=1 不定义也可以，会使用默认值。 由于该注解是需要加到controller层,因此我们得使用CGLIB代理。这里有一个坑，需要将开启CGLIB的配置配置到我们web.xml中的 1234567891011&lt;!-- Spring MVC servlet --&gt; &lt;servlet&gt; &lt;servlet-name&gt;SpringMVC&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring-mvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;async-supported&gt;true&lt;/async-supported&gt; &lt;/servlet&gt; 这里所定义的spring-mvc.xml文件中，不然springMVC所在的子容器是无法被父容器所加载的。 使用实例： 1234567891011121314151617181920212223@CheckReqNo@RequestMapping(value = "/createRedisContent",method = RequestMethod.POST)@ResponseBodypublic BaseResponse&lt;NULLBody&gt; createRedisContent(@RequestBody RedisContentReq redisContentReq)&#123; BaseResponse&lt;NULLBody&gt; response = new BaseResponse&lt;NULLBody&gt;() ; Rediscontent rediscontent = new Rediscontent() ; try &#123; CommonUtil.setLogValueModelToModel(redisContentReq,rediscontent); rediscontentMapper.insertSelective(rediscontent) ; response.setReqNo(redisContentReq.getReqNo()); response.setCode(StatusEnum.SUCCESS.getCode()); response.setMessage(StatusEnum.SUCCESS.getMessage()); &#125;catch (Exception e)&#123; logger.error("system error",e); response.setReqNo(response.getReqNo()); response.setCode(StatusEnum.FAIL.getCode()); response.setMessage(StatusEnum.FAIL.getMessage()); &#125; return response ;&#125; 统一异常controller1234567891011121314151617181920212223242526272829/** * * ClassName: ErrorController &lt;br/&gt; * Function: 错误异常统一处理. &lt;br/&gt; * @author crossoverJie * @version * @since JDK 1.7 */@ControllerAdvicepublic class ErrorController &#123; private Logger logger = LoggerFactory.getLogger(this.getClass()); @ExceptionHandler(Exception.class) @ResponseStatus(HttpStatus.OK) @ResponseBody public Object processUnauthenticatedException(NativeWebRequest request, Exception e) &#123; logger.error("请求出现异常:", e); BaseResponse&lt;NULLBody&gt; response = new BaseResponse&lt;NULLBody&gt;(); response.setCode(StatusEnum.FAIL.getCode()); if (e instanceof RuntimeException)&#123; response.setMessage(e.getMessage()); &#125; else &#123; response.setMessage(StatusEnum.FAIL.getMessage()); &#125; return response ; &#125;&#125; 这样当controller层出现异常之后都会进入这里进行统一的返回。 总结至此整个插件的流程已经全部OK，从中可以看出Spring AOP在实际开发中的各种好处。之前的几篇文章也有应用到： 在JavaWeb应用中使用Redis 动态切换数据源 不知不觉这个小白入门的SSM系列已经更新了14篇了，在GitHub也有了500多颗星了，期间也和不少朋友有过交流、探讨，感谢大家的支持。 接下来可能不太会更新这个系列了，由于博主现在所在的项目组采用的是目前比较流行的SpringBoot+SpringCloud和Docker的方式来进行架构的，所以之后的重心肯定会移到这方面，用过SpringBoot之后相信大家肯定也回不去了。 所以之后我会继续更新SpringBoot+SpringCloud相关的文章，欢迎持续关注，持续拍砖(ps:这个插件也会用springBoot重写一遍) 插件地址：https://github.com/crossoverJie/SSM-REQUEST-CHECK.git 项目地址：https://github.com/crossoverJie/SSM.git 个人博客地址：http://crossoverjie.top。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>HTTP</tag>
        <tag>annotation</tag>
        <tag>AOP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM(十三) 将dubbo暴露出HTTP服务]]></title>
    <url>%2F2017%2F05%2F07%2FSSM13%2F</url>
    <content type="text"><![CDATA[前言通常来说一个dubbo服务都是对内给内部调用的，但也有可能一个服务就是需要提供给外部使用，并且还不能有使用语言的局限性。 比较标准的做法是对外的服务我们统一提供一个openAPI，这样的调用方需要按照标准提供相应的appID以及密钥来进行验签才能使用。这样固然是比较规范和安全，但复杂度也不亚于开发一个单独的系统了。 这里所讲到的没有那么复杂，就只是把一个不需要各种权限检验的dubbo服务对外提供为HTTP服务。 调用示例: 准备工作以下是本文所涉及到的一些知识点： Spring相关知识。 Java反射相关知识。 SpringMVC相关知识。 其实思路很简单，就是利用SpringMVC提供一个HTTP接口。在该接口中通过入参进行反射找到具体的dubbo服务实现进行调用。 HttpProviderConf配置类首先需要定义一个HttpProviderConf类用于保存声明需要对外提供服务的包名，毕竟我们反射时需要用到一个类的全限定名： 12345678public class HttpProviderConf &#123; /** * 提供http访问的包 */ private List&lt;String&gt; usePackage ; //省略getter setter方法&#125; 就只有一个usePackage成员变量，用于存放需要包名。至于用List的原因是允许有多个。 请求响应入参、出参HttpRequest入参123456public class HttpRequest &#123; private String param ;//入参 private String service ;//请求service private String method ;//请求方法 //省略getter setter方法&#125; 其中param是用于存放真正调用dubbo服务时的入参，传入json在调用的时候解析成具体的参数对象。 service存放dubbo服务声明的interface API的包名。 method则是真正调用的方法名称。 HttpResponse 响应1234567891011public class HttpResponse implements Serializable&#123; private static final long serialVersionUID = -552828440320737814L; private boolean success;//成功标志 private String code;//信息码 private String description;//描述 //省略getter setter方法&#125; 这里只是封装了常用的HTTP服务的响应数据。 暴露服务controller最重要的则是controller里的实现代码了。 先贴代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155@Controller@RequestMapping("/dubboAPI")public class DubboController implements ApplicationContextAware&#123; private final static Logger logger = LoggerFactory.getLogger(DubboController.class); @Autowired private HttpProviderConf httpProviderConf; //缓存作用的map private final Map&lt;String, Class&lt;?&gt;&gt; cacheMap = new HashMap&lt;String, Class&lt;?&gt;&gt;(); protected ApplicationContext applicationContext; @ResponseBody @RequestMapping(value = "/&#123;service&#125;/&#123;method&#125;",method = RequestMethod.POST) public String api(HttpRequest httpRequest, HttpServletRequest request, @PathVariable String service, @PathVariable String method) &#123; logger.debug("ip:&#123;&#125;-httpRequest:&#123;&#125;",getIP(request), JSON.toJSONString(httpRequest)); String invoke = invoke(httpRequest, service, method); logger.debug("callback :"+invoke) ; return invoke ; &#125; private String invoke(HttpRequest httpRequest,String service,String method)&#123; httpRequest.setService(service); httpRequest.setMethod(method); HttpResponse response = new HttpResponse() ; logger.debug("input param:"+JSON.toJSONString(httpRequest)); if (!CollectionUtils.isEmpty(httpProviderConf.getUsePackage()))&#123; boolean isPac = false ; for (String pac : httpProviderConf.getUsePackage()) &#123; if (service.startsWith(pac))&#123; isPac = true ; break ; &#125; &#125; if (!isPac)&#123; //调用的是未经配置的包 logger.error("service is not correct,service="+service); response.setCode("2"); response.setSuccess(false); response.setDescription("service is not correct,service="+service); &#125; &#125; try &#123; Class&lt;?&gt; serviceCla = cacheMap.get(service); if (serviceCla == null)&#123; serviceCla = Class.forName(service) ; logger.debug("serviceCla:"+JSON.toJSONString(serviceCla)); //设置缓存 cacheMap.put(service,serviceCla) ; &#125; Method[] methods = serviceCla.getMethods(); Method targetMethod = null ; for (Method m : methods) &#123; if (m.getName().equals(method))&#123; targetMethod = m ; break ; &#125; &#125; if (method == null)&#123; logger.error("method is not correct,method="+method); response.setCode("2"); response.setSuccess(false); response.setDescription("method is not correct,method="+method); &#125; Object bean = this.applicationContext.getBean(serviceCla); Object result = null ; Class&lt;?&gt;[] parameterTypes = targetMethod.getParameterTypes(); if (parameterTypes.length == 0)&#123; //没有参数 result = targetMethod.invoke(bean); &#125;else if (parameterTypes.length == 1)&#123; Object json = JSON.parseObject(httpRequest.getParam(), parameterTypes[0]); result = targetMethod.invoke(bean,json) ; &#125;else &#123; logger.error("Can only have one parameter"); response.setSuccess(false); response.setCode("2"); response.setDescription("Can only have one parameter"); &#125; return JSON.toJSONString(result) ; &#125;catch (ClassNotFoundException e)&#123; logger.error("class not found",e); response.setSuccess(false); response.setCode("2"); response.setDescription("class not found"); &#125; catch (InvocationTargetException e) &#123; logger.error("InvocationTargetException",e); response.setSuccess(false); response.setCode("2"); response.setDescription("InvocationTargetException"); &#125; catch (IllegalAccessException e) &#123; logger.error("IllegalAccessException",e); response.setSuccess(false); response.setCode("2"); response.setDescription("IllegalAccessException"); &#125; return JSON.toJSONString(response) ; &#125; /** * 获取IP * @param request * @return */ private String getIP(HttpServletRequest request) &#123; if (request == null) return null; String s = request.getHeader("X-Forwarded-For"); if (s == null || s.length() == 0 || "unknown".equalsIgnoreCase(s)) &#123; s = request.getHeader("Proxy-Client-IP"); &#125; if (s == null || s.length() == 0 || "unknown".equalsIgnoreCase(s)) &#123; s = request.getHeader("WL-Proxy-Client-IP"); &#125; if (s == null || s.length() == 0 || "unknown".equalsIgnoreCase(s)) &#123; s = request.getHeader("HTTP_CLIENT_IP"); &#125; if (s == null || s.length() == 0 || "unknown".equalsIgnoreCase(s)) &#123; s = request.getHeader("HTTP_X_FORWARDED_FOR"); &#125; if (s == null || s.length() == 0 || "unknown".equalsIgnoreCase(s)) &#123; s = request.getRemoteAddr(); &#125; if ("127.0.0.1".equals(s) || "0:0:0:0:0:0:0:1".equals(s)) try &#123; s = InetAddress.getLocalHost().getHostAddress(); &#125; catch (UnknownHostException unknownhostexception) &#123; return ""; &#125; return s; &#125; public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; this.applicationContext = applicationContext; &#125; 先一步一步的看： 首先是定义了一个DubboController,并使用了SpringMVC的注解对外暴露HTTP服务。 实现了org.springframework.context.ApplicationContextAware类，实现了setApplicationContext()方法用于初始化Spring上下文对象，在之后可以获取到容器里的相应对象。 核心的invoke()方法。 调用时：http://127.0.0.1:8080/SSM-SERVICE/dubboAPI/com.crossoverJie.api.UserInfoApi/getUserInfo。 具体如上文的调用实例。先将com.crossoverJie.api.UserInfoApi、getUserInfo赋值到httpRequest入参中。 判断传入的包是否是对外提供的。如下配置：1234567891011&lt;!--dubbo服务暴露为http服务--&gt;&lt;bean class="com.crossoverJie.dubbo.http.conf.HttpProviderConf"&gt; &lt;property name="usePackage"&gt; &lt;list&gt; &lt;!--需要暴露服务的接口包名，可多个--&gt; &lt;value&gt;com.crossoverJie.api&lt;/value&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt;&lt;!--扫描暴露包--&gt;&lt;context:component-scan base-package="com.crossoverJie.dubbo.http"/&gt; 其中的com.crossoverJie.api就是自己需要暴露的包名，可以多个。 接着在缓存map中取出反射获取到的接口类类型，如果获取不到则通过反射获取，并将值设置到缓存map中，这样不用每次都反射获取，可以节省系统开销(反射很耗系统资源)。 接着也是判断该接口中是否有传入的getUserInfo方法。 取出该方法的参数列表，如果没有参数则直接调用。 如果有参数，判断个数。这里最多只运行一个参数。也就是说在真正的dubbo调用的时候只能传递一个BO类型，具体的参数列表可以写到BO中。因为如果有多个在进行json解析的时候是无法赋值到两个参数对象中去的。 之后进行调用，将调用返回的数据进行返回即可。 总结通常来说这样提供的HTTP接口再实际中用的不多，但是很方便调试。 比如写了一个dubbo的查询接口，在测试环境或者是预发布环境中就可以直接通过HTTP请求的方式进行简单的测试，或者就是查询数据。比在Java中写单测来测试或查询快的很多。 安装1git clone https://github.com/crossoverJie/SSM-DUBBO-HTTP.git 1cd SSM-DUBBO-HTTP 1mvn clean 1mvn install 使用12345&lt;dependency&gt; &lt;groupId&gt;com.crossoverJie&lt;/groupId&gt; &lt;artifactId&gt;SSM-HTTP-PROVIDER&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt; spring配置1234567891011&lt;!--dubbo服务暴露为http服务--&gt;&lt;bean class="com.crossoverJie.dubbo.http.conf.HttpProviderConf"&gt; &lt;property name="usePackage"&gt; &lt;list&gt; &lt;!--需要暴露服务的接口包名，可多个--&gt; &lt;value&gt;com.crossoverJie.api&lt;/value&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt;&lt;!--扫描暴露包--&gt;&lt;context:component-scan base-package="com.crossoverJie.dubbo.http"/&gt; 插件地址：https://github.com/crossoverJie/SSM-DUBBO-HTTP 项目地址：https://github.com/crossoverJie/SSM.git 个人博客地址：http://crossoverjie.top。 GitHub地址：https://github.com/crossoverJie。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>dubbo</tag>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[科普-为自己的博客免费加上小绿锁]]></title>
    <url>%2F2017%2F05%2F07%2Fhttps%2F</url>
    <content type="text"><![CDATA[在如今的HTTPS大当其道的情况下自己的博客要是还没有用上。作为互联网的螺丝钉(码农)岂不是很没面子。 使用CLOUDFLARE这里使用CLOUDFLARE来提供HTTPS服务。 在其官网进行注册，按照提示添加好自己的域名即可。 之后需要在自己域名的提供商处修改DNS服务器，我是在万网购买的修改后如下图：其中的DNS服务器地址由CLOUDFLARE是提供的。修改完成之后通常需要等待一段时间才能生效。 接着在CLOUDFLARE配置DNS解析：点击CLOUDFLARE顶部的DNS进行如我上图中的配置，和之前的配置没有什么区别。 等待一段时间之后发现使用HTTP,HTTPS都能访问，但是最好还是能在访问HTTP的时候能强制跳转到HTTPS. 在CLOUDFLARE菜单栏点击page-rules之后新建一个page rule：这样整个网站的请求都会强制到请求到HTTPS. 主题配置由于我才用的是Hexo中的Next主题，其中配置了CNZZ站长统计。其中配置的CNZZ统计JS是才用的HTTP。导致在首页的时候chrome一直提示感叹号。修改站点themes/next/layout/_scripts/third-party/analytics目录下的cnzz-analytics.swig文件1234567&#123;% if theme.cnzz_siteid %&#125; &lt;div style=&quot;display: none;&quot;&gt; &lt;script src=&quot;https://s6.cnzz.com/stat.php?id=&#123;&#123; theme.cnzz_siteid &#125;&#125;&amp;web_id=&#123;&#123; theme.cnzz_siteid &#125;&#125;&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt; &lt;/div&gt;&#123;% endif %&#125; 之后再进行构建的时候就会使用HTTPS. 值得注意一点的是之后文章中所使用的图片都要用HTTPS的地址了，不然chrome会提示感叹号。 个人博客地址：http://crossoverjie.top。 GitHub地址：https://github.com/crossoverJie。]]></content>
      <categories>
        <category>科普</category>
      </categories>
      <tags>
        <tag>HTTP</tag>
        <tag>HTTPS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM(十二) dubbo日志插件]]></title>
    <url>%2F2017%2F04%2F25%2FSSM12%2F</url>
    <content type="text"><![CDATA[前言在之前dubbo分布式框架中讲到了如何利用dubbo来搭建一个微服务项目。其中还有一些值得优化提高开发效率的地方，比如日志： 当我们一个项目拆分为N多个微服务之后，当其中一个调用另一个服务出现了问题，首先第一步自然是查看日志。 出现问题的有很多情况，如提供方自身代码的问题，调用方的姿势不对等。 自身的问题这个管不了，但是我们可以对每一个入参、返回都加上日志，这样首先就可以判断调用方是否姿势不对了。 为了规范日志已经后续的可扩展，我们可以单独提供一个插件给每个项目使用即可。 效果如下： 123456789101112132017-04-25 15:15:38,968 DEBUG [com.alibaba.dubbo.remoting.transport.DecodeHandler] - [DUBBO] Decode decodeable message com.alibaba.dubbo.rpc.protocol.dubbo.DecodeableRpcInvocation, dubbo version: 2.5.3, current host: 127.0.0.12017-04-25 15:15:39,484 DEBUG [com.crossoverJie.dubbo.filter.DubboTraceFilter] - dubbo请求数据:&#123;&quot;args&quot;:[1],&quot;interfaceName&quot;:&quot;com.crossoverJie.api.UserInfoApi&quot;,&quot;methodName&quot;:&quot;getUserInfo&quot;&#125;2017-04-25 15:15:39,484 INFO [com.crossoverJie.api.impl.UserInfoApiImpl] - 用户查询Id=12017-04-25 15:15:39,505 DEBUG [org.mybatis.spring.SqlSessionUtils] - Creating a new SqlSession2017-04-25 15:15:39,525 DEBUG [org.mybatis.spring.SqlSessionUtils] - SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@6f56b29] was not registered for synchronization because synchronization is not active2017-04-25 15:15:39,549 DEBUG [org.mybatis.spring.transaction.SpringManagedTransaction] - JDBC Connection [com.alibaba.druid.proxy.jdbc.ConnectionProxyImpl@778b3121] will not be managed by Spring2017-04-25 15:15:39,555 DEBUG [com.crossoverJie.api.dubbo.dao.T_userDao.selectByPrimaryKey] - ==&gt; Preparing: select id, username, password,roleId from t_user where id = ? 2017-04-25 15:15:39,591 DEBUG [com.crossoverJie.api.dubbo.dao.T_userDao.selectByPrimaryKey] - ==&gt; Parameters: 1(Integer)2017-04-25 15:15:39,616 DEBUG [com.crossoverJie.api.dubbo.dao.T_userDao.selectByPrimaryKey] - &lt;== Total: 12017-04-25 15:15:39,616 DEBUG [com.alibaba.druid.pool.PreparedStatementPool] - &#123;conn-10003, pstmt-20000&#125; enter cache2017-04-25 15:15:39,617 DEBUG [org.mybatis.spring.SqlSessionUtils] - Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@6f56b29]2017-04-25 15:15:45,473 INFO [com.crossoverJie.dubbo.filter.DubboTraceFilter] - dubbo执行成功2017-04-25 15:15:45,476 DEBUG [com.crossoverJie.dubbo.filter.DubboTraceFilter] - dubbo返回数据&#123;&quot;args&quot;:[&#123;&quot;id&quot;:1,&quot;password&quot;:&quot;123456&quot;,&quot;roleId&quot;:1,&quot;userName&quot;:&quot;crossoverJie&quot;&#125;],&quot;interfaceName&quot;:&quot;com.crossoverJie.api.UserInfoApi&quot;,&quot;methodName&quot;:&quot;getUserInfo&quot;&#125; dubbo filter拓展参考官方文档，我们可以通过1234567891011## 定义实体首先定义一个实体类用于保存调用过程中的一些数据：```javapublic class FilterDesc &#123; private String interfaceName ;//接口名 private String methodName ;//方法名 private Object[] args ;//参数 //省略getter setter&#125; DubboTraceFilter具体拦截逻辑1234567891011121314151617181920212223242526272829303132333435363738@Activate(group = Constants.PROVIDER, order = -999)public class DubboTraceFilter implements Filter&#123; private static final Logger logger = LoggerFactory.getLogger(DubboTraceFilter.class); public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException &#123; try &#123; FilterDesc filterReq = new FilterDesc() ; filterReq.setInterfaceName(invocation.getInvoker().getInterface().getName()); filterReq.setMethodName(invocation.getMethodName()) ; filterReq.setArgs(invocation.getArguments()); logger.debug("dubbo请求数据:"+JSON.toJSONString(filterReq)); Result result = invoker.invoke(invocation); if (result.hasException() &amp;&amp; invoker.getInterface() != GenericService.class)&#123; logger.error("dubbo执行异常",result.getException()); &#125;else &#123; logger.info("dubbo执行成功"); FilterDesc filterRsp = new FilterDesc() ; filterRsp.setMethodName(invocation.getMethodName()); filterRsp.setInterfaceName(invocation.getInvoker().getInterface().getName()); filterRsp.setArgs(new Object[]&#123;result.getValue()&#125;); logger.debug("dubbo返回数据"+JSON.toJSONString(filterRsp)); &#125; return result ; &#125;catch (RuntimeException e)&#123; logger.error("dubbo未知异常" + RpcContext.getContext().getRemoteHost() + ". service: " + invoker.getInterface().getName() + ", method: " + invocation.getMethodName() + ", exception: " + e.getClass().getName() + ": " + e.getMessage(), e); throw e ; &#125; &#125;&#125; 逻辑非常简单，只是对调用过程、异常、成功之后打印相应的日志而已。 但是有个地方要注意一下：需要在resource目录下加上META-INF.dubbo/com.alibaba.dubbo.rpc.Filter文件。1dubboTraceFilter=com.crossoverJie.dubbo.filter.DubboTraceFilter 目录结构如下：12345678910src |-main |-java |-com |-xxx |-XxxFilter.java (实现Filter接口) |-resources |-META-INF |-dubbo |-com.alibaba.dubbo.rpc.Filter (纯文本文件，内容为：xxx=com.xxx.XxxFilter) 总结该项目已经托管到GitHub：https://github.com/crossoverJie/SSM-DUBBO-FILTER 使用方法安装1cd /SSM-DUBBO-FILTER 1mvn clean 1mvn install 使用在服务提供的项目中加上依赖，这样每次调用都会打上日志。12345&lt;dependency&gt; &lt;groupId&gt;com.crossoverJie&lt;/groupId&gt; &lt;artifactId&gt;SSM-TRACE-FILTER&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt; 在拦截器中最好不要加上一些耗时任务，需要考虑到性能问题。 项目地址：https://github.com/crossoverJie/SSM.git 个人博客地址：http://crossoverjie.top。 GitHub地址：https://github.com/crossoverJie。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
        <tag>日志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM(十一) 基于dubbo的分布式架构]]></title>
    <url>%2F2017%2F04%2F07%2FSSM11%2F</url>
    <content type="text"><![CDATA[前言现在越来越多的互联网公司还是将自己公司的项目进行服务化，这确实是今后项目开发的一个趋势，就这个点再凭借之前的SSM项目来让第一次接触的同学能快速上手。 浅谈分布式架构分布式架构单看这个名字给人的感觉就是高逼格，但其实从历史的角度来分析一下就比较明了了。 我们拿一个电商系统来说： 单系统对于一个刚起步的创业公司项目肯定是追求越快完成功能越好，并且用户量也不大。 这时候所有的业务逻辑都是在一个项目中就可以满足。 垂直拆分-多应用当业务量和用户量发展到一定地步的时候，这时一般会将应用同时部署到几台服务器上，在用户访问的时候使用Nginx进行反向代理和简单的负载均衡。 SOA服务化当整个系统以及发展的足够大的时候，比如一个电商系统中存在有： 用户系统 订单系统 支付系统 物流系统 等系统。如果每次修改了其中一个系统就要重新发布上线的话那么耦合就太严重了。 所以需要将整个项目拆分成若干个独立的应用，可以进行独立的开发上线实现快速迭代。 如上图所示每个应用之间相互独立,每个应用可以消费其他应用暴露出来的服务，同时也对外提供服务。 从架构的层面简单的理解了，接下来看看如何编码实现。 基于dubbo的实现dubbo应该算是国内使用最多的分布式服务框架，基于此来实现对新入门的同学应该很有帮助。 其中有涉及到安装dubbo服务的注册中心zookeeper等相关知识点可以自行查看官方文档，这里就不单独讲了。 对外提供服务首先第一步需要在SSM-API模块中定义一个接口，这里就搞了一个用户查询的接口12345678910111213141516/** * Function:用户API * @author chenjiec * Date: 2017/4/4 下午9:46 * @since JDK 1.7 */public interface UserInfoApi &#123; /** * 获取用户信息 * @param userId * @return * @throws Exception */ public UserInfoRsp getUserInfo(int userId) throws Exception;&#125; 接着在SSM-SERVICE模块中进行实现：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import com.alibaba.dubbo.config.annotation.Service;/** * Function: * @author chenjiec * Date: 2017/4/4 下午9:51 * @since JDK 1.7 */@Servicepublic class UserInfoApiImpl implements UserInfoApi &#123; private static Logger logger = LoggerFactory.getLogger(UserInfoApiImpl.class); @Autowired private T_userService t_userService ; /** * 获取用户信息 * * @param userId * @return * @throws Exception */ @Override public UserInfoRsp getUserInfo(int userId) throws Exception &#123; logger.info("用户查询Id="+userId); //返回对象 UserInfoRsp userInfoRsp = new UserInfoRsp() ; T_user t_user = t_userService.selectByPrimaryKey(userId) ; //构建 buildUserInfoRsp(userInfoRsp,t_user) ; return userInfoRsp; &#125; /** * 构建返回 * @param userInfoRsp * @param t_user */ private void buildUserInfoRsp(UserInfoRsp userInfoRsp, T_user t_user) &#123; if (t_user == null)&#123; t_user = new T_user() ; &#125; CommonUtil.setLogValueModelToModel(t_user,userInfoRsp); &#125;&#125; 这些都是通用的代码，但值得注意的一点是这里使用的dubbo框架所提供的@service注解。作用是声明需要暴露的服务接口。 再之后就是几个dubbo相关的配置文件了。 spring-dubbo-config.xml12345678910111213&lt;dubbo:application name="ssm-service" owner="crossoverJie" organization="ssm-crossoverJie" logger="slf4j"/&gt;&lt;dubbo:registry id="dubbo-registry" address="zookeeper://192.168.0.188:2181" file="/tmp/dubbo.cachr" /&gt;&lt;dubbo:monitor protocol="registry" /&gt;&lt;dubbo:protocol name="dubbo" port="20880" /&gt;&lt;dubbo:provider timeout="15000" retries="0" delay="-1" /&gt;&lt;dubbo:consumer check="false" timeout="15000" /&gt; 其实就是配置我们服务注册的zk地址，以及服务名称、超时时间等配置。 spring-dubbo-provider.xml1&lt;dubbo:annotation package="com.crossoverJie.api.impl" /&gt; 这个配置扫描注解包的位置，一般配置到接口实现包即可。 spring-dubbo-consumer.xml这个是消费者配置项，表明我们需要依赖的其他应用。这里我们在SSM-BOOT项目中进行配置：12&lt;dubbo:reference id="userInfoApi" interface="com.crossoverJie.api.UserInfoApi" /&gt; 直接就是配置的刚才我们提供的那个用户查询的接口，这样当我们自己的内部项目需要使用到这个服务只需要依赖SSM-BOOT即可，不需要单独的再去配置consumer。这个我有在上一篇SSM(十) 项目重构-互联网项目的Maven结构中也有提到。 安装管理控制台还有一个需要做的就是安装管理控制台，这里可以看到我们有多少服务、调用情况是怎么样等作用。 这里我们可以将dubbo的官方源码下载下来，对其中的dubbo-admin模块进行打包，将生成的WAR包放到Tomcat中运行起来即可。 但是需要注意一点的是：需要将其中的dubbo.properties的zk地址修改为自己的即可。123dubbo.registry.address=zookeeper://127.0.0.1:2181dubbo.admin.root.password=rootdubbo.admin.guest.password=guest 到时候登陆的话使用root，密码也是root。使用guest，密码也是guest。 登陆界面如下图： 其中我们可以看到有两个服务以及注册上去了，但是没有消费者。 消费服务为了能够更直观的体验到消费服务，我新建了一个项目：https://github.com/crossoverJie/SSM-CONSUMER。 其中在SSM-CONSUMER-API中我也定义了一个接口：12345678910111213141516/** * Function:薪资API * @author chenjiec * Date: 2017/4/4 下午9:46 * @since JDK 1.7 */public interface SalaryInfoApi &#123; /** * 获取薪资 * @param userId * @return * @throws Exception */ public SalaryInfoRsp getSalaryInfo(int userId) throws Exception;&#125; 因为作为消费者的同时我们也对外提供了一个获取薪资的一个服务。 在SSM-CONSUMER-SERVICE模块中进行了实现：12345678910111213141516171819202122232425262728293031323334353637/** * Function: * @author chenjiec * Date: 2017/4/4 下午9:51 * @since JDK 1.7 */@Servicepublic class SalaryInfoApiImpl implements SalaryInfoApi &#123; private static Logger logger = LoggerFactory.getLogger(SalaryInfoApiImpl.class); @Autowired UserInfoApi userInfoApi ; /** * 获取用户信息 * * @param userId * @return * @throws Exception */ @Override public SalaryInfoRsp getSalaryInfo(int userId) throws Exception &#123; logger.info("薪资查询Id="+userId); //返回对象 SalaryInfoRsp salaryInfoRsp = new SalaryInfoRsp() ; //调用远程服务 UserInfoRsp userInfo = userInfoApi.getUserInfo(userId); salaryInfoRsp.setUsername(userInfo.getUserName()); return salaryInfoRsp; &#125;&#125; 其中就可以直接使用userInfoApi调用之前的个人信息服务。 再调用之前需要注意的有点是，我们只需要依赖SSM-BOOT这个模块即可进行调用，因为SSM-BOOT模块已经为我们配置了消费者之类的操作了：1234&lt;dependency&gt; &lt;groupId&gt;com.crossoverJie&lt;/groupId&gt; &lt;artifactId&gt;SSM-BOOT&lt;/artifactId&gt;&lt;/dependency&gt; 还有一点是在配置SSM-BOOT中的spring-dubbo-cosumer.xml配置文件的时候，路径要和我们初始化spring配置文件时的路径一致：12345&lt;!-- Spring和mybatis的配置文件 --&gt;&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath*:spring/*.xml&lt;/param-value&gt;&lt;/context-param&gt; 接下来跑个单测试一下能否调通：123456789101112131415161718192021/** * Function: * * @author chenjiec * Date: 2017/4/5 下午10:41 * @since JDK 1.7 */@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = &#123; "classpath*:/spring/*.xml" &#125;)public class SalaryInfoApiImplTest &#123; @Autowired private SalaryInfoApi salaryInfoApi ; @Test public void getSalaryInfo() throws Exception &#123; SalaryInfoRsp salaryInfo = salaryInfoApi.getSalaryInfo(1); System.out.println(JSON.toJSONString(salaryInfo)); &#125;&#125; 消费者 提供者可以看到确实是调用成功了的。 接下来将消费者项目也同时启动在来观察管理控制台有什么不一样：会看到多了一个消费者所提供的服务com.crossoverjie.consumer.api.SalaryInfoApi,同时com.crossoverJie.api.UserInfoApi服务已经正常，说明已经有消费者了。 点进去便可查看具体的消费者。 总结这样一个基于dubbo的分布式服务已经讲的差不多了，在实际的开发中我们便会开发一个大系统中的某一个子应用，这样就算一个子应用出问题了也不会影响到整个大的项目。 再提一点：在实际的生产环境一般同一个服务我们都会有一个master,slave的主从服务，这样在上线的过程中不至于整个应用出现无法使用的尴尬情况。 谈到了SOA的好处，那么自然也有相对于传统模式的不方便之处： 拆分一个大的项目为成百上千的子应用就不可能手动上线了，即需要自动化的部署上线，如Jenkins。 还有一个需要做到的就是监控，需要一个单独的监控平台来帮我们实时查看各个服务的运行情况以便于及时定位和解决问题。 日志查看分析，拆分之后不可能再去每台服务器上查看日志，需要一个单独的日志查看分析工具如elk。 以上就是我理解的，如有差错欢迎指正。 项目地址：https://github.com/crossoverJie/SSM.git 个人博客地址：http://crossoverjie.top。 GitHub地址：https://github.com/crossoverJie。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM(十) 项目重构-互联网项目的Maven结构]]></title>
    <url>%2F2017%2F03%2F04%2FSSM10%2F</url>
    <content type="text"><![CDATA[前言很久没有更新博客了，之前定下周更逐渐成了月更。怎么感觉像我追过的一部动漫。这个博文其实很早就想写了。之前所有的代码都是在一个模块里面进行开发，这和maven的理念是完全不相符的，最近硬是抽了一个时间来对项目的结构进行了一次重构。 先来看看这次重构之后的目录结构 为什么需要分模块 至于为什么要分模块呢？ 我们设想一个这样的场景：在现在的互联网开发中，会把一个很大的系统拆分成各个子系统用于降低他们之间的耦合度。 在一个子项目中通常都会为API、WEB、Service等模块。而且当项目够大时，这些通常都不是一个人能完成的工作，需要一个团队来各司其职。 想象一下：当之前所有的项目都在一个模块的时候，A改动了API，需要Deploy代码。而B也改动了service的代码，但并没有完全做完。所以A在提交build的时候就会报错 而且在整个项目足够大的时候，这个build的时间也是很影响效率的。 但让我将各个模块之间分开之后效果就不一样了。我修改了API我就只需要管我的就行，不需要整个项目进行build。 而且当有其他项目需要依赖我这个API的时候也只需要依赖API即可，不用整个项目都依赖过去。 各个模块的作用来看下这次我所分的模块。 ROOT这是整个项目的根节点。先看一下其中的pom.xml： 123456789101112131415161718192021222324252627282930&lt;groupId&gt;com.crossoverJie&lt;/groupId&gt; &lt;artifactId&gt;SSM&lt;/artifactId&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;version&gt;2.0.0&lt;/version&gt; &lt;modules&gt; &lt;module&gt;SSM-API&lt;/module&gt; &lt;module&gt;SSM-BOOT&lt;/module&gt; &lt;module&gt;SSM-SERVICE&lt;/module&gt; &lt;module&gt;SSM-WEB&lt;/module&gt; &lt;/modules&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;spring.version&gt;4.1.4.RELEASE&lt;/spring.version&gt; &lt;jackson.version&gt;2.5.0&lt;/jackson.version&gt; &lt;lucene.version&gt;6.0.1&lt;/lucene.version&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.crossoverJie&lt;/groupId&gt; &lt;artifactId&gt;SSM-API&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; 我截取了其中比较重点的配置。 由于这是父节点，所以我的packag类型使用的是pom。其中分别有着四个子模块。 其中重点看下&lt;dependencyManagement&gt;这个标签。如果使用的是IDEA这个开发工具的话是可以看到如下图： 标红的有一个向下的箭头，点一下就可以进入子模块中相同的依赖。这样子模块就不需要配置具体的版本了，统一由父模块来进行维护，对之后的版本升级也带来了好处。 SSM-API接下来看下API这个模块： 通常这个模块都是用于定义外部接口的，以及改接口所依赖的一些DTO类。一般这个模块都是拿来给其他项目进行依赖，并和本项目进行数据交互的。 SSM-BOOTBOOT这个模块比较特殊。可以看到这里没有任何代码，只有一个rpc的配置文件。通常这个模块是用于给我们内部项目进行依赖的，并不像上面的API模块一样给其他部门或者是项目进行依赖的。 因为在我们的RPC调用的时候，用dubbo来举例，是需要配置所依赖的consumer。 但如果是我们自己内部调用的话我们就可以把需要调用自己的dubbo服务提供者配置在这里，这样的话我们自己调用就只需要依赖这个BOOT就可以进行调用了。 哦对了，BOOT同时还会依赖API，这样才实现了只依赖BOOT就可以调用自己内部的dubbo服务了。如下所示：12345678910111213&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.crossoverJie&lt;/groupId&gt; &lt;artifactId&gt;SSM-API&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; SSM-SERVICESERVICE模块就比较好理解了。是处理具体业务逻辑的地方，也是对之前的API的实现。 通常这也是一个web模块，所以我的pom类型是WAR。 SSM-WEB其实WEB模块和SERVICE模块有点重合了。通常来说这个模块一般在一个对外提供http访问接口的项目中。 这里只是为了展示项目结构，所以也写在了这里。 他的作用和service差不多，都是WAR的类型。 总结这次没有实现什么特别的功能，只是对一些还没有接触过这种项目结构开发的童鞋能起到一些引导作用。 具体源码还请关注我的github。 项目地址：https://github.com/crossoverJie/SSM.git 个人博客地址：http://crossoverjie.top。 GitHub地址：https://github.com/crossoverJie。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>Maven</tag>
        <tag>重构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM(九) 反射的实际应用 - 构建日志对象]]></title>
    <url>%2F2017%2F01%2F19%2FSSM9%2F</url>
    <content type="text"><![CDATA[前言相信做Java的童鞋或多或少都听过反射，这也应该是Java从入门到进阶的必经之路。 但是在我们的实际开发中直接使用它们的几率貌似还是比较少的，（除了造轮子或者是Spring Mybatis这些框架外）。 所以这里介绍一个在实际开发中还是小有用处的反射实例。 传统日志有关反射的一些基本知识就不说了，可以自行Google，也可以看下反射入门。 日志相信大家都不陌生，在实际开发中一些比较敏感的数据表我们需要对它的每一次操作都记录下来。 先来看看传统的写法：1234567891011121314@Testpublic void insertSelective() throws Exception &#123; Content content = new Content() ; content.setContent("asdsf"); content.setCreatedate("2016-12-09"); contentService.insertSelective(content) ; ContentLog log = new ContentLog(); log.setContentid(content.getContentid()); log.setContent("asdsf"); log.setCreatedate("2016-12-09"); contentLogService.insertSelective(log);&#125; 非常简单，就是在保存完数据表之后再把相同的数据保存到日志表中。但是这样有以下几个问题： 如果数据表的字段较多的话，比如几百个。那么日志表的setter()方法就得写几百次，还得是都写对的情况下。 如果哪天数据表的字段发生了增加，那么每个写日志的地方都得增加该字段，提高了维护的成本。 针对以上的情况就得需要反射这个主角来解决了。 利用反射构建日志我们先来先来看下使用反射之后对代码所带来的改变：12345678910111213@Testpublic void insertSelective2() throws Exception &#123; Content content = new Content(); content.setContent("你好"); content.setContentname("1"); content.setCreatedate("2016-09-23"); contentService.insertSelective(content); ContentLog log = new ContentLog(); CommonUtil.setLogValueModelToModel(content, log); contentLogService.insertSelective(log);&#125; 同样的保存日志，不管多少字段，只需要三行代码即可解决。而且就算之后字段发生改变写日志这段代码仍然不需要改动。 其实这里最主要的一个方法就是CommonUtil.setLogValueModelToModel(content, log); 来看下是如何实现的;12345678910111213141516171819202122232425262728293031323334353637/** * 生成日志实体工具 * * @param objectFrom * @param objectTo */ public static void setLogValueModelToModel(Object objectFrom, Object objectTo) &#123; Class&lt;? extends Object&gt; clazzFrom = objectFrom.getClass(); Class&lt;? extends Object&gt; clazzTo = objectTo.getClass(); for (Method toSetMethod : clazzTo.getMethods()) &#123; String mName = toSetMethod.getName(); if (mName.startsWith("set")) &#123; //字段名 String field = mName.substring(3); //获取from 值 Object value; try &#123; if ("LogId".equals(field)) &#123; continue; &#125; Method fromGetMethod = clazzFrom.getMethod("get" + field); value = fromGetMethod.invoke(objectFrom); //设置值 toSetMethod.invoke(objectTo, value); &#125; catch (NoSuchMethodException e) &#123; throw new RuntimeException(e); &#125; catch (InvocationTargetException e) &#123; throw new RuntimeException(e); &#125; catch (IllegalAccessException e) &#123; throw new RuntimeException(e); &#125; &#125; &#125; &#125; 再使用之前我们首先需要构建好主的数据表，然后new一个日志表的对象。 在setLogValueModelToModel()方法中： 分别获得数据表和日志表对象的类类型。 获取到日志对象的所有方法集合。 遍历该集合，并拿到该方法的名称。 只取其中set开头的方法，也就是set方法。因为我们需要在循环中为日志对象的每一个字段赋值。 之后截取方法名称获得具体的字段名称。 用之前截取的字段名称，通过getMethod()方法返回数据表中的该字段的getter方法。 相当于执行了String content = content.getContent(); 执行该方法获得该字段具体的值。 利用当前循环的setter方法为日志对象的每一个字段赋值。 相当于执行了log.setContent(&quot;asdsf&quot;); 其中字段名称为LogId时跳出了当前循环，因为LogId是日志表的主键，是不需要赋值的。 当循环结束时，日志对象也就构建完成了。之后只需要保存到数据库中即可。 总结反射其实是非常耗资源的，再使用过程中还是要慎用。其中对method、field、constructor等对象做缓存也是很有必要的。 项目地址：https://github.com/crossoverJie/SSM.git 个人博客地址：http://crossoverjie.top。 GitHub地址：https://github.com/crossoverJie。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Reflect</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM(八)动态切换数据源]]></title>
    <url>%2F2017%2F01%2F05%2FSSM8%2F</url>
    <content type="text"><![CDATA[前言 在现在开发的过程中应该大多数朋友都有遇到过切换数据源的需求。比如现在常用的数据库读写分离，或者就是有两个数据库的情况，这些都需要用到切换数据源。 手动切换数据源使用Spring的AbstractRoutingDataSource类来进行拓展多数据源。 该类就相当于一个dataSource的路由，用于根据key值来进行切换对应的dataSource。 下面简单来看下AbstractRoutingDataSource类的几段关键源码：123456789101112131415161718192021222324252627282930313233343536373839@Overridepublic Connection getConnection() throws SQLException &#123; return determineTargetDataSource().getConnection();&#125;@Overridepublic Connection getConnection(String username, String password) throws SQLException &#123; return determineTargetDataSource().getConnection(username, password);&#125;/** * Retrieve the current target DataSource. Determines the * &#123;@link #determineCurrentLookupKey() current lookup key&#125;, performs * a lookup in the &#123;@link #setTargetDataSources targetDataSources&#125; map, * falls back to the specified * &#123;@link #setDefaultTargetDataSource default target DataSource&#125; if necessary. * @see #determineCurrentLookupKey() */protected DataSource determineTargetDataSource() &#123; Assert.notNull(this.resolvedDataSources, "DataSource router not initialized"); Object lookupKey = determineCurrentLookupKey(); DataSource dataSource = this.resolvedDataSources.get(lookupKey); if (dataSource == null &amp;&amp; (this.lenientFallback || lookupKey == null)) &#123; dataSource = this.resolvedDefaultDataSource; &#125; if (dataSource == null) &#123; throw new IllegalStateException("Cannot determine target DataSource for lookup key [" + lookupKey + "]"); &#125; return dataSource;&#125;/** * Determine the current lookup key. This will typically be * implemented to check a thread-bound transaction context. * &lt;p&gt;Allows for arbitrary keys. The returned key needs * to match the stored lookup key type, as resolved by the * &#123;@link #resolveSpecifiedLookupKey&#125; method. */protected abstract Object determineCurrentLookupKey(); 可以看到其中获取链接的方法getConnection()调用的determineTargetDataSource则是关键方法。该方法用于返回我们使用的数据源。 其中呢又是determineCurrentLookupKey()方法来返回当前数据源的key值。之后通过该key值在resolvedDataSources这个map中找到对应的value(该value就是数据源)。 resolvedDataSources这个map则是在：123456789101112131415@Overridepublic void afterPropertiesSet() &#123; if (this.targetDataSources == null) &#123; throw new IllegalArgumentException("Property 'targetDataSources' is required"); &#125; this.resolvedDataSources = new HashMap&lt;Object, DataSource&gt;(this.targetDataSources.size()); for (Map.Entry&lt;Object, Object&gt; entry : this.targetDataSources.entrySet()) &#123; Object lookupKey = resolveSpecifiedLookupKey(entry.getKey()); DataSource dataSource = resolveSpecifiedDataSource(entry.getValue()); this.resolvedDataSources.put(lookupKey, dataSource); &#125; if (this.defaultTargetDataSource != null) &#123; this.resolvedDefaultDataSource = resolveSpecifiedDataSource(this.defaultTargetDataSource); &#125;&#125; 这个方法通过targetDataSources这个map来进行赋值的。targetDataSources则是我们在配置文件中进行赋值的，下面会讲到。 再来看看determineCurrentLookupKey()方法，从protected来修饰就可以看出是需要我们来进行重写的。 DynamicDataSource 和 DataSourceHolder于是我新增了DynamicDataSource类，代码如下：1234567891011121314151617package com.crossoverJie.util;import org.springframework.jdbc.datasource.lookup.AbstractRoutingDataSource;/** * Function: * * @author chenjiec * Date: 2017/1/2 上午12:22 * @since JDK 1.7 */public class DynamicDataSource extends AbstractRoutingDataSource &#123; @Override protected Object determineCurrentLookupKey() &#123; return DataSourceHolder.getDataSources(); &#125;&#125; 代码很简单，继承了AbstractRoutingDataSource类并重写了其中的determineCurrentLookupKey()方法。 这里直接用DataSourceHolder返回了一个数据源。 DataSourceHolder代码如下：1234567891011121314151617181920package com.crossoverJie.util;/** * Function:动态数据源 * * @author chenjiec * Date: 2017/1/2 上午12:19 * @since JDK 1.7 */public class DataSourceHolder &#123; private static final ThreadLocal&lt;String&gt; dataSources = new ThreadLocal&lt;String&gt;(); public static void setDataSources(String dataSource) &#123; dataSources.set(dataSource); &#125; public static String getDataSources() &#123; return dataSources.get(); &#125;&#125; 这里我使用了ThreadLocal来保存了数据源，关于ThreadLocal的知识点可以查看以下这篇文章：解密ThreadLocal 之后在Spring的配置文件中配置我们的数据源，就是上文讲到的为targetDataSources赋值：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566&lt;bean id="ssm1DataSource" class="com.alibaba.druid.pool.DruidDataSource" init-method="init" destroy-method="close"&gt; &lt;!-- 指定连接数据库的驱动 --&gt; &lt;property name="driverClassName" value="$&#123;jdbc.driverClass&#125;" /&gt; &lt;property name="url" value="$&#123;jdbc.url&#125;" /&gt; &lt;property name="username" value="$&#123;jdbc.user&#125;" /&gt; &lt;property name="password" value="$&#123;jdbc.password&#125;" /&gt; &lt;!-- 配置初始化大小、最小、最大 --&gt; &lt;property name="initialSize" value="3" /&gt; &lt;property name="minIdle" value="3" /&gt; &lt;property name="maxActive" value="20" /&gt; &lt;!-- 配置获取连接等待超时的时间 --&gt; &lt;property name="maxWait" value="60000" /&gt; &lt;!-- 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 --&gt; &lt;property name="timeBetweenEvictionRunsMillis" value="60000" /&gt; &lt;!-- 配置一个连接在池中最小生存的时间，单位是毫秒 --&gt; &lt;property name="minEvictableIdleTimeMillis" value="300000" /&gt; &lt;property name="validationQuery" value="SELECT 'x'" /&gt; &lt;property name="testWhileIdle" value="true" /&gt; &lt;property name="testOnBorrow" value="false" /&gt; &lt;property name="testOnReturn" value="false" /&gt; &lt;!-- 打开PSCache，并且指定每个连接上PSCache的大小 --&gt; &lt;property name="poolPreparedStatements" value="true" /&gt; &lt;property name="maxPoolPreparedStatementPerConnectionSize" value="20" /&gt; &lt;!-- 配置监控统计拦截的filters，去掉后监控界面sql无法统计 --&gt; &lt;property name="filters" value="stat" /&gt; &lt;/bean&gt; &lt;bean id="ssm2DataSource" class="com.alibaba.druid.pool.DruidDataSource" init-method="init" destroy-method="close"&gt; &lt;!-- 指定连接数据库的驱动 --&gt; &lt;property name="driverClassName" value="$&#123;jdbc.driverClass&#125;"/&gt; &lt;property name="url" value="$&#123;jdbc.url2&#125;"/&gt; &lt;property name="username" value="$&#123;jdbc.user2&#125;"/&gt; &lt;property name="password" value="$&#123;jdbc.password2&#125;"/&gt; &lt;property name="initialSize" value="3"/&gt; &lt;property name="minIdle" value="3"/&gt; &lt;property name="maxActive" value="20"/&gt; &lt;!-- 配置获取连接等待超时的时间 --&gt; &lt;property name="maxWait" value="60000"/&gt; &lt;!-- 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 --&gt; &lt;property name="timeBetweenEvictionRunsMillis" value="60000"/&gt; &lt;!-- 配置一个连接在池中最小生存的时间，单位是毫秒 --&gt; &lt;property name="minEvictableIdleTimeMillis" value="300000"/&gt; &lt;property name="validationQuery" value="SELECT 'x'"/&gt; &lt;property name="testWhileIdle" value="true"/&gt; &lt;property name="testOnBorrow" value="false"/&gt; &lt;property name="testOnReturn" value="false"/&gt; &lt;!-- 打开PSCache，并且指定每个连接上PSCache的大小 --&gt; &lt;property name="poolPreparedStatements" value="true"/&gt; &lt;property name="maxPoolPreparedStatementPerConnectionSize" value="20"/&gt; &lt;!-- 配置监控统计拦截的filters，去掉后监控界面sql无法统计 --&gt; &lt;property name="filters" value="stat"/&gt; &lt;/bean&gt; &lt;bean id="dataSource" class="com.crossoverJie.util.DynamicDataSource"&gt; &lt;property name="targetDataSources"&gt; &lt;map key-type="java.lang.String"&gt; &lt;entry key="ssm1DataSource" value-ref="ssm1DataSource"/&gt; &lt;entry key="ssm2DataSource" value-ref="ssm2DataSource"/&gt; &lt;/map&gt; &lt;/property&gt; &lt;!--默认数据源--&gt; &lt;property name="defaultTargetDataSource" ref="ssm1DataSource"/&gt; &lt;/bean&gt; 这里分别配置了两个数据源：ssm1DataSource和ssm2DataSource。之后再通过Spring的依赖注入方式将两个数据源设置进targetDataSources。 接下来的用法相比大家也应该猜到了。 就是在每次调用数据库之前我们都要先通过DataSourceHolder来设置当前的数据源。看下demo：123456@Testpublic void selectByPrimaryKey() throws Exception &#123; DataSourceHolder.setDataSources(Constants.DATASOURCE_TWO); Datasource datasource = dataSourceService.selectByPrimaryKey(7); System.out.println(JSON.toJSONString(datasource));&#125; 详见我的单测。 使用起来也是非常简单。但是不知道大家注意到没有，这样的做法槽点很多： 每次使用需要手动切换，总有一些人会忘记写(比如我)。 如果是后期需求变了，查询其他的表了还得一个个改回来。 那有没有什么方法可以自动的帮我们切换呢？ 肯定是有的，大家应该也想得到。就是利用Spring的AOP了。 自动切换数据源首先要定义好我们的切面类DataSourceExchange:1234567891011121314151617181920212223242526272829303132333435363738394041package com.crossoverJie.util;import org.aspectj.lang.JoinPoint;/** * Function:拦截器方法 * * @author chenjiec * Date: 2017/1/3 上午12:34 * @since JDK 1.7 */public class DataSourceExchange &#123; /** * * @param point */ public void before(JoinPoint point) &#123; //获取目标对象的类类型 Class&lt;?&gt; aClass = point.getTarget().getClass(); //获取包名用于区分不同数据源 String whichDataSource = aClass.getName().substring(25, aClass.getName().lastIndexOf(".")); if ("ssmone".equals(whichDataSource)) &#123; DataSourceHolder.setDataSources(Constants.DATASOURCE_ONE); &#125; else &#123; DataSourceHolder.setDataSources(Constants.DATASOURCE_TWO); &#125; &#125; /** * 执行后将数据源置为空 */ public void after() &#123; DataSourceHolder.setDataSources(null); &#125;&#125; 逻辑也比较简单，就是在执行数据库操作之前做一个切面。 通过JoinPoint对象获取目标对象。 在目标对象中获取包名来区分不同的数据源。 根据不同数据源来进行赋值。 执行完毕之后将数据源清空。 关于一些JoinPoint的API：1234567891011121314package org.aspectj.lang;import org.aspectj.lang.reflect.SourceLocation;public interface JoinPoint &#123; String toString(); //连接点所在位置的相关信息 String toShortString(); //连接点所在位置的简短相关信息 String toLongString(); //连接点所在位置的全部相关信息 Object getThis(); //返回AOP代理对象 Object getTarget(); //返回目标对象 Object[] getArgs(); //返回被通知方法参数列表 Signature getSignature(); //返回当前连接点签名 SourceLocation getSourceLocation();//返回连接点方法所在类文件中的位置 String getKind(); //连接点类型 StaticPart getStaticPart(); //返回连接点静态部分&#125; 为了通过包名来区分不同数据源，我将目录结构稍微调整了下： 将两个不同的数据源的实现类放到不同的包中，这样今后如果还需要新增其他数据源也可以灵活的切换。 看下Spring的配置：123456789101112131415161718192021&lt;bean id="dataSourceExchange" class="com.crossoverJie.util.DataSourceExchange"/&gt;&lt;!--配置切面拦截方法 --&gt;&lt;aop:config proxy-target-class="false"&gt; &lt;!--将com.crossoverJie.service包下的所有select开头的方法加入拦截 去掉select则加入所有方法 --&gt; &lt;aop:pointcut id="controllerMethodPointcut" expression=" execution(* com.crossoverJie.service.*.select*(..))"/&gt; &lt;aop:pointcut id="selectMethodPointcut" expression=" execution(* com.crossoverJie.dao..*Mapper.select*(..))"/&gt; &lt;aop:advisor advice-ref="methodCacheInterceptor" pointcut-ref="controllerMethodPointcut"/&gt; &lt;!--所有数据库操作的方法加入切面--&gt; &lt;aop:aspect ref="dataSourceExchange"&gt; &lt;aop:pointcut id="dataSourcePointcut" expression="execution(* com.crossoverJie.service.*.*(..))"/&gt; &lt;aop:before pointcut-ref="dataSourcePointcut" method="before"/&gt; &lt;aop:after pointcut-ref="dataSourcePointcut" method="after"/&gt; &lt;/aop:aspect&gt;&lt;/aop:config&gt; 这是在我们上一篇整合redis缓存的基础上进行修改的。这样缓存和多数据源都满足了。 实际使用：12345@Testpublic void selectByPrimaryKey() throws Exception &#123; Rediscontent rediscontent = rediscontentService.selectByPrimaryKey(30); System.out.println(JSON.toJSONString(rediscontent));&#125; 这样看起来就和使用一个数据源这样简单，再也不用关心切换的问题了。 总结不过按照这样的写法是无法做到在一个事务里控制两个数据源的。这个我还在学习中，有相关经验的大牛不妨指点一下。 项目地址：https://github.com/crossoverJie/SSM.git 个人博客地址：http://crossoverjie.top。 GitHub地址：https://github.com/crossoverJie。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>AOP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GoodBye 2016,Welcome 2017 | 码农砌墙记]]></title>
    <url>%2F2016%2F12%2F31%2FGoodBye%202016%2CWelcome%202017%20%7C%20%E7%A0%81%E5%86%9C%E7%A0%8C%E5%A2%99%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[前言 早在这个月初的时候我就很想写一篇年终总结了，因为这一年相对于去年确实是经历的太多了。结果一直等到31号，在家里和媳妇吃完晚饭就马上打开电脑开码。 五月二十三-第一次跳槽 根据整年的时间线开始第一件大事自然就是换公司了。 先来点前景提要:我是14年11月份参加工作的。当时其实还没有毕业就在一家给大型企业做定制软件开发的公司实习。刚开始工作的时候什么事情都觉得非常新奇，一个在学校学的东西能运用到实际开发中并能给用户带来便利让我觉得做码农真是一件非常正确的选择啊(ps当时真是太年轻)。 后来真是造化弄人，当时负责我参与的这个项目的负责人跳槽了，我自然就成了整个公司最熟悉此项目的人了。现在不得不佩服公司老板真是心大啊，居然让一个实习生来负责这个项目。就这样我成了整个项目的负责人，从之后的开发到测试到上线到后面的维护几乎都是我一个人在负责。来一张当时上线的截图： 由于这次项目的顺利验收，公司也对我越来越信任。之后也就理所当然的又负责了几个项目。 虽然离开了但真的非常感谢公司当时对一个什么都不懂的新人给予信任。 之后随着技术的提升我接触了github、v站这样的技术论坛，逐渐的发现天外有天，我这点雕虫小技真的完全不算什么，真正机遇与挑战并存的地方是互联网。 但是此时我已经在这家公司做了一年多了，突然离开这个舒适圈来到一个陌生的环境是需要很大勇气的，或者说需要一个刺激点。 正好@嘟爷成了这个导火索。那个时候我正在搭我的个人博客正好看到了他的文章，觉得写得非常好。而且正好他也正准备转向互联网，于是我给他写了一封很长的邮件说了我心中的一些疑惑与顾虑让他给点建议。 在他的建议之下我才开始投递简历准备换一家互联网公司，感谢嘟爷给了我一个这么正确的建议。 之后我顺利的进入了一个创业公司，开始了狭义的互联网开发道路，为什么是狭义请接着往后看。 搭建个人博客 搭建博客这事也是必须的拿出来说一说的。 上面说到我看了嘟爷的博客才开始搭建自己的博客，到现在为止由于我的拖延症(加上是真的懒)一共写了20篇。不能说写的有多好，但确实是我在工作和学习中的一些总结。 让我意外的是我博客的访问量，下图是我cnzz的统计截图： 六月二十一-开源项目关于开源项目，之前我在github上面看很多优秀的开源项目，也很佩服那些作者，于是就想着自己能不能也搞一个，但是一来就造个轮子对我来说确实有点不现实。 于是我换了一个思路，由于现在我勉强也不算是新入门的菜鸟了，但我是从菜鸟过来的，深知刚开始的时候找资料的痛苦。不是资料太老就是没有体系，讲一点是一点的那种。 于是就有了现在这个项目:会不定期更新一些在实际开发中使用的技巧(ps:目前不是很忙基本上一周一更)。 没有复杂的业务流程，更不是XXXX系统，只有一些技术的分享。 从六月二十一号到现在还是有100多颗星了： 九月二十三-第二次跳槽看到这里是不是觉得我有病啊，怎么又是跳槽。。。 其实我也不想，我在上面说到开始了我的狭义互联网开发，为什么是狭义呢？ 因为做了一段时间才发现这个项目除了是部署在云服务器上和有一个微信端之外和我之前所做的项目貌似没有本质上的区别，还是一个管理系统。 这里我不评价公司的业务，但是公司的技术总监在修改问题的时候是直接在云服务器上登陆数据库删除数据，会不会觉得很奇葩。最奇葩的是删除的时候忘了写where条件导致把整张表的数据都删了，这个时候如果是你你会不会怀疑那啥。。 除此之外技术总监本人还是挺好的，不过我更觉得他适合做销售总监。 加上后来公司的业务没有发展起来，所做的系统又老是出问题(联想上文)，加上还在流传我们技术部要裁人。那我还不如自己走(现在V站逛多了突然觉得好亏)。 于是我开始了我的第二次跳槽，前后时间才间隔4个月，不得不感慨命运弄人啊。 之后我来到现在这家员工5000余人的真正的互联网公司，开始了真正意义的互联网开发。这里必须得感谢我的面试官也是我现在这个项目的leader，给了我这个互联网菜鸟机会。 不过命运总是如此的相识，明年也就是下周他就换部门了，意味着现在这个项目我又成负责人了。希望一切顺利吧。 技术相关前面说到我是九月份的时候才进入这家正真意义的互联网公司的，所以体术提升最明显也是在这段时间。 这段时间所学的起码是我在前面两家公司一年都学不到的，这里我大致列了一下： 熟悉了一个互联网产品的生命周期(关于开发、测试、预发布、灰度以及上线) 熟悉了一些关于并发、主从、缓存、调度、容器这些主流的技术。 最重要的一点，学会了不加班不舒服斯基。 身体相关不知是错觉还是什么，感觉今年看到IT行业猝死或者是出事的新闻越来越多，加上我这个今年才22岁的青年有时候也会腰疼脖子酸，导致我对于身体也是越来越担忧。 其实我从初中的时候就开始打篮球，在工作之前也是对篮球完全是痴迷的状态，每天不打球就浑身难受。刚工作的那段时间还能坚持每周末去打球，但是今年能做到一个月打一次都非常难得了。。 再此，我立个flag，明天下午出去打球，明年坚持至少每两周打一次球。 2017小目标到这里也基本上总结的差不多了，还有半个小时就是17年了。 还是定一个17年的小目标吧： 博客坚持写，至少保持两周一更。 开源项目坚持维护，争取造一个轮子出来。 坚持锻炼，我还得养家糊口。 最后希望家人朋友都平平安安。]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM(七)在JavaWeb应用中使用Redis]]></title>
    <url>%2F2016%2F12%2F18%2FSSM7%2F</url>
    <content type="text"><![CDATA[前言由于最近换(mang)了(de)家(yi)公(bi)司接触了新的东西所以很久没有更新了。这次谈谈Redis，关于Redis应该很多朋友就算没有用过也听过，算是这几年最流行的NoSql之一了。Redis的应用场景非常多这里就不一一列举了，这次就以一个最简单的也最常用的 缓存数据 来举例。先来看一张效果图： 作用就是在每次查询接口的时候首先判断Redis中是否有缓存，有的话就读取，没有就查询数据库并保存到Redis中，下次再查询的话就会直接从缓存中读取了。Redis中的结果：之后查询redis发现确实是存进来了。 Redis安装与使用首先第一步自然是安装Redis。我是在我VPS上进行安装的，操作系统是CentOS6.5。 下载Redishttps://redis.io/download，我机器上安装的是3.2.5 将下载下来的’reidis-3.2.5-tar.gz’上传到usr/local这个目录进行解压。 进入该目录。 编译安装 12makemake install 修改redis.conf配置文件。 这里我只是简单的加上密码而已。12vi redis.confrequirepass 你的密码 启动Redis 启动时候要选择我们之前修改的配置文件才能使配置文件生效。1234进入src目录cd /usr/local/redis-3.2.5/src启动服务./redis-server ../redis.conf 登陆redis1./redis-cli -a 你的密码 Spring整合Redis这里我就直接开始用Spring整合毕竟在实际使用中都是和Spring一起使用的。 修改Spring配置文件加入以下内容：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970&lt;!-- jedis 配置 --&gt; &lt;bean id="poolConfig" class="redis.clients.jedis.JedisPoolConfig"&gt; &lt;property name="maxIdle" value="$&#123;redis.maxIdle&#125;"/&gt; &lt;property name="maxWaitMillis" value="$&#123;redis.maxWait&#125;"/&gt; &lt;property name="testOnBorrow" value="$&#123;redis.testOnBorrow&#125;"/&gt; &lt;/bean&gt; &lt;!-- redis服务器中心 --&gt; &lt;bean id="connectionFactory" class="org.springframework.data.redis.connection.jedis.JedisConnectionFactory"&gt; &lt;property name="poolConfig" ref="poolConfig"/&gt; &lt;property name="port" value="$&#123;redis.port&#125;"/&gt; &lt;property name="hostName" value="$&#123;redis.host&#125;"/&gt; &lt;property name="password" value="$&#123;redis.password&#125;"/&gt; &lt;property name="timeout" value="$&#123;redis.timeout&#125;"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean id="redisTemplate" class="org.springframework.data.redis.core.RedisTemplate"&gt; &lt;property name="connectionFactory" ref="connectionFactory"/&gt; &lt;property name="keySerializer"&gt; &lt;bean class="org.springframework.data.redis.serializer.StringRedisSerializer"/&gt; &lt;/property&gt; &lt;property name="valueSerializer"&gt; &lt;bean class="org.springframework.data.redis.serializer.JdkSerializationRedisSerializer"/&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- cache配置 --&gt; &lt;bean id="methodCacheInterceptor" class="com.crossoverJie.intercept.MethodCacheInterceptor"&gt; &lt;property name="redisUtil" ref="redisUtil"/&gt; &lt;/bean&gt; &lt;bean id="redisUtil" class="com.crossoverJie.util.RedisUtil"&gt; &lt;property name="redisTemplate" ref="redisTemplate"/&gt; &lt;/bean&gt; &lt;!--配置切面拦截方法 --&gt; &lt;aop:config proxy-target-class="true"&gt; &lt;!--将com.crossoverJie.service包下的所有select开头的方法加入拦截 去掉select则加入所有方法w --&gt; &lt;aop:pointcut id="controllerMethodPointcut" expression=" execution(* com.crossoverJie.service.*.select*(..))"/&gt; &lt;aop:pointcut id="selectMethodPointcut" expression=" execution(* com.crossoverJie.dao..*Mapper.select*(..))"/&gt; &lt;aop:advisor advice-ref="methodCacheInterceptor" pointcut-ref="controllerMethodPointcut"/&gt; &lt;/aop:config&gt;``` 更多的配置可以直接在源码里面查看：[https://github.com/crossoverJie/SSM/blob/master/src/main/resources/spring-mybatis.xml](https://github.com/crossoverJie/SSM/blob/master/src/main/resources/spring-mybatis.xml)。以上都写有注释，也都是一些简单的配置相信都能看懂。下面我会着重说下如何配置缓存的。# Spring切面使用缓存Spring的`AOP`真是是一个好东西，还不太清楚是什么的同学建议先自行`Google`下吧。在不使用切面的时候如果我们想给某个方法加入缓存的话肯定是在方法返回之前就要加入相应的逻辑判断，只有一个或几个倒还好，如果有几十上百个的话那GG了，而且维护起来也特别麻烦。&gt; 好在Spring的AOP可以帮我们解决这个问题。&gt; 这次就在我们需要加入缓存方法的切面加入这个逻辑，并且只需要一个配置即可搞定，就是上文中所提到的配置文件，如下：```xml &lt;!--配置切面拦截方法 --&gt; &lt;aop:config proxy-target-class="true"&gt; &lt;!--将com.crossoverJie.service包下的所有select开头的方法加入拦截 去掉select则加入所有方法w --&gt; &lt;aop:pointcut id="controllerMethodPointcut" expression=" execution(* com.crossoverJie.service.*.select*(..))"/&gt; &lt;aop:pointcut id="selectMethodPointcut" expression=" execution(* com.crossoverJie.dao..*Mapper.select*(..))"/&gt; &lt;aop:advisor advice-ref="methodCacheInterceptor" pointcut-ref="controllerMethodPointcut"/&gt; &lt;/aop:config&gt; 这里我们使用表达式execution(* com.crossoverJie.service.*.select*(..))来拦截service中所有以select开头的方法。这样只要我们要将加入的缓存的方法以select命名开头的话每次进入方法之前都会进入我们自定义的MethodCacheInterceptor拦截器。这里贴一下MethodCacheInterceptor中处理逻辑的核心方法：12345678910111213141516171819202122232425262728293031323334353637383940414243444546@Override public Object invoke(MethodInvocation invocation) throws Throwable &#123; Object value = null; String targetName = invocation.getThis().getClass().getName(); String methodName = invocation.getMethod().getName(); // 不需要缓存的内容 //if (!isAddCache(StringUtil.subStrForLastDot(targetName), methodName)) &#123; if (!isAddCache(targetName, methodName)) &#123; // 执行方法返回结果 return invocation.proceed(); &#125; Object[] arguments = invocation.getArguments(); String key = getCacheKey(targetName, methodName, arguments); logger.debug("redisKey: " + key); try &#123; // 判断是否有缓存 if (redisUtil.exists(key)) &#123; return redisUtil.get(key); &#125; // 写入缓存 value = invocation.proceed(); if (value != null) &#123; final String tkey = key; final Object tvalue = value; new Thread(new Runnable() &#123; @Override public void run() &#123; if (tkey.startsWith("com.service.impl.xxxRecordManager")) &#123; redisUtil.set(tkey, tvalue, xxxRecordManagerTime); &#125; else if (tkey.startsWith("com.service.impl.xxxSetRecordManager")) &#123; redisUtil.set(tkey, tvalue, xxxSetRecordManagerTime); &#125; else &#123; redisUtil.set(tkey, tvalue, defaultCacheExpireTime); &#125; &#125; &#125;).start(); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); if (value == null) &#123; return invocation.proceed(); &#125; &#125; return value; &#125; 先是查看了当前方法是否在我们自定义的方法中，如果不是的话就直接返回，不进入拦截器。 之后利用反射获取的类名、方法名、参数生成redis的key。 用key在redis中查询是否已经有缓存。 有缓存就直接返回缓存内容，不再继续查询数据库。 如果没有缓存就查询数据库并将返回信息加入到redis中。 使用PageHelper这次为了分页方便使用了比较流行的PageHelper来帮我们更简单的进行分页。首先是新增一个mybatis的配置文件mybatis-config：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;&lt;configuration&gt; &lt;settings&gt; &lt;setting name="cacheEnabled" value="true"/&gt; &lt;setting name="lazyLoadingEnabled" value="true"/&gt; &lt;setting name="multipleResultSetsEnabled" value="true"/&gt; &lt;setting name="useColumnLabel" value="true"/&gt; &lt;setting name="useGeneratedKeys" value="false"/&gt; &lt;setting name="autoMappingBehavior" value="PARTIAL"/&gt; &lt;setting name="defaultExecutorType" value="SIMPLE"/&gt; &lt;setting name="defaultStatementTimeout" value="25"/&gt; &lt;setting name="safeRowBoundsEnabled" value="false"/&gt; &lt;setting name="mapUnderscoreToCamelCase" value="false"/&gt; &lt;setting name="localCacheScope" value="SESSION"/&gt; &lt;setting name="jdbcTypeForNull" value="OTHER"/&gt; &lt;setting name="lazyLoadTriggerMethods" value="equals,clone,hashCode,toString"/&gt; &lt;/settings&gt; &lt;plugins&gt; &lt;!-- com.github.pagehelper为PageHelper类所在包名 --&gt; &lt;plugin interceptor="com.github.pagehelper.PageHelper"&gt; &lt;property name="dialect" value="mysql"/&gt; &lt;!-- 该参数默认为false --&gt; &lt;!-- 设置为true时，会将RowBounds第一个参数offset当成pageNum页码使用 --&gt; &lt;!-- 和startPage中的pageNum效果一样 --&gt; &lt;property name="offsetAsPageNum" value="true"/&gt; &lt;!-- 该参数默认为false --&gt; &lt;!-- 设置为true时，使用RowBounds分页会进行count查询 --&gt; &lt;property name="rowBoundsWithCount" value="true"/&gt; &lt;!-- 设置为true时，如果pageSize=0或者RowBounds.limit = 0就会查询出全部的结果 --&gt; &lt;!-- （相当于没有执行分页查询，但是返回结果仍然是Page类型） &lt;property name="pageSizeZero" value="true"/&gt; --&gt; &lt;!-- 3.3.0版本可用 - 分页参数合理化，默认false禁用 --&gt; &lt;!-- 启用合理化时，如果pageNum&lt;1会查询第一页，如果pageNum&gt;pages会查询最后一页 --&gt; &lt;!-- 禁用合理化时，如果pageNum&lt;1或pageNum&gt;pages会返回空数据 --&gt; &lt;property name="reasonable" value="true"/&gt; &lt;!-- 3.5.0版本可用 - 为了支持startPage(Object params)方法 --&gt; &lt;!-- 增加了一个`params`参数来配置参数映射，用于从Map或ServletRequest中取值 --&gt; &lt;!-- 可以配置pageNum,pageSize,count,pageSizeZero,reasonable,不配置映射的用默认值 --&gt; &lt;!-- 不理解该含义的前提下，不要随便复制该配置 --&gt; &lt;property name="params" value="pageNum=start;pageSize=limit;"/&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/configuration&gt; 接着在mybatis的配置文件中引入次配置文件：1234567&lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;!-- 自动扫描mapping.xml文件 --&gt; &lt;property name="mapperLocations" value="classpath:mapping/*.xml"&gt;&lt;/property&gt; &lt;!--加入PageHelper--&gt; &lt;property name="configLocation" value="classpath:mybatis-config.xml"/&gt;&lt;/bean&gt; 接着在service方法中：1234567891011@Overridepublic PageEntity&lt;Rediscontent&gt; selectByPage(Integer pageNum, Integer pageSize) &#123; PageHelper.startPage(pageNum, pageSize); //因为是demo，所以这里默认没有查询条件。 List&lt;Rediscontent&gt; rediscontents = rediscontentMapper.selectByExample(new RediscontentExample()); PageEntity&lt;Rediscontent&gt; rediscontentPageEntity = new PageEntity&lt;Rediscontent&gt;(); rediscontentPageEntity.setList(rediscontents); int size = rediscontentMapper.selectByExample(new RediscontentExample()).size(); rediscontentPageEntity.setCount(size); return rediscontentPageEntity;&#125; 只需要使用PageHelper.startPage(pageNum, pageSize);方法就可以帮我们简单的分页了。这里我自定义了一个分页工具类PageEntity来更方便的帮我们在之后生成JSON数据。123456789101112131415161718192021222324252627282930package com.crossoverJie.util;import java.io.Serializable;import java.util.List;/** * 分页实体 * * @param &lt;T&gt; */public class PageEntity&lt;T&gt; implements Serializable &#123; private List&lt;T&gt; list;// 分页后的数据 private Integer count; public Integer getCount() &#123; return count; &#125; public void setCount(Integer count) &#123; this.count = count; &#125; public List&lt;T&gt; getList() &#123; return list; &#125; public void setList(List&lt;T&gt; list) &#123; this.list = list; &#125;&#125; 更多PageHelper的使用请查看一下链接：https://github.com/pagehelper/Mybatis-PageHelper 前端联调接下来看下控制层RedisController:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package com.crossoverJie.controller;import com.crossoverJie.pojo.Rediscontent;import com.crossoverJie.service.RediscontentService;import com.crossoverJie.util.CommonUtil;import com.crossoverJie.util.PageEntity;import com.github.pagehelper.PageHelper;import net.sf.json.JSONArray;import net.sf.json.JSONObject;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import javax.servlet.http.HttpServletResponse;@Controller@RequestMapping("/redis")public class RedisController &#123; private static Logger logger = LoggerFactory.getLogger(RedisController.class); @Autowired private RediscontentService rediscontentService; @RequestMapping("/redis_list") public void club_list(HttpServletResponse response, @RequestParam(value = "page", defaultValue = "0") int page, @RequestParam(value = "pageSize", defaultValue = "0") int pageSize) &#123; JSONObject jsonObject = new JSONObject(); JSONObject jo = new JSONObject(); try &#123; JSONArray ja = new JSONArray(); PageHelper.startPage(1, 10); PageEntity&lt;Rediscontent&gt; rediscontentPageEntity = rediscontentService.selectByPage(page, pageSize); for (Rediscontent rediscontent : rediscontentPageEntity.getList()) &#123; JSONObject jo1 = new JSONObject(); jo1.put("rediscontent", rediscontent); ja.add(jo1); &#125; jo.put("redisContents", ja); jo.put("count", rediscontentPageEntity.getCount()); jsonObject = CommonUtil.parseJson("1", "成功", jo); &#125; catch (Exception e) &#123; jsonObject = CommonUtil.parseJson("2", "操作异常", ""); logger.error(e.getMessage(), e); &#125; //构建返回 CommonUtil.responseBuildJson(response, jsonObject); &#125;&#125; 这里就不做过多解释了，就是从redis或者是service中查询出数据并返回。 前端的显示界面在https://github.com/crossoverJie/SSM/blob/master/src/main/webapp/redis/showRedis.jsp中(并不是前端，将就看)。其中核心的redis_list.js的代码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485var page = 1, rows = 10;$(document).ready(function () &#123; initJqPaginator(); //加载 load_redis_list(); $(".query_but").click(function () &#123;//查询按钮 page = 1; load_redis_list(); &#125;);&#125;);//初始化分页function initJqPaginator() &#123; $.jqPaginator('#pagination', &#123; totalPages: 100, visiblePages: 10, currentPage: 1, first: '&lt;li class="prev"&gt;&lt;a href="javascript:;"&gt;首页&lt;/a&gt;&lt;/li&gt;', last: '&lt;li class="prev"&gt;&lt;a href="javascript:;"&gt;末页&lt;/a&gt;&lt;/li&gt;', prev: '&lt;li class="prev"&gt;&lt;a href="javascript:;"&gt;上一页&lt;/a&gt;&lt;/li&gt;', next: '&lt;li class="next"&gt;&lt;a href="javascript:;"&gt;下一页&lt;/a&gt;&lt;/li&gt;', page: '&lt;li class="page"&gt;&lt;a href="javascript:;"&gt;&#123;&#123;page&#125;&#125;&lt;/a&gt;&lt;/li&gt;', onPageChange: function (num, type) &#123; page = num; if (type == "change") &#123; load_redis_list(); &#125; &#125; &#125;);&#125;//列表function create_club_list(redisContens) &#123; var phone = 0; var html = '&lt;div class="product_box"&gt;' + '&lt;div class="br"&gt;' + '&lt;div class="product_link"&gt;' + '&lt;div class="product_phc"&gt;' + '&lt;img class="phc" src="" &gt;' + '&lt;/div&gt;' + '&lt;span class="product_name"&gt;' + redisContens.id + '&lt;/span&gt;&lt;/div&gt;' + '&lt;div class="product_link toto"&gt;' + redisContens.content + '&lt;/div&gt;' + '&lt;div class="product_link toto"&gt;' + '&lt;span&gt;' + "" + '&lt;/span&gt;' + '&lt;/div&gt;' + '&lt;div class="product_link toto"&gt;' + '&lt;span&gt;' + phone + '&lt;/span&gt;&lt;/div&gt;' + '&lt;div class="product_link toto"&gt;' + '&lt;span&gt;' + 0 + '&lt;/span&gt;&lt;/div&gt;' + '&lt;div class="product_link toto product_operation"&gt;' + '&lt;span onclick="edit_club(' + 0 + ')"&gt;编辑&lt;/span&gt;' + '&lt;span onclick="edit_del(' + 0 + ')"&gt;删除&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;' + '&lt;/div&gt;'; return html;&#125;//加载列表function load_redis_list() &#123; var name = $("#name").val(); $.ajax(&#123; type: 'POST', url: getPath() + '/redis/redis_list', async: false, data: &#123;name: name, page: page, pageSize: rows&#125;, datatype: 'json', success: function (data) &#123; if (data.result == 1) &#123; $(".product_length_number").html(data.data.count); var html = ""; var count = data.data.count; for (var i = 0; i &lt; data.data.redisContents.length; i++) &#123; var redisContent = data.data.redisContents[i]; html += create_club_list(redisContent.rediscontent); &#125; $(".product_content").html(html); //这里是分页的插件 $('#pagination').jqPaginator('option', &#123; totalPages: (Math.ceil(count / rows) &lt; 1 ? 1 : Math.ceil(count / rows)), currentPage: page &#125;); &#125; else &#123; alert(data.msg); &#125; &#125; &#125;); $(".product_box:even").css("background", "#e6e6e6");//隔行变色&#125; 其实就是一个简单的请求接口，并根据返回数据动态生成Dom而已。 总结以上就是一个简单的redis的应用。redis的应用场景还非常的多，比如现在我所在做的一个项目就有用来处理短信验证码的业务场景，之后有时间可以写一个demo。 项目地址：https://github.com/crossoverJie/SSM.gitGitHub地址：https://github.com/crossoverJie。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM(六)跨域传输]]></title>
    <url>%2F2016%2F10%2F18%2FSSM6%2F</url>
    <content type="text"><![CDATA[前言不知大家在平时的开发过程中有没有遇到过跨域访问资源的问题，我不巧在上周就碰到一个这样的问题，幸运的是在公司前端同学的帮忙下解决了该问题。 什么是跨域问题？ 只要协议、域名、端口有任何一个不同，都被当作是不同的域 只要是在不同域中是无法进行通信的。 基于以上的的出发点，我们又有跨域共享资源的需求(譬如现在流行的前后端分离之后分别部署的情况)，本文所采用的解决办法是JSONP，说到JSONP就会首先想到JSON。虽然只有一字之差但意义却完全不一样，首先科普一下JSON。 JSON 其实现在JSON已经是相当流行了，只要涉及到前后端的数据交互大都都是采用的JSON(不管是web还是android和IOS)，所以我这里就举一个例子，就算是没有用过的同学也能很快明白其中的意思。 PostMan首先给大家安利一款后端开发的利器PostMan,可以用于模拟几乎所有的HTTP请求，在开发阶段调试后端接口非常有用。这是一个Chrome插件，可以直接在google商店搜索直接下载(当然前提你懂得)。之后界面就如下：。界面非常简洁，有点开发经验的童鞋应该都会使用，不太会用的直接google下就可以了比较简单。接着我们就可以利用PostMan来发起一次请求获取JSON了。这里以我SSM项目为例,也正好有暴露一个JSON的接口。地址如下:http://www.crossoverjie.top/SSM/content_load。直接在POSTMAN中的地址栏输入该地址，采用GET的方式请求，之后所返回的就是JSON格式的字符串。由于Javascript原生的就支持JSON，所以解析起来非常方便。 JSONP好了，终于可以谈谈JSONP了。之前说道JSONP是用来解决跨域问题的，那么他是如何解决的呢。经过我们开发界的前辈们发现，HTML中拥有SRC属性的标签都不受跨域的影响，比如：&lt;script&gt;、&lt;img&gt;、&lt;iframe&gt;标签。由于JS原生支持JSON的解析，于是我们采用&lt;script&gt;的方式来处理跨域解析，代码如下一看就明白。web端:1234567891011121314151617181920212223242526272829303132&lt;html lang="zh"&gt;&lt;head&gt; &lt;script type="text/javascript"&gt; $(document).ready(function()&#123; $.ajax(&#123; type: "get", async: false, url: "http://www.crossoverjie.top/SSM/jsonpInfo?callback=getUser&amp;userId=3", dataType: "jsonp", jsonp: "callback",//一般默认为:callback jsonpCallback:"getUser",//自定义的jsonp回调函数名称，默认为jQuery自动生成的随机函数名，也可以写"?"，jQuery会自动为你处理数据 success: function(json)&#123; /** * 获得服务器返回的信息。 * 可以做具体的业务处理。 */ alert('用户信息：ID： ' + json.userId + ' ，姓名： ' + json.username + '。'); &#125;, error: function()&#123; alert('fail'); &#125; &#125;); &#125;); &lt;/script&gt;&lt;/head&gt;&lt;body oncontextmenu="return false"&gt;&lt;/body&gt;&lt;/html&gt; 其中我们采用了JQuery给我封装好的函数，这样就可以自动帮我们解析了。首先我们来看下代码中的http://www.crossoverjie.top/SSM/jsonpInfo?callback=getUser&amp;userId=3这个地址返回的是什么内容，还是放到POSTMAN中执行如下：。可以看到我们所传递的callback参数带着查询的数据又原封不动的返回给我们了，这样的话即使我们不使用JQuery给我封装好的函数，我们自定义一个和callback名称一样的函数一样是可以解析其中的数据的，只是Jquery帮我们做了而已。 前端没问题了，那么后端又是如何实现的呢？也很简单，如下：1234567@RequestMapping(value = "/jsonpInfo",method = &#123; RequestMethod.GET &#125;)@ResponseBodypublic Object jsonpInfo(String callback,Integer userId) throws IOException &#123; User user = userService.getUserById(userId); JSONPObject jsonpObject = new JSONPObject(callback,user) ; return jsonpObject ;&#125; 后端采用了jackson中的JSONPObject这个类的一个构造方法，只需要将callback字段和需要转成JSON字符串的对象放进去即可。需要主要的是需要使用@ResponseBody注解才能成功返回。 总结其实网上还有其他的方法来处理跨域问题，不过我觉得这样的方式最为简单。同样JSONP也是有缺点的，比如：只支持GET方式的HTTP请求。以上代码依然在博主的SSM项目中，如有需要可以直接FORK。 项目地址：https://github.com/crossoverJie/SSM.git 个人博客地址：http://crossoverjie.top。 GitHub地址：https://github.com/crossoverJie。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JSONP</tag>
        <tag>JSON</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux（二）服务器运行环境配置]]></title>
    <url>%2F2016%2F09%2F20%2FLinux-normal2%2F</url>
    <content type="text"><![CDATA[前言Linux相信对大多数程序员来说都不陌生，毕竟在服务器端依然还是霸主地位而且丝毫没有退居二线的意思，以至于现在几乎每一个软件开发的相关人员都得或多或少的知道一些Linux的相关内容，本文将介绍如何在刚拿到一台云服务器(采用centos)来进行运行环境的搭建，包括JDK、Mysql、Tomcat以及nginx。相信对于小白来说很有必要的，也是我个人的一个记录。 该服务器的用途是用于部署JavaEE项目。部署之后的效果图如下: JDK安装由于我们之后需要部署的是JavaEE项目，所以首先第一步就是安装JDK了。 卸载自带的openJDK现在的服务器拿来之后一般都是默认给我们安装一个openJDK，首先我们需要卸载掉。 使用rpm -qa | grep java命令查看系统中是否存在有Java。 使用rpm -e --nodeps 相关应用名称来进行卸载。(相关应用名称就是上一个命令中显示出来的名称复制到这里卸载即可)。 下载并安装JDK 之后是下载ORACLE所提供的JDK，传送门根据自己系统的情况下载对应版本即可。笔者使用的是jdk-8u101-linux-x64.rpm版本。 然后使用FTP工具上传到/usr/java目录下即可，没有java目录新建一个即可。 然后使用rpm -ivh jdk-8u101-linux-x64.rpm命令进行解压安装。 profile文件配置安装完成之后使用vi /etc/profile命令编辑profile文件(注意该文件路径是指根目录下的etc文件夹不要找错了)。在该文件中加入以下内容：123export JAVA_HOME=/usr/java/jdk-8u101-linux-x64export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarexport PATH=$PATH:$JAVA_HOME/bin 保存之后运行source /etc/profile使配置生效。 验证是否安装成功之后我们使用在windows平台也有的命令java -version，如果输出如图：表示安装成功。 MySQL安装卸载自带的Mysql首先第一步还是要卸载掉自带的mysql。rpm -e --nodeps mysql命令和之前一样只是把应用名称换成mysql了而已。 使用yum来安装mysql之后我们采用yum来安装mysql。这样的方式最简单便捷。yum install -y mysql-server mysql mysql-deve执行该命令直到出现Complete!提示之后表示安装成功。rpm -qi mysql-server之后使用该命令可以查看我们安装的mysql信息。 mysql相关配置使用service mysqld start来启动mysql服务(第一次会输出很多信息)，之后就不会了。然后我们可以使用chkconfig mysqld on命令将mysql设置为开机启动。输入chkconfig --list | grep mysql命令显示如下图：表示设置成功。使用mysqladmin -u root password &#39;root&#39;为root账户设置密码。 设置远程使用1234grant all privileges on *.* to &apos;root&apos;@&apos;%&apos; identified by &apos;123456&apos; with grant option;# root是用户名，%代表任意主机，&apos;123456&apos;指定的登录密码（这个和本地的root密码可以设置不同的，互不影响）flush privileges; # 重载系统权限exit; 验证使用使用mysql -u root -proot来登录mysql。如果出现以下界面表示设置成功。 Tomcat安装Tomcat也是我们运行JavaEE项目必备的一个中间件。 第一步需要下载linux的Tomcat，传送门。根据自己系统版本进行下载即可。之后将apache-tomcat-8.5.5.tar.gz上传到/usr/local目录中。 解压该压缩包tar -zxv -f apache-tomcat-8.5.5.tar.gz,再使用mv apache-tomcat-8.5.5 tomcat将解压的Tomcat移动到外层的Tomcat目录中。 进入/usr/local/tomcat/apache-tomcat-8.5.5/bin目录使用./startup.bat命令启动tomcat。 因为tomcat使用的默认端口是8080，linux防火墙默认是不能访问的，需要手动将其打开。使用vi + /etc/sysconfig/iptables编辑iptables(注意etc目录是根目录下的)，加入以下代码:12-A RH-Firewall-1-INPUT -m state --state NEW -m tcp -p tcp --dport 8080 -j ACCEPT-A RH-Firewall-1-INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT 这里我们开放了8080和80端口，之后安装nginx就不用在开放了。 ps:这里用到了简单的vim命令。按i进入插入模式，输入上面两段代码。之后按esc退出插入模式。再按:wq保存关闭即可。之后使用service iptables restart命令重启防火墙即可。在浏览器输入服务器的ip+8080如果出现Tomcat的欢迎页即表明Tomcat安装成功。 nginx安装最后是安装nginx，这里我们还是使用最简单的yum的方式来进行安装。 首先使用以下几个命令安装必备的几个库： 123yum -y install pcre*yum -y install openssl*yum -y install gcc 之后安装nginx。 1234567cd /usr/local/wget http://nginx.org/download/nginx-1.4.2.tar.gztar -zxvf nginx-1.4.2.tar.gzcd nginx-1.4.2 ./configure --prefix=/usr/local/nginx --with-http_stub_status_modulemakemake install 之后就可以使用/usr/local/nginx/sbin/nginx命令来启动nginx了。输入服务器的IP地址，如果出现nginx的欢迎界面表示安装成功了。 nginx配置这里我就简单贴以下我的配置，主要就是配置一个upstream,之后在server中引用配置的那个upstream即可。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125#user nobody;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; # &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; # &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; upstream crossover_main &#123; server 127.0.0.1:8080; &#125; server &#123; listen 80; server_name www.crossoverjie.top; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; proxy_pass http://crossover_main/examples/; proxy_set_header Host $http_host; proxy_set_header X-Forwarded-For $remote_addr; index index.jsp; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache&apos;s document root # concurs with nginx&apos;s one # #location ~ /\.ht &#123; # deny all; #&#125; &#125; # another virtual host using mix of IP-, name-, and port-based configuration # #server &#123; # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; # HTTPS server # #server &#123; # listen 443; # server_name localhost; # ssl on; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_timeout 5m; # ssl_protocols SSLv2 SSLv3 TLSv1; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125;&#125; 之后我们在地址栏输入服务器的IP地址(如果有域名解析了服务器的IP可以直接输入域名)就会进入我们在upstream中配置的地址加上在server中的地址。根据我这里的配置最后解析地址就是http://127.0.0.1:8080/examples应该是很好理解的。最终的结果是我在片头放的那张截图一样。 总结这是一个简单的基于centOS的运行环境配置，对于小白练手应该是够了，有不清楚和错误的地方欢迎指出反正我也不会回复。 个人博客地址：http://crossoverjie.top。 GitHub地址：https://github.com/crossoverJie。]]></content>
      <categories>
        <category>Linux笔记</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>centos</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM(五)基于webSocket的聊天室]]></title>
    <url>%2F2016%2F09%2F04%2FSSM5%2F</url>
    <content type="text"><![CDATA[前言不知大家在平时的需求中有没有遇到需要实时处理信息的情况，如站内信，订阅，聊天之类的。在这之前我们通常想到的方法一般都是采用轮训的方式每隔一定的时间向服务器发送请求从而获得最新的数据，但这样会浪费掉很多的资源并且也不是实时的，于是随着HTML5的推出带来了websocket可以根本的解决以上问题实现真正的实时传输。 websocket是什么？至于websocket是什么、有什么用这样的问题一Google一大把，这里我就简要的说些websocket再本次实例中的作用吧。由于在本次实例中需要实现的是一个聊天室，一个实时的聊天室。如下图：采用websocket之后可以让前端和和后端像C/S模式一样实时通信，不再需要每次单独发送请求。由于是基于H5的所以对于老的浏览器如IE7、IE8之类的就没办法了，不过H5是大势所趋这点不用担心。 后端既然推出了websocket，作为现在主流的Java肯定也有相应的支持，所以在JavaEE7之后也对websocket做出了规范，所以本次的代码理论上是要运行在Java1.7+和Tomcat7.0+之上的。看过我前面几篇文章的朋友应该都知道本次实例也是运行在之前的SSM之上的，所以这里就不再赘述了。首先第一步需要加入websocket的依赖：123456789101112&lt;!-- https://mvnrepository.com/artifact/javax.websocket/javax.websocket-api --&gt;&lt;dependency&gt; &lt;groupId&gt;javax.websocket&lt;/groupId&gt; &lt;artifactId&gt;javax.websocket-api&lt;/artifactId&gt; &lt;version&gt;1.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-websocket&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt; 以上就是使用websocket所需要用到的包。spring-websocket这个主要是在之后需要在websocket的后端注入service所需要的。之后再看一下后端的核心代码MyWebSocket.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135package com.crossoverJie.controller;/** * Created by Administrator on 2016/8/7. */import com.crossoverJie.pojo.Content;import com.crossoverJie.service.ContentService;import org.apache.camel.BeanInject;import org.apache.camel.EndpointInject;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;import org.springframework.stereotype.Controller;import org.springframework.web.context.support.SpringBeanAutowiringSupport;import org.springframework.web.socket.server.standard.SpringConfigurator;import java.io.IOException;import java.text.SimpleDateFormat;import java.util.Date;import java.util.concurrent.CopyOnWriteArraySet;import javax.annotation.PostConstruct;import javax.websocket.OnClose;import javax.websocket.OnError;import javax.websocket.OnMessage;import javax.websocket.OnOpen;import javax.websocket.Session;import javax.websocket.server.ServerEndpoint;//该注解用来指定一个URI，客户端可以通过这个URI来连接到WebSocket。/** 类似Servlet的注解mapping。无需在web.xml中配置。 * configurator = SpringConfigurator.class是为了使该类可以通过Spring注入。 */@ServerEndpoint(value = "/websocket",configurator = SpringConfigurator.class)public class MyWebSocket &#123; //静态变量，用来记录当前在线连接数。应该把它设计成线程安全的。 private static int onlineCount = 0; public MyWebSocket() &#123; &#125; @Autowired private ContentService contentService ; //concurrent包的线程安全Set，用来存放每个客户端对应的MyWebSocket对象。 // 若要实现服务端与单一客户端通信的话，可以使用Map来存放，其中Key可以为用户标识 private static CopyOnWriteArraySet&lt;MyWebSocket&gt; webSocketSet = new CopyOnWriteArraySet&lt;MyWebSocket&gt;(); //与客户端的连接会话，需要通过它来给客户端发送数据 private Session session; /** * 连接建立成功调用的方法 * @param session 可选的参数。session为与某个客户端的连接会话，需要通过它来给客户端发送数据 */ @OnOpen public void onOpen(Session session)&#123; this.session = session; webSocketSet.add(this); //加入set中 addOnlineCount(); //在线数加1 System.out.println("有新连接加入！当前在线人数为" + getOnlineCount()); &#125; /** * 连接关闭调用的方法 */ @OnClose public void onClose()&#123; webSocketSet.remove(this); //从set中删除 subOnlineCount(); //在线数减1 System.out.println("有一连接关闭！当前在线人数为" + getOnlineCount()); &#125; /** * 收到客户端消息后调用的方法 * @param message 客户端发送过来的消息 * @param session 可选的参数 */ @OnMessage public void onMessage(String message, Session session) &#123; System.out.println("来自客户端的消息:" + message); //群发消息 for(MyWebSocket item: webSocketSet)&#123; try &#123; item.sendMessage(message); &#125; catch (IOException e) &#123; e.printStackTrace(); continue; &#125; &#125; &#125; /** * 发生错误时调用 * @param session * @param error */ @OnError public void onError(Session session, Throwable error)&#123; System.out.println("发生错误"); error.printStackTrace(); &#125; /** * 这个方法与上面几个方法不一样。没有用注解，是根据自己需要添加的方法。 * @param message * @throws IOException */ public void sendMessage(String message) throws IOException&#123; //保存数据到数据库 Content content = new Content() ; content.setContent(message); SimpleDateFormat sm = new SimpleDateFormat("yyyy-MM-dd HH:mm:dd") ; content.setCreateDate(sm.format(new Date())); contentService.insertSelective(content) ; this.session.getBasicRemote().sendText(message); //this.session.getAsyncRemote().sendText(message); &#125; public static synchronized int getOnlineCount() &#123; return onlineCount; &#125; public static synchronized void addOnlineCount() &#123; MyWebSocket.onlineCount++; &#125; public static synchronized void subOnlineCount() &#123; MyWebSocket.onlineCount--; &#125;&#125; 这就是整个websocket的后端代码。看起来也比较简单主要就是使用那几个注解。每当有一个客户端连入、关闭、发送消息都会调用各自注解的方法。这里我讲一下sendMessage()这个方法。 websocket绕坑在sendMessage()方法中我只想实现一个简单的功能，就是将每次的聊天记录都存到数据库中。看似一个简单的功能硬是花了我半天的时间。我先是按照以前的惯性思维只需要在这个类中注入service即可。但是无论怎么弄每次都注入不进来都是null。最后没办法只有google了，最后终于在神级社区StackOverFlow中找到了答案，就是前边所说的需要添加的第二个 maven依赖，然后加入@ServerEndpoint(value = &quot;/websocket&quot;,configurator = SpringConfigurator.class)这个注解即可利用Spring注入了。接着就可以做消息的保存了。 前端前端我采用了Bootstrap做的，不太清楚Bootstrap的童鞋建议先看下官方文档也比较简单。还是先贴一下代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146&lt;%@ page language="java" import="java.util.*" pageEncoding="UTF-8" %&gt;&lt;% String path = request.getContextPath(); String basePath = request.getScheme() + "://" + request.getServerName() + ":" + request.getServerPort() + path + "/";%&gt;&lt;!DOCTYPE HTML&gt;&lt;html&gt;&lt;head&gt; &lt;base href="&lt;%=basePath%&gt;"&gt; &lt;!-- Bootstrap --&gt; &lt;link rel="stylesheet" href="http://cdn.bootcss.com/bootstrap/3.3.5/css/bootstrap.min.css"&gt; &lt;!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries --&gt; &lt;!-- WARNING: Respond.js doesn't work if you view the page via file:// --&gt; &lt;!--[if lt IE 9]&gt; &lt;script src="//cdn.bootcss.com/html5shiv/3.7.2/html5shiv.min.js"&gt;&lt;/script&gt; &lt;script src="//cdn.bootcss.com/respond.js/1.4.2/respond.min.js"&gt;&lt;/script&gt; &lt;![endif]--&gt; &lt;script type="text/javascript" charset="utf-8" src="&lt;%=path%&gt;/ueditor/ueditor.config.js"&gt;&lt;/script&gt; &lt;script type="text/javascript" charset="utf-8" src="&lt;%=path%&gt;/ueditor/ueditor.all.min.js"&gt; &lt;/script&gt; &lt;!--建议手动加在语言，避免在ie下有时因为加载语言失败导致编辑器加载失败--&gt; &lt;!--这里加载的语言文件会覆盖你在配置项目里添加的语言类型，比如你在配置项目里配置的是英文，这里加载的中文，那最后就是中文--&gt; &lt;script type="text/javascript" charset="utf-8" src="&lt;%=path%&gt;/ueditor/lang/zh-cn/zh-cn.js"&gt;&lt;/script&gt; &lt;title&gt;聊天室&lt;/title&gt;&lt;/head&gt;&lt;body data="/ssm"&gt;&lt;input id="text" type="text"/&gt;&lt;button onclick="send()"&gt;发送&lt;/button&gt;&lt;button onclick="closeWebSocket()"&gt;关闭连接&lt;/button&gt;&lt;div id="message"&gt;&lt;/div&gt;&lt;div class="container-fluid"&gt; &lt;div class="row"&gt; &lt;div class="col-md-12"&gt; &lt;div class="panel panel-primary"&gt; &lt;div class="panel-heading"&gt;聊天室&lt;/div&gt; &lt;div id="msg" class="panel-body"&gt; &lt;/div&gt; &lt;div class="panel-footer"&gt; 在线人数&lt;span id="onlineCount"&gt;1&lt;/span&gt;人 &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="container-fluid"&gt; &lt;div class="row"&gt; &lt;div class="col-md-12"&gt; &lt;script id="editor" type="text/plain" style="width:1024px;height:200px;"&gt;&lt;/script&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="container-fluid"&gt; &lt;div class="row"&gt; &lt;div class="col-md-12"&gt; &lt;p class="text-right"&gt; &lt;button onclick="sendMsg();" class="btn btn-success"&gt;发送&lt;/button&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;script type="text/javascript"&gt; var ue = UE.getEditor('editor'); var websocket = null; //判断当前浏览器是否支持WebSocket if ('WebSocket' in window) &#123; websocket = new WebSocket("ws://192.168.0.102:8080/ssm/websocket"); &#125; else &#123; alert("对不起！你的浏览器不支持webSocket") &#125; //连接发生错误的回调方法 websocket.onerror = function () &#123; setMessageInnerHTML("error"); &#125;; //连接成功建立的回调方法 websocket.onopen = function (event) &#123; setMessageInnerHTML("加入连接"); &#125;; //接收到消息的回调方法 websocket.onmessage = function (event) &#123; setMessageInnerHTML(event.data); &#125;; //连接关闭的回调方法 websocket.onclose = function () &#123; setMessageInnerHTML("断开连接"); &#125;; //监听窗口关闭事件，当窗口关闭时，主动去关闭websocket连接， // 防止连接还没断开就关闭窗口，server端会抛异常。 window.onbeforeunload = function () &#123; var is = confirm("确定关闭窗口？"); if (is)&#123; websocket.close(); &#125; &#125;; //将消息显示在网页上 function setMessageInnerHTML(innerHTML) &#123; $("#msg").append(innerHTML+"&lt;br/&gt;") &#125;; //关闭连接 function closeWebSocket() &#123; websocket.close(); &#125; //发送消息 function send() &#123; var message = $("#text").val() ; websocket.send(message); $("#text").val("") ; &#125; function sendMsg()&#123; var msg = ue.getContent(); websocket.send(msg); ue.setContent(''); &#125;&lt;/script&gt;&lt;!-- jQuery (necessary for Bootstrap's JavaScript plugins) --&gt;&lt;script src="http://cdn.bootcss.com/jquery/1.11.3/jquery.min.js"&gt;&lt;/script&gt;&lt;!-- Include all compiled plugins (below), or include individual files as needed --&gt;&lt;script src="http://cdn.bootcss.com/bootstrap/3.3.5/js/bootstrap.min.js"&gt;&lt;/script&gt;&lt;script type="text/javascript" src="&lt;%=path%&gt;/js/Globals.js"&gt;&lt;/script&gt;&lt;script type="text/javascript" src="&lt;%=path%&gt;/js/websocket.js"&gt;&lt;/script&gt;&lt;/html&gt; 其实其中重要的就是那几个JS方法，都写有注释。需要注意的是这里1234567//判断当前浏览器是否支持WebSocketif ('WebSocket' in window) &#123; websocket = new WebSocket("ws://192.168.0.102:8080/ssm/websocket");&#125;else &#123; alert("对不起！你的浏览器不支持webSocket")&#125; 当项目跑起来之后需要将这里的地址改为你项目的地址即可。哦对了，我在这里采用了百度的一个Ueditor的富文本编辑器(虽然百度搜索我现在很少用了，但是这个编辑器确实还不错)，这个编辑器也比较简单只需要个性化的配置一下个人的需求即可。 Ueditor相关配置直接使用我项目运行的童鞋就不需要重新下载了，我将资源放在了webapp目录下的ueditor文件夹下面的。值得注意的是我们首先需要将jsp--&gt;lib下的jar包加入到项目中。加好之后会出现一个想下的箭头表示已经引入成功。，之后修改该目录下的config.json文件，主要修改以下内容即可：123456"imageAllowFiles": [".png", ".jpg", ".jpeg", ".gif", ".bmp"], /* 上传图片格式显示 */"imageCompressEnable": true, /* 是否压缩图片,默认是true */"imageCompressBorder": 1600, /* 图片压缩最长边限制 */"imageInsertAlign": "none", /* 插入的图片浮动方式 */"imageUrlPrefix": "http://192.168.0.102:8080/ssm", /* 图片访问路径前缀 */"imagePathFormat": "/ueditor/jsp/upload/image/&#123;yyyy&#125;&#123;mm&#125;&#123;dd&#125;/&#123;time&#125;&#123;rand:6&#125;", 这里主要是要修改imageUrlPrefix为你自己的项目地址就可以了。ueditor一个我认为很不错的就是他支持图片、多图、截图上传，而且都不需要手动编写后端接口，所有上传的文件、图片都会保存到项目发布出去的jsp--&gt;upload文件夹下一看就明白了。更多关于ueditor的配置可以查看官网。 其中值得注意一点的是，由于项目采用了Spring MVC并拦截了所有的请求，导致静态资源不能访问，如果是需要用到上传txt文件之类的需求可以参照web.xml中修改，如下:1234&lt;servlet-mapping&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;url-pattern&gt;*.txt&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 这样就可以访问txt文件了，如果还需要上传PPT之类的就以此类推。 总结这样一个简单的基于websocket的聊天室就算完成了，感兴趣的朋友可以将项目部署到外网服务器上这样好基友之间就可以愉快的聊(zhuang)天(bi)了。当然这只是一个简单的项目，感兴趣的朋友再这基础之上加入实时在线人数，用户名和IP之类的。 项目地址：https://github.com/crossoverJie/SSM.git个人博客地址：http://crossoverjie.top。GitHub地址：https://github.com/crossoverJie。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>websocket</tag>
        <tag>HTML5</tag>
        <tag>ueditor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM(四)WebService入门详解]]></title>
    <url>%2F2016%2F08%2F02%2FSSM4%2F</url>
    <content type="text"><![CDATA[前言webservice这个不知道大家首次接触的时候是怎么理解的，反正我记得我当时第一次接触这个东西的时候以为又是一个XX框架，觉得还挺高大上。然而这一切在之后我使用过后才发现这些全都是YY。那么webservice到底是什么呢，根据我自己的理解：简单来说就像是一个公开的接口，其他系统不管你是用什么语言来编写的都可以调用这个接口，并可以返回相应的数据给你。就像是现在很多的天气应用，他们肯定不会自己去搞一个气象局之类的部门去监测天气，大多都是直接调用一个天气接口，然后返回天气数据，相关应用就可以将这些信息展示给用户了。通常来说发布这类接口的应用都是用一两种语言来编写即可，但是调用这个接口应用可能会是各种语言来编写的，为了满足这样的需求webservice出现了。 简单来说webservice就是为了满足以上需求而定义出来的规范。 Spring整合CXF在Java中实现webservice有多种方法，java本身在jdk1.7之后也对webservice有了默认的实现，但是在我们实际开发中一般还是会使用框架来，比如这里所提到的CXF就有着广泛的应用。废话我就不多说了，直接讲Spring整合CXF，毕竟现在的JavaEE开发是离不开Spring了。该项目还是基于之前的SSM进行开发的。 加入maven依赖第一步肯定是要加入maven依赖：12345678910111213141516171819&lt;!--cxf--&gt;&lt;!-- https://mvnrepository.com/artifact/org.apache.cxf/cxf-rt-frontend-jaxws --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.cxf&lt;/groupId&gt; &lt;artifactId&gt;cxf-rt-frontend-jaxws&lt;/artifactId&gt; &lt;version&gt;3.1.6&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.apache.cxf/cxf-core --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.cxf&lt;/groupId&gt; &lt;artifactId&gt;cxf-core&lt;/artifactId&gt; &lt;version&gt;3.1.6&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.apache.cxf/cxf-rt-transports-http --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.cxf&lt;/groupId&gt; &lt;artifactId&gt;cxf-rt-transports-http&lt;/artifactId&gt; &lt;version&gt;3.1.6&lt;/version&gt;&lt;/dependency&gt; web.xml配置接着我们需要配置一个CXF的servlet：123456789&lt;!--定义一个cxf的servlet--&gt;&lt;servlet&gt; &lt;servlet-name&gt;CXFServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.apache.cxf.transport.servlet.CXFServlet&lt;/servlet-class&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;CXFServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/webservice/*&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 之后只要我们访问webservice/*这个地址就会进入CXF的servlet中。 整合Spring配置接下来是最重要的一部，用Spring整合CXF：在这之前我有新建一个CXF的包，如下图：这里有两个主要类 HelloWorld接口。 实现HelloWorld接口的HelloWorldImpl类。代码如下：HelloWorld.java12345678package com.crossoverJie.cxf;import javax.jws.WebService;@WebServicepublic interface HelloWorld &#123; public String say(String str);&#125; 其中就只定义了一个简单的say()方法。HelloWorldImpl.java1234567891011package com.crossoverJie.cxf.impl;import com.crossoverJie.cxf.HelloWorld;import org.springframework.stereotype.Component;import javax.jws.WebService;@Component("helloWorld")@WebServicepublic class HelloWorldImpl implements HelloWorld &#123; public String say(String str) &#123; return "Hello"+str; &#125;&#125; 这里就是对say()方法的简单实现。接下来就是整合Spring了，由于需要使用到CXF的标签，所以我们需要添加额外的命名路径如下： 1234567891011121314151617181920212223242526&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:p="http://www.springframework.org/schema/p" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:context="http://www.springframework.org/schema/context" xmlns:jee="http://www.springframework.org/schema/jee" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:jaxws="http://cxf.apache.org/jaxws" xsi:schemaLocation=" http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.0.xsd http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd http://www.springframework.org/schema/jee http://www.springframework.org/schema/jee/spring-jee-4.0.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.0.xsd http://cxf.apache.org/jaxws http://cxf.apache.org/schemas/jaxws.xsd"&gt; &lt;import resource="classpath:META-INF/cxf/cxf.xml"/&gt; &lt;import resource="classpath:META-INF/cxf/cxf-servlet.xml"/&gt; &lt;!-- 自动扫描webService --&gt; &lt;context:component-scan base-package="com.crossoverJie.cxf" /&gt; &lt;!-- 定义webservice的发布接口 --&gt; &lt;jaxws:endpoint implementor="#helloWorld" address="/HelloWorld"&lt;/beans&gt; 更加具体的配置可以查看官方给出的文档:http://cxf.apache.org/docs/how-do-i-develop-a-service.html。#helloWorld指的是我们在HelloWorldImpl类中所自定义的名字，/HelloWorld则是我们需要访问的地址。之后我们运行项目输入该地址：http://127.0.0.1:8080/ssm/webservice/HelloWorld?wsdl如果出现如下界面：则说明我们的webservice发布成功了。接下来只需要通过客户端调用这个接口即可获得返回结果了。 总结以上就是一个简单的webservice入门实例，更多的关于CXF拦截器，客户端调用就没有做过多介绍，后续有时间的话再接着更新。 项目地址：https://github.com/crossoverJie/SSM.git个人博客地址：http://crossoverjie.top。GitHub地址：https://github.com/crossoverJie。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>IDEA</tag>
        <tag>CXF</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM(三)Shiro使用详解]]></title>
    <url>%2F2016%2F07%2F15%2FSSM3%2F</url>
    <content type="text"><![CDATA[前言相比有做过企业级开发的童鞋应该都有做过权限安全之类的功能吧，最先开始我采用的是建用户表,角色表,权限表，之后在拦截器中对每一个请求进行拦截，再到数据库中进行查询看当前用户是否有该权限，这样的设计能满足大多数中小型系统的需求。不过这篇所介绍的Shiro能满足之前的所有需求，并且使用简单，安全性高，而且现在越来越的多企业都在使用Shiro，这应该是一个收入的你的技能库。 创建自定义MyRealm类有关Shiro的基础知识我这里就不过多介绍了，直接来干货，到最后会整合Spring来进行权限验证。首先在使用Shiro的时候我们要考虑在什么样的环境下使用： 登录的验证 对指定角色的验证 对URL的验证 基本上我们也就这三个需求，所以同时我们也需要三个方法： findUserByUserName(String username)根据username查询用户，之后Shiro会根据查询出来的User的密码来和提交上来的密码进行比对。 findRoles(String username)根据username查询该用户的所有角色，用于角色验证。 findPermissions(String username)根据username查询他所拥有的权限信息，用于权限判断。 下面我贴一下我的mapper代码(PS:该项目依然是基于之前的SSM，不太清楚整合的请看SSM一)。123456789101112131415161718192021222324252627&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd" &gt;&lt;mapper namespace="com.crossoverJie.dao.T_userDao" &gt; &lt;resultMap id="BaseResultMap" type="com.crossoverJie.pojo.T_user" &gt; &lt;result property="id" column="id"/&gt; &lt;result property="userName" column="userName"/&gt; &lt;result property="password" column="password"/&gt; &lt;result property="roleId" column="roleId"/&gt; &lt;/resultMap&gt; &lt;sql id="Base_Column_List" &gt; id, username, password,roleId &lt;/sql&gt; &lt;select id="findUserByUsername" parameterType="String" resultMap="BaseResultMap"&gt; select &lt;include refid="Base_Column_List"/&gt; from t_user where userName=#&#123;userName&#125; &lt;/select&gt; &lt;select id="findRoles" parameterType="String" resultType="String"&gt; select r.roleName from t_user u,t_role r where u.roleId=r.id and u.userName=#&#123;userName&#125; &lt;/select&gt; &lt;select id="findPermissions" parameterType="String" resultType="String"&gt; select p.permissionName from t_user u,t_role r,t_permission p where u.roleId=r.id and p.roleId=r.id and u.userName=#&#123;userName&#125; &lt;/select&gt;&lt;/mapper&gt; 很简单只有三个方法，分别对应上面所说的三个方法。对sql稍微熟悉点的童鞋应该都能看懂，不太清楚就拷到数据库中执行一下就行了，数据库的Sql也在我的github上。实体类就比较简单了，就只有四个字段以及get,set方法。我就这里就不贴了，具体可以去github上fork我的源码。 现在就需要创建自定义的MyRealm类，这个还是比较重要的。继承至Shiro的AuthorizingRealm类，用于处理自己的验证逻辑，下面贴一下我的代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package com.crossoverJie.shiro;import com.crossoverJie.pojo.T_user;import com.crossoverJie.service.T_userService;import org.apache.shiro.authc.AuthenticationException;import org.apache.shiro.authc.AuthenticationInfo;import org.apache.shiro.authc.AuthenticationToken;import org.apache.shiro.authc.SimpleAuthenticationInfo;import org.apache.shiro.authz.AuthorizationInfo;import org.apache.shiro.authz.SimpleAuthorizationInfo;import org.apache.shiro.realm.AuthorizingRealm;import org.apache.shiro.subject.PrincipalCollection;import javax.annotation.Resource;import java.util.Set;/** * Created with IDEA * Created by $&#123;jie.chen&#125; on 2016/7/14. * Shiro自定义域 */public class MyRealm extends AuthorizingRealm &#123; @Resource private T_userService t_userService; /** * 用于的权限的认证。 * @param principalCollection * @return */ @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principalCollection) &#123; String username = principalCollection.getPrimaryPrincipal().toString() ; SimpleAuthorizationInfo info = new SimpleAuthorizationInfo() ; Set&lt;String&gt; roleName = t_userService.findRoles(username) ; Set&lt;String&gt; permissions = t_userService.findPermissions(username) ; info.setRoles(roleName); info.setStringPermissions(permissions); return info; &#125; /** * 首先执行这个登录验证 * @param token * @return * @throws AuthenticationException */ @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException &#123; //获取用户账号 String username = token.getPrincipal().toString() ; T_user user = t_userService.findUserByUsername(username) ; if (user != null)&#123; //将查询到的用户账号和密码存放到 authenticationInfo用于后面的权限判断。第三个参数随便放一个就行了。 AuthenticationInfo authenticationInfo = new SimpleAuthenticationInfo(user.getUserName(),user.getPassword(), "a") ; return authenticationInfo ; &#125;else&#123; return null ; &#125; &#125;&#125; 继承AuthorizingRealm类之后就需要覆写它的两个方法，doGetAuthorizationInfo,doGetAuthenticationInfo，这两个方法的作用我都有写注释，逻辑也比较简单。doGetAuthenticationInfo是用于登录验证的，在登录的时候需要将数据封装到Shiro的一个token中，执行shiro的login()方法，之后只要我们将MyRealm这个类配置到Spring中，登录的时候Shiro就会自动的调用doGetAuthenticationInfo()方法进行验证。哦对了，忘了贴下登录的Controller了：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package com.crossoverJie.controller;import com.crossoverJie.pojo.T_user;import com.crossoverJie.service.T_userService;import org.apache.shiro.SecurityUtils;import org.apache.shiro.authc.UsernamePasswordToken;import org.apache.shiro.subject.Subject;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.RequestMapping;import javax.annotation.Resource;/** * Created with IDEA * Created by $&#123;jie.chen&#125; on 2016/7/14. * 后台Controller */@Controller@RequestMapping("/")public class T_userController &#123; @Resource private T_userService t_userService ; @RequestMapping("/loginAdmin") public String login(T_user user, Model model)&#123; Subject subject = SecurityUtils.getSubject() ; UsernamePasswordToken token = new UsernamePasswordToken(user.getUserName(),user.getPassword()) ; try &#123; subject.login(token); return "admin" ; &#125;catch (Exception e)&#123; //这里将异常打印关闭是因为如果登录失败的话会自动抛异常// e.printStackTrace(); model.addAttribute("error","用户名或密码错误") ; return "../../login" ; &#125; &#125; @RequestMapping("/admin") public String admin()&#123; return "admin"; &#125; @RequestMapping("/student") public String student()&#123; return "admin" ; &#125; @RequestMapping("/teacher") public String teacher()&#123; return "admin" ; &#125;&#125; 主要就是login()方法。逻辑比较简单，只是登录验证的时候不是像之前那样直接查询数据库然后返回是否有用户了，而是调用subject的login()方法,就是我上面提到的，调用login()方法时Shiro会自动调用我们自定义的MyRealm类中的doGetAuthenticationInfo()方法进行验证的，验证逻辑是先根据用户名查询用户，如果查询到的话再将查询到的用户名和密码放到SimpleAuthenticationInfo对象中，Shiro会自动根据用户输入的密码和查询到的密码进行匹配，如果匹配不上就会抛出异常，匹配上之后就会执行doGetAuthorizationInfo()进行相应的权限验证。doGetAuthorizationInfo()方法的处理逻辑也比较简单，根据用户名获取到他所拥有的角色以及权限，然后赋值到SimpleAuthorizationInfo对象中即可，Shiro就会按照我们配置的XX角色对应XX权限来进行判断，这个配置在下面的整合中会讲到。 整合Spring接下来应该是大家比较关系的一步：整合Spring。我是在之前的Spring SpringMVC Mybatis的基础上进行整合的。 web.xml配置首先我们需要在web.xml进行配置Shiro的过滤器。我只贴Shiro部分的，其余的和之前配置是一样的。1234567891011121314&lt;!-- shiro过滤器定义 --&gt;&lt;filter&gt; &lt;filter-name&gt;shiroFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy&lt;/filter-class&gt; &lt;init-param&gt; &lt;!-- 该值缺省为false,表示生命周期由SpringApplicationContext管理,设置为true则表示由ServletContainer管理 --&gt; &lt;param-name&gt;targetFilterLifecycle&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;shiroFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 配置还是比较简单的，这样会过滤所有的请求。之后我们还需要在Spring中配置一个shiroFilter的bean。 spring-mybatis.xml配置由于这里配置较多，我就全部贴一下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.1.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.1.xsd"&gt; &lt;!-- 自动扫描 --&gt; &lt;context:component-scan base-package="com.crossoverJie" /&gt; &lt;!-- 引入配置文件 --&gt; &lt;bean id="propertyConfigurer" class="org.springframework.beans.factory.config.PropertyPlaceholderConfigurer"&gt; &lt;property name="location" value="classpath:jdbc.properties" /&gt; &lt;/bean&gt; &lt;bean id="dataSource" class="com.alibaba.druid.pool.DruidDataSource" init-method="init" destroy-method="close"&gt; &lt;!-- 指定连接数据库的驱动 --&gt; &lt;property name="driverClassName" value="$&#123;jdbc.driverClass&#125;" /&gt; &lt;property name="url" value="$&#123;jdbc.url&#125;" /&gt; &lt;property name="username" value="$&#123;jdbc.user&#125;" /&gt; &lt;property name="password" value="$&#123;jdbc.password&#125;" /&gt; &lt;!-- 配置初始化大小、最小、最大 --&gt; &lt;property name="initialSize" value="3" /&gt; &lt;property name="minIdle" value="3" /&gt; &lt;property name="maxActive" value="20" /&gt; &lt;!-- 配置获取连接等待超时的时间 --&gt; &lt;property name="maxWait" value="60000" /&gt; &lt;!-- 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 --&gt; &lt;property name="timeBetweenEvictionRunsMillis" value="60000" /&gt; &lt;!-- 配置一个连接在池中最小生存的时间，单位是毫秒 --&gt; &lt;property name="minEvictableIdleTimeMillis" value="300000" /&gt; &lt;property name="validationQuery" value="SELECT 'x'" /&gt; &lt;property name="testWhileIdle" value="true" /&gt; &lt;property name="testOnBorrow" value="false" /&gt; &lt;property name="testOnReturn" value="false" /&gt; &lt;!-- 打开PSCache，并且指定每个连接上PSCache的大小 --&gt; &lt;property name="poolPreparedStatements" value="true" /&gt; &lt;property name="maxPoolPreparedStatementPerConnectionSize" value="20" /&gt; &lt;!-- 配置监控统计拦截的filters，去掉后监控界面sql无法统计 --&gt; &lt;property name="filters" value="stat" /&gt; &lt;/bean&gt; &lt;!-- spring和MyBatis完美整合，不需要mybatis的配置映射文件 --&gt; &lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;!-- 自动扫描mapping.xml文件 --&gt; &lt;property name="mapperLocations" value="classpath:mapping/*.xml"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- DAO接口所在包名，Spring会自动查找其下的类 --&gt; &lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;property name="basePackage" value="com.crossoverJie.dao" /&gt; &lt;property name="sqlSessionFactoryBeanName" value="sqlSessionFactory"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- (事务管理)transaction manager, use JtaTransactionManager for global tx --&gt; &lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;/bean&gt; &lt;!-- 配置自定义Realm --&gt; &lt;bean id="myRealm" class="com.crossoverJie.shiro.MyRealm"/&gt; &lt;!-- 安全管理器 --&gt; &lt;bean id="securityManager" class="org.apache.shiro.web.mgt.DefaultWebSecurityManager"&gt; &lt;property name="realm" ref="myRealm"/&gt; &lt;/bean&gt; &lt;!-- Shiro过滤器 核心--&gt; &lt;bean id="shiroFilter" class="org.apache.shiro.spring.web.ShiroFilterFactoryBean"&gt; &lt;!-- Shiro的核心安全接口,这个属性是必须的 --&gt; &lt;property name="securityManager" ref="securityManager"/&gt; &lt;!-- 身份认证失败，则跳转到登录页面的配置 --&gt; &lt;property name="loginUrl" value="/login.jsp"/&gt; &lt;!-- 权限认证失败，则跳转到指定页面 --&gt; &lt;property name="unauthorizedUrl" value="/nopower.jsp"/&gt; &lt;!-- Shiro连接约束配置,即过滤链的定义 --&gt; &lt;property name="filterChainDefinitions"&gt; &lt;value&gt; &lt;!--anon 表示匿名访问，不需要认证以及授权--&gt; /loginAdmin=anon &lt;!--authc表示需要认证 没有进行身份认证是不能进行访问的--&gt; /admin*=authc /student=roles[teacher] /teacher=perms["user:create"] &lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 保证实现了Shiro内部lifecycle函数的bean执行 --&gt; &lt;bean id="lifecycleBeanPostProcessor" class="org.apache.shiro.spring.LifecycleBeanPostProcessor"/&gt; &lt;!-- 开启Shiro注解 --&gt; &lt;bean class="org.springframework.aop.framework.autoproxy.DefaultAdvisorAutoProxyCreator" depends-on="lifecycleBeanPostProcessor"/&gt; &lt;bean class="org.apache.shiro.spring.security.interceptor.AuthorizationAttributeSourceAdvisor"&gt; &lt;property name="securityManager" ref="securityManager"/&gt; &lt;/bean&gt;&lt;/beans&gt; 在这里我们配置了上文中所提到的自定义myRealm,这样Shiro就可以按照我们自定义的逻辑来进行权限验证了。其余的都比较简单，看注释应该都能明白。着重讲解一下：12345678910111213&lt;property name="filterChainDefinitions"&gt; &lt;value&gt; &lt;!--anon 表示匿名访问，不需要认证以及授权--&gt; /loginAdmin=anon &lt;!--authc表示需要认证 没有进行身份认证是不能进行访问的--&gt; /admin*=authc /student=roles[teacher] /teacher=perms["user:create"] &lt;/value&gt;&lt;/property&gt; /loginAdmin=anon的意思的意思是，发起/loginAdmin这个请求是不需要进行身份认证的，这个请求在这次项目中是一个登录请求，一般对于这样的请求都是不需要身份认证的。 /admin*=authc表示 /admin,/admin1,/admin2这样的请求都是需要进行身份认证的，不然是不能访问的。 /student=roles[teacher]表示访问/student请求的用户必须是teacher角色，不然是不能进行访问的。 /teacher=perms[“user:create”]表示访问/teacher请求是需要当前用户具有user:create权限才能进行访问的。更多相关权限过滤的资料可以访问shiro的官方介绍：传送门 使用Shiro标签库Shiro还有着强大标签库，可以在前端帮我获取信息和做判断。我贴一下我这里登录完成之后显示的界面：12345678910111213141516171819202122232425&lt;%-- Created by IntelliJ IDEA. User: Administrator Date: 2016/7/14 Time: 13:17 To change this template use File | Settings | File Templates.--%&gt;&lt;%@ page contentType="text/html;charset=UTF-8" language="java" %&gt;&lt;%@ taglib prefix="shiro" uri="http://shiro.apache.org/tags" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;后台&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;shiro:hasRole name="admin"&gt; 这是admin角色登录：&lt;shiro:principal&gt;&lt;/shiro:principal&gt;&lt;/shiro:hasRole&gt;&lt;shiro:hasPermission name="user:create"&gt; 有user:create权限信息&lt;/shiro:hasPermission&gt;&lt;br&gt;登录成功&lt;/body&gt;&lt;/html&gt; 要想使用Shiro标签，只需要引入一下标签即可：&lt;%@ taglib prefix=&quot;shiro&quot; uri=&quot;http://shiro.apache.org/tags&quot; %&gt;其实英语稍微好点的童鞋应该都能看懂。下面我大概介绍下一些标签的用法： 具有admin角色才会显示标签内的信息。 获取用户信息。默认调用Subject.getPrincipal()获取，即 Primary Principal。 用户拥有user:create这个权限才回显示标签内的信息。更多的标签可以查看官网：传送门 整体测试 这是我的测试数据。首先来验证一下登录：先输入一个错误的账号和密码： 接下来输入一个正确的： 可以看到我登录的用户是crossoverJie他是有admin的角色，并且拥有user:*(ps:系统数据详见上面的数据库截图)的权限，所以在这里： 123456&lt;shiro:hasRole name="admin"&gt; 这是admin角色登录：&lt;shiro:principal&gt;&lt;/shiro:principal&gt;&lt;/shiro:hasRole&gt;&lt;shiro:hasPermission name="user:create"&gt; 有user:create权限信息&lt;/shiro:hasPermission&gt; 是能显示出标签内的信息，并把用户信息也显示出来了。接着我们来访问一下/student这个请求，因为在Spring的配置文件中： 12345678910111213&lt;property name="filterChainDefinitions"&gt; &lt;value&gt; &lt;!--anon 表示匿名访问，不需要认证以及授权--&gt; /loginAdmin=anon &lt;!--authc表示需要认证 没有进行身份认证是不能进行访问的--&gt; /admin*=authc /student=roles[teacher] /teacher=perms["user:create"] &lt;/value&gt;&lt;/property&gt; 只有teacher角色才能访问/student这个请求的： 果然，Shiro做了安全控制是不能进行访问的。然后我们换aaa用户登录，他正好是teacher角色，看能不能访问/student。 果然是能访问的。因为我在控制器里访问/student返回的是同一个界面所以看到的还是这个界面。 1234@RequestMapping("/teacher")public String teacher()&#123; return "admin" ;&#125; 并且没有显示之前Shiro标签内的内容。其他的我就不测了，大家可以自己在数据库里加一些数据，或者是改下拦截的权限多试试，这样对Shiro的理解就会更加深刻。 MD5加密Shiro还封装了一个我认为非常不错的功能，那就是MD5加密，代码如下： 1234567891011121314151617181920package com.crossoverJie.shiro;import org.apache.shiro.crypto.hash.Md5Hash;/** * Created with IDEA * 基于Shiro的MD5加密 * Created by $&#123;jie.chen&#125; on 2016/7/13. */public class MD5Util &#123; public static String md5(String str,String salt)&#123; return new Md5Hash(str,salt).toString() ; &#125; public static void main(String[] args) &#123; String md5 = md5("abc123","crossoverjie") ; System.out.println(md5); &#125;&#125; 代码非常简单，只需要调用Md5Hash(str,salt)方法即可，这里多了一个参数，第一个参数不用多解释，是需要加密的字符串。第二个参数salt中文翻译叫盐，加密的时候我们传一个字符串进去，只要这个salt不被泄露出去，那原则上加密之后是无法被解密的，在存用户密码的时候可以使用，感觉还是非常屌的。 总结以上就是Shiro实际使用的案例，将的比较初略，但是关于Shiro的核心东西都在里面了。大家可以去我的github上下载源码，只要按照我给的数据库就没有问题，项目跑起来之后试着改下里面的东西可以加深对Shiro的理解。 项目地址：https://github.com/crossoverJie/SSM.git个人博客地址：http://crossoverjie.top。GitHub地址：https://github.com/crossoverJie。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>IDEA</tag>
        <tag>Shiro</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM(二)Lucene全文检索]]></title>
    <url>%2F2016%2F07%2F06%2FSSM2%2F</url>
    <content type="text"><![CDATA[前言 大家平时肯定都有用过全文检索工具，最常用的百度谷歌就是其中的典型。如果自己能够做一个那是不是想想就逼格满满呢。Apache就为我们提供了这样一个框架，以下就是在实际开发中加入Lucene的一个小Demo。 获取Maven依赖首先看一下实际运行的效果图：这个项目是基于之前使用IDEA搭建的SSM的基础上进行增加的，建议小白先看下一我。上一篇博客，以及共享在Github上的源码。以下是Lucene所需要的依赖：1234567891011121314151617181920212223242526272829303132333435&lt;!--加入lucene--&gt; &lt;!-- https://mvnrepository.com/artifact/org.apache.lucene/lucene-core --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-core&lt;/artifactId&gt; &lt;version&gt;$&#123;lucene.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.apache.lucene/lucene-queryparser --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-queryparser&lt;/artifactId&gt; &lt;version&gt;$&#123;lucene.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.apache.lucene/lucene-analyzers-common --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-analyzers-common&lt;/artifactId&gt; &lt;version&gt;$&#123;lucene.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--lucene中文分词--&gt; &lt;!-- https://mvnrepository.com/artifact/org.apache.lucene/lucene-analyzers-smartcn --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-analyzers-smartcn&lt;/artifactId&gt; &lt;version&gt;$&#123;lucene.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--lucene高亮--&gt; &lt;!-- https://mvnrepository.com/artifact/org.apache.lucene/lucene-highlighter --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-highlighter&lt;/artifactId&gt; &lt;version&gt;$&#123;lucene.version&#125;&lt;/version&gt; &lt;/dependency&gt; 具体的用途我都写有注释。在IDEA中修改了Pom.xml文件之后只需要点击如图所示的按钮即可重新获取依赖： 编写Lucene工具类这个工具类中的具体代码我就不单独提出来说了，每个关键的地方我都写有注释，不清楚的再讨论。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164package com.crossoverJie.lucene;import com.crossoverJie.pojo.User;import org.apache.lucene.analysis.TokenStream;import org.apache.lucene.analysis.cn.smart.SmartChineseAnalyzer;import org.apache.lucene.document.Document;import org.apache.lucene.document.Field;import org.apache.lucene.document.StringField;import org.apache.lucene.document.TextField;import org.apache.lucene.index.*;import org.apache.lucene.queryparser.classic.QueryParser;import org.apache.lucene.search.*;import org.apache.lucene.search.highlight.*;import org.apache.lucene.store.Directory;import org.apache.lucene.store.FSDirectory;import java.io.StringReader;import java.nio.file.Paths;import java.util.LinkedList;import java.util.List;import com.crossoverJie.util.*;/** * 博客索引类 * @author Administrator * */public class LuceneIndex &#123; private Directory dir=null; /** * 获取IndexWriter实例 * @return * @throws Exception */ private IndexWriter getWriter()throws Exception&#123; /** * 生成的索引我放在了C盘，可以根据自己的需要放在具体位置 */ dir= FSDirectory.open(Paths.get("C://lucene")); SmartChineseAnalyzer analyzer=new SmartChineseAnalyzer(); IndexWriterConfig iwc=new IndexWriterConfig(analyzer); IndexWriter writer=new IndexWriter(dir, iwc); return writer; &#125; /** * 添加博客索引 * @param user */ public void addIndex(User user)throws Exception&#123; IndexWriter writer=getWriter(); Document doc=new Document(); doc.add(new StringField("id",String.valueOf(user.getUserId()), Field.Store.YES)); /** * yes是会将数据存进索引，如果查询结果中需要将记录显示出来就要存进去，如果查询结果 * 只是显示标题之类的就可以不用存，而且内容过长不建议存进去 * 使用TextField类是可以用于查询的。 */ doc.add(new TextField("username", user.getUsername(), Field.Store.YES)); doc.add(new TextField("description",user.getDescription(), Field.Store.YES)); writer.addDocument(doc); writer.close(); &#125; /** * 更新博客索引 * @param user * @throws Exception */ public void updateIndex(User user)throws Exception&#123; IndexWriter writer=getWriter(); Document doc=new Document(); doc.add(new StringField("id",String.valueOf(user.getUserId()), Field.Store.YES)); doc.add(new TextField("username", user.getUsername(), Field.Store.YES)); doc.add(new TextField("description",user.getDescription(), Field.Store.YES)); writer.updateDocument(new Term("id", String.valueOf(user.getUserId())), doc); writer.close(); &#125; /** * 删除指定博客的索引 * @param userId * @throws Exception */ public void deleteIndex(String userId)throws Exception&#123; IndexWriter writer=getWriter(); writer.deleteDocuments(new Term("id", userId)); writer.forceMergeDeletes(); // 强制删除 writer.commit(); writer.close(); &#125; /** * 查询用户 * @param q 查询关键字 * @return * @throws Exception */ public List&lt;User&gt; searchBlog(String q)throws Exception&#123; /** * 注意的是查询索引的位置得是存放索引的位置，不然会找不到。 */ dir= FSDirectory.open(Paths.get("C://lucene")); IndexReader reader = DirectoryReader.open(dir); IndexSearcher is=new IndexSearcher(reader); BooleanQuery.Builder booleanQuery = new BooleanQuery.Builder(); SmartChineseAnalyzer analyzer=new SmartChineseAnalyzer(); /** * username和description就是我们需要进行查找的两个字段 * 同时在存放索引的时候要使用TextField类进行存放。 */ QueryParser parser=new QueryParser("username",analyzer); Query query=parser.parse(q); QueryParser parser2=new QueryParser("description",analyzer); Query query2=parser2.parse(q); booleanQuery.add(query, BooleanClause.Occur.SHOULD); booleanQuery.add(query2, BooleanClause.Occur.SHOULD); TopDocs hits=is.search(booleanQuery.build(), 100); QueryScorer scorer=new QueryScorer(query); Fragmenter fragmenter = new SimpleSpanFragmenter(scorer); /** * 这里可以根据自己的需要来自定义查找关键字高亮时的样式。 */ SimpleHTMLFormatter simpleHTMLFormatter=new SimpleHTMLFormatter("&lt;b&gt;&lt;font color='red'&gt;","&lt;/font&gt;&lt;/b&gt;"); Highlighter highlighter=new Highlighter(simpleHTMLFormatter, scorer); highlighter.setTextFragmenter(fragmenter); List&lt;User&gt; userList=new LinkedList&lt;User&gt;(); for(ScoreDoc scoreDoc:hits.scoreDocs)&#123; Document doc=is.doc(scoreDoc.doc); User user=new User(); user.setUserId(Integer.parseInt(doc.get(("id")))); user.setDescription(doc.get(("description"))); String username=doc.get("username"); String description=doc.get("description"); if(username!=null)&#123; TokenStream tokenStream = analyzer.tokenStream("username", new StringReader(username)); String husername=highlighter.getBestFragment(tokenStream, username); if(StringUtil.isEmpty(husername))&#123; user.setUsername(username); &#125;else&#123; user.setUsername(husername); &#125; &#125; if(description!=null)&#123; TokenStream tokenStream = analyzer.tokenStream("description", new StringReader(description)); String hContent=highlighter.getBestFragment(tokenStream, description); if(StringUtil.isEmpty(hContent))&#123; if(description.length()&lt;=200)&#123; user.setDescription(description); &#125;else&#123; user.setDescription(description.substring(0, 200)); &#125; &#125;else&#123; user.setDescription(hContent); &#125; &#125; userList.add(user); &#125; return userList; &#125;&#125; 查询Controller的编写接下来是查询Controller：123456789101112131415161718192021222324@RequestMapping("/q")public String search(@RequestParam(value = "q", required = false,defaultValue = "") String q, @RequestParam(value = "page", required = false, defaultValue = "1") String page, Model model, HttpServletRequest request) throws Exception &#123; LuceneIndex luceneIndex = new LuceneIndex() ; List&lt;User&gt; userList = luceneIndex.searchBlog(q); /** * 关于查询之后的分页我采用的是每次分页发起的请求都是将所有的数据查询出来， * 具体是第几页再截取对应页数的数据，典型的拿空间换时间的做法，如果各位有什么 * 高招欢迎受教。 */ Integer toIndex = userList.size() &gt;= Integer.parseInt(page) * 5 ? Integer.parseInt(page) * 5 : userList.size(); List&lt;User&gt; newList = userList.subList((Integer.parseInt(page) - 1) * 5, toIndex); model.addAttribute("userList",newList) ; String s = this.genUpAndDownPageCode(Integer.parseInt(page), userList.size(), q, 5, request.getServletContext(). getContextPath()); model.addAttribute("pageHtml",s) ; model.addAttribute("q",q) ; model.addAttribute("resultTotal",userList.size()) ; model.addAttribute("pageTitle","搜索关键字'" + q + "'结果页面") ; return "queryResult";&#125; 其中有用到一个genUpAndDownPageCode()方法来生成分页的Html代码，如下：1234567891011121314151617181920212223242526272829303132/** * 查询之后的分页 * @param page * @param totalNum * @param q * @param pageSize * @param projectContext * @return */private String genUpAndDownPageCode(int page,Integer totalNum,String q,Integer pageSize,String projectContext)&#123; long totalPage=totalNum%pageSize==0?totalNum/pageSize:totalNum/pageSize+1; StringBuffer pageCode=new StringBuffer(); if(totalPage==0)&#123; return ""; &#125;else&#123; pageCode.append("&lt;nav&gt;"); pageCode.append("&lt;ul class='pager' &gt;"); if(page&gt;1)&#123; pageCode.append("&lt;li&gt;&lt;a href='"+projectContext+"/q?page="+(page-1)+"&amp;q="+q+"'&gt;上一页&lt;/a&gt;&lt;/li&gt;"); &#125;else&#123; pageCode.append("&lt;li class='disabled'&gt;&lt;a href='#'&gt;上一页&lt;/a&gt;&lt;/li&gt;"); &#125; if(page&lt;totalPage)&#123; pageCode.append("&lt;li&gt;&lt;a href='"+projectContext+"/q?page="+(page+1)+"&amp;q="+q+"'&gt;下一页&lt;/a&gt;&lt;/li&gt;"); &#125;else&#123; pageCode.append("&lt;li class='disabled'&gt;&lt;a href='#'&gt;下一页&lt;/a&gt;&lt;/li&gt;"); &#125; pageCode.append("&lt;/ul&gt;"); pageCode.append("&lt;/nav&gt;"); &#125; return pageCode.toString();&#125; 代码比较简单，就是根据的页数、总页数来生成分页代码，对了我前端采用的是现在流行的Bootstrap，这个有不会的可以去他官网看看，比较简单易上手。接下来只需要编写显示界面就大功告成了。 显示界面我只贴关键代码，具体的可以去Github上查看。1234567891011121314151617181920212223242526272829303132333435363738394041&lt;c:choose&gt; &lt;c:when test="$&#123;userList.size()==0 &#125;"&gt; &lt;div align="center" style="padding-top: 20px"&gt;&lt;font color="red"&gt;$&#123;q&#125;&lt;/font&gt;未查询到结果，请换个关键字试试！&lt;/div&gt; &lt;/c:when&gt; &lt;c:otherwise&gt; &lt;div align="center" style="padding-top: 20px"&gt; 查询&lt;font color="red"&gt;$&#123;q&#125;&lt;/font&gt;关键字，约$&#123;resultTotal&#125;条记录！ &lt;/div&gt; &lt;c:forEach var="u" items="$&#123;userList &#125;" varStatus="status"&gt; &lt;div class="panel-heading "&gt; &lt;div class="row"&gt; &lt;div class="col-md-6"&gt; &lt;div class="row"&gt; &lt;div class="col-md-12"&gt; &lt;b&gt; &lt;a href="&lt;%=path %&gt;/user/showUser/$&#123;u.userId&#125;"&gt;$&#123;u.username&#125;&lt;/a&gt; &lt;/b&gt; &lt;br/&gt; $&#123;u.description&#125; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="col-md-4 col-md-offset-2"&gt; &lt;p class="text-muted text-right"&gt; $&#123;u.password&#125; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="panel-footer"&gt; &lt;p class="text-right"&gt; &lt;span class="label label-default"&gt; &lt;span class="glyphicon glyphicon-comment" aria-hidden="true"&gt;&lt;/span&gt; $&#123;u.password&#125; &lt;/span&gt; &lt;/p&gt; &lt;/div&gt; &lt;/c:forEach&gt; &lt;/c:otherwise&gt; &lt;/c:choose&gt; 利用JSTL标签即可将数据循环展示出来，关键字就不需要单独做处理了，在后台查询的时候已经做了修改了。 总结关于全文检索的框架不止Lucene还有solr，具体谁好有什么区别我也不太清楚，准备下来花点时间研究下。哦对了，最近又有点想做Android开发了，感觉做点东西能够实实在在的摸得到逼格确实要高些(现在主要在做后端开发)，感兴趣的朋友可以关注下。哦对了，直接运行我代码的朋友要下注意： 首先要将数据库倒到自己的MySQL上 之后在首次运行的时候需要点击重新生成索引按钮生成一遍索引之后才能进行搜索，因为现在的数据是直接存到数据库中的，并没有在新增的时候就增加索引，在实际开发的时候需要在新增数据那里再生成一份索引，就直接调用LuceneIndex类中的addIndex方法传入实体即可，再做更新、删除操作的时候也同样需要对索引做操作。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>IDEA</tag>
        <tag>Lucene</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM(一)框架的整合]]></title>
    <url>%2F2016%2F06%2F28%2FSSM1%2F</url>
    <content type="text"><![CDATA[前言最近这几年JetBrains公司开发的IDEA是越来越流行了，甚至Google的官方IDE都是IDEA来定制的，可见IDEA的发展趋势是越来越好，由于博主接触IDEA的时间也不长，所以有关IDEA和Eclipse的区别和优劣势请自行百度了。借此机会我就使用IDEA来整合一下SSM，针对于初学者(初次使用IDEA和JAVAEE初学者)还是有帮助的。 新建SSM项目哦对了，关于IDEA的版本问题强烈建议使用旗舰版，有条件的就购买，没条件的嘛。。天朝你懂的。在欢迎界面点击Create New Project。之后选择Maven(新建JAVAEE项目是需要安装JDK的，这个就不在这里讲解了。)选好之后点击下一步。之后填入GroupID和ArtifactID这里尽量按照Maven的命名规范来即可。之后点击下一步，填入项目名称，这里我建议和之前填写的ArtifactID名称一样即可。点击Finish完成项目的创建。之后尽量不要做其他操作，让IDEA完成索引创建。 完善目录结构首先观察一下IDEA给我们生成的目录结构，这是一个标准的Maven目录。但是其中少了一个webapp目录用于存放jsp、css、js、图片之类的文件。之后还需要完善我们的目录结构，如下图：以上的命名都是我们开发过程中常用的命名规则，不一定按照我这样来，但是最好是有一定的规范。 POM.xmlpom.xml是整个maven的核心配置文件，里面有对项目的描述和项目所需要的依赖。哦对了，在修改pom.xml文件之前我们最好先设置一下该项目的Maven设置(IDEA对每个项目的maven设置和Eclipse不一样，不是设置一次就可了，如果今后还要新建项目那就还需要设置，同时按住ctrl,alt,s是打开设置的快捷键，更多有关IDEA的操作今后会更新相关博文。) IDEA的Maven设置在Eclipse中用过Maven的都应该知道，这里是将项目的Maven换成我们自己安装的Maven，下面两个目录是选择Maven配置文件，不知道是什么原因在Eclipse中选择了配置文件之后会自动的将Maven本地厂库的路径更改为你settings.xml中配置的路径。既然这里没有自动选中那我们就手动修改即可，尽量不要放在C盘，一是用久之后本地厂库占用的空间会比较大，二是万一系统崩溃的话还有可能找回来。 修改pom.xml以下是我的pom.xml文件：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!--suppress MavenModelInspection --&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.crossoverJie&lt;/groupId&gt; &lt;artifactId&gt;SSM&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;1.6&lt;/source&gt; &lt;target&gt;1.6&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;spring.version&gt;4.1.4.RELEASE&lt;/spring.version&gt; &lt;jackson.version&gt;2.5.0&lt;/jackson.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- spring --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- 使用SpringMVC需配置 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 关系型数据库整合时需配置 如hibernate jpa等 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-orm&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.2.4&lt;/version&gt; &lt;/dependency&gt; &lt;!-- log4j --&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mysql连接 --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.34&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.0.18&lt;/version&gt; &lt;/dependency&gt; &lt;!-- json --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-annotations&lt;/artifactId&gt; &lt;version&gt;$&#123;jackson.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-core&lt;/artifactId&gt; &lt;version&gt;$&#123;jackson.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;$&#123;jackson.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- aop --&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.8.4&lt;/version&gt; &lt;/dependency&gt; &lt;!-- servlet --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;servlet-api&lt;/artifactId&gt; &lt;version&gt;3.0-alpha-1&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;version&gt;3.4&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 上传文件 --&gt; &lt;dependency&gt; &lt;groupId&gt;commons-fileupload&lt;/groupId&gt; &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 关于maven的知识点我就不细讲了，毕竟这是一个整合教程。 spring-mvc.xml这个配置文件是springMVC的配置文件：里面的我都写有注释，应该都能看懂。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:p="http://www.springframework.org/schema/p" xmlns:context="http://www.springframework.org/schema/context" xmlns:mvc="http://www.springframework.org/schema/mvc" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.1.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.1.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-4.0.xsd"&gt; &lt;!-- 自动扫描该包，使SpringMVC认为包下用了@controller注解的类是控制器 --&gt; &lt;context:component-scan base-package="com.crossoverJie.controller" /&gt; &lt;!--避免IE执行AJAX时，返回JSON出现下载文件 --&gt; &lt;!--&lt;bean id="mappingJacksonHttpMessageConverter" class="org.springframework.http.converter.json.MappingJacksonHttpMessageConverter"&gt; &lt;property name="supportedMediaTypes"&gt; &lt;list&gt; &lt;value&gt;text/html;charset=UTF-8&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt;--&gt; &lt;mvc:annotation-driven/&gt; &lt;!-- 启动SpringMVC的注解功能，完成请求和注解POJO的映射 --&gt; &lt;!-- 定义跳转的文件的前后缀 ，视图模式配置--&gt; &lt;bean class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;!-- 这里的配置我的理解是自动给后面action的方法return的字符串加上前缀和后缀，变成一个 可用的url地址 --&gt; &lt;property name="prefix" value="/WEB-INF/jsp/" /&gt; &lt;property name="suffix" value=".jsp" /&gt; &lt;/bean&gt; &lt;!-- 配置文件上传，如果没有使用文件上传可以不用配置，当然如果不配，那么配置文件中也不必引入上传组件包 --&gt; &lt;bean id="multipartResolver" class="org.springframework.web.multipart.commons.CommonsMultipartResolver"&gt; &lt;!-- 默认编码 --&gt; &lt;property name="defaultEncoding" value="utf-8" /&gt; &lt;!-- 文件大小最大值 --&gt; &lt;property name="maxUploadSize" value="10485760000" /&gt; &lt;!-- 内存中的最大值 --&gt; &lt;property name="maxInMemorySize" value="40960" /&gt; &lt;/bean&gt; &lt;!-- 配置拦截器 --&gt; &lt;!--&lt;mvc:interceptors&gt; &lt;mvc:interceptor&gt; &amp;lt;!&amp;ndash; &lt;mvc:mapping path="/**"/&gt;拦截所有 &amp;ndash;&amp;gt; &lt;mvc:mapping path="/user/**"/&gt; &lt;mvc:mapping path="/role/**"/&gt; &lt;mvc:mapping path="/function/**"/&gt; &lt;mvc:mapping path="/news/**"/&gt; &lt;mvc:mapping path="/img/**"/&gt; &lt;bean class="com.crossoverJie.intercept.Intercept"&gt;&lt;/bean&gt; &lt;/mvc:interceptor&gt; &lt;/mvc:interceptors&gt;--&gt;&lt;/beans&gt; 关于上面拦截器注释掉的那里，配置是没有问题的，因为这是一个整合项目，所以里边也没有用到拦截器，为了防止运行报错所以就先注释掉了。如果后续需要增加拦截器，可以参考这里的配置。 spring-mybatis.xml这个是spring和mybatis的整合配置文件，其中还有Druid连接池的配置。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.1.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.1.xsd"&gt; &lt;!-- 自动扫描 --&gt; &lt;context:component-scan base-package="com.crossoverJie" /&gt; &lt;!-- 引入配置文件 --&gt; &lt;bean id="propertyConfigurer" class="org.springframework.beans.factory.config.PropertyPlaceholderConfigurer"&gt; &lt;property name="location" value="classpath:jdbc.properties" /&gt; &lt;/bean&gt; &lt;bean id="dataSource" class="com.alibaba.druid.pool.DruidDataSource" init-method="init" destroy-method="close"&gt; &lt;!-- 指定连接数据库的驱动 --&gt; &lt;property name="driverClassName" value="$&#123;jdbc.driverClass&#125;" /&gt; &lt;property name="url" value="$&#123;jdbc.url&#125;" /&gt; &lt;property name="username" value="$&#123;jdbc.user&#125;" /&gt; &lt;property name="password" value="$&#123;jdbc.password&#125;" /&gt; &lt;!-- 配置初始化大小、最小、最大 --&gt; &lt;property name="initialSize" value="3" /&gt; &lt;property name="minIdle" value="3" /&gt; &lt;property name="maxActive" value="20" /&gt; &lt;!-- 配置获取连接等待超时的时间 --&gt; &lt;property name="maxWait" value="60000" /&gt; &lt;!-- 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 --&gt; &lt;property name="timeBetweenEvictionRunsMillis" value="60000" /&gt; &lt;!-- 配置一个连接在池中最小生存的时间，单位是毫秒 --&gt; &lt;property name="minEvictableIdleTimeMillis" value="300000" /&gt; &lt;property name="validationQuery" value="SELECT 'x'" /&gt; &lt;property name="testWhileIdle" value="true" /&gt; &lt;property name="testOnBorrow" value="false" /&gt; &lt;property name="testOnReturn" value="false" /&gt; &lt;!-- 打开PSCache，并且指定每个连接上PSCache的大小 --&gt; &lt;property name="poolPreparedStatements" value="true" /&gt; &lt;property name="maxPoolPreparedStatementPerConnectionSize" value="20" /&gt; &lt;!-- 配置监控统计拦截的filters，去掉后监控界面sql无法统计 --&gt; &lt;property name="filters" value="stat" /&gt; &lt;/bean&gt; &lt;!-- spring和MyBatis完美整合，不需要mybatis的配置映射文件 --&gt; &lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;!-- 自动扫描mapping.xml文件 --&gt; &lt;property name="mapperLocations" value="classpath:mapping/*.xml"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- DAO接口所在包名，Spring会自动查找其下的类 --&gt; &lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;property name="basePackage" value="com.crossoverJie.dao" /&gt; &lt;property name="sqlSessionFactoryBeanName" value="sqlSessionFactory"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- (事务管理)transaction manager, use JtaTransactionManager for global tx --&gt; &lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;/bean&gt;&lt;/beans&gt; 以上两个就是最重要的配置文件了，只要其中的包名和配置文件中的名字一样就不会出问题。关于xxMpper.xml以及实体类的生成，我们可以借助mybatis-generator自动生成工具来生成，方便快捷。 IDEA配置Tomcat关于Tomcat的下载与安装我这里就不多介绍了。按照下图选择：在name中为这个Tomcat输入一个名字。之后选择你本地Tomcat的目录点击Ok即可。点击apply和保存之后就返回首页即可看到Tomcat的标识。根据需要点击Run和Debug即可运行。 运行结果如下：点击上图的2,3,4可看到不同用户的结果，如果你走到这一步，那么恭喜你整合成功。 总结以上源码都在github上。项目地址：SSM欢迎拍砖。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
        <tag>SpringMVC</tag>
        <tag>Mybatis</tag>
        <tag>IDEA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日常记录（三）更换Hexo主题]]></title>
    <url>%2F2016%2F06%2F18%2Fnormal-skill3%2F</url>
    <content type="text"><![CDATA[前言 由于博主的喜新厌旧，再经过一段时间对上一个主题的审美疲劳加上我专(zhuang)研(bi)的精神于是就想找一个B格较高的主题。经过一段时间的查找发现NexT这个主题简洁而不失华丽，低调而不失逼格(就不收广告费了)特别适合我，接着就着手开干。 安装NexT主题从Git上克隆主题这里我就不介绍有关Hexo的东西了，默认是知道如何搭建Hexo博客的。还不太清楚的请自行百度。首先将NexT主题先克隆到自己电脑上： cd your-hexo-site git clone https://github.com/iissnan/hexo-theme-next themes/next。安装主题接下来我们只需要将站点下的_config.yml配置文件中的主题配置更换成Next，如下图：其实这样主题就配好了，是不是很简单。 NexT主题配置Hexo配置文件相关配置Next主题的个人头像是在Hexo配置文件中的。NexT同样也支持多说配置，我们只需要将你自己的多说账号也配置到Hexo的配置文件中即可。duoshuo_shortname: your name Next配置文件相关配置NexT主题非常吸引我的一点就是他支持打赏功能，这让我这种穷逼程序猿又看到了生路(多半也没人会给我打赏)，以下一段配置即可在每篇博文下边开启打赏功能。微信也是可以的，但是我找了半天没有找到生成微信支付码的地方。其他的一些配置我觉得都比较简单，看官方的帮助文档也是完全可以的，有问题的我们可以再讨论。 一个绕坑指南我在换完NexT之后发现在首页这里显示的分类和便签的统计都是对的，但是点进去之后就是空白的。我查看了Hexo和NexT的文档发现我写的没有任何问题，之后就懵逼了。。。各位有碰到这个问题的可以往下看。 绕坑之后我仔细的查阅了NexT的文档，发现他所使用的tags和categories文件夹下的index.md的格式是这样的：12345---title: tagsdate: 2016-06-16 02:13:06type: &quot;tags&quot;--- 这和我之前使用的JackMan主题是完全不一样的(有关JackMan主题可以自行查阅)。之后我讲categories文件下的index.md文件也换成这样的格式就没有问题了。如果你和我一样眼神不好的话建议配副眼镜。 总结其实以上的很多东西都是在NexT官方文档里查得到的，接下来我会尝试提一点pull request来更加深入的了解Hexo。]]></content>
      <categories>
        <category>日常记录</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日常记录（二）SpringMvc导出Excel]]></title>
    <url>%2F2016%2F06%2F14%2Fnormal-skill2%2F</url>
    <content type="text"><![CDATA[前言 相信很多朋友在实际工作中都会要将数据导出成Excel的需求，通常这样的做法有两种。一是采用JXL来生成Excel，之后保存到服务器，然后在生成页面之后下载该文件。二是使用POI来生成Excel，之后使用Stream的方式输出到前台直接下载(ps:当然也可以生成到服务器中再下载。)。这里我们讨论第二种。至于两种方式的优缺点请自行百度。 Struts2的方式通常我会将已经生成好的HSSFWorkbook放到一个InputStream中，然后再到xml配置文件中将返回结果更改为stream的方式。如下：12345678private void responseData(HSSFWorkbook wb) throws IOException &#123; ByteArrayOutputStream baos = new ByteArrayOutputStream(); wb.write(baos); baos.flush(); byte[] aa = baos.toByteArray(); excelStream = new ByteArrayInputStream(aa, 0, aa.length); baos.close();&#125; 配置文件：1234567&lt;action name="exportXxx" class="xxxAction" method="exportXxx"&gt; &lt;result name="exportSuccess" type="stream"&gt; &lt;param name="inputName"&gt;excelStream&lt;/param&gt; &lt;param name="contentType"&gt;application/vnd.ms-excel&lt;/param&gt; &lt;param name="contentDisposition"&gt;attachment;filename="Undefined.xls"&lt;/param&gt; &lt;/result&gt;&lt;/action&gt; 这样即可达到点击链接即可直接下载文件的目的。 SpringMVC的方式先贴代码：123456789101112131415@RequestMapping("/exportXxx.action")public void exportXxx(HttpServletRequest request, HttpServletResponse response, @RequestParam(value="scheduleId", defaultValue="0")int scheduleId)&#123; HSSFWorkbook wb = createExcel(scheduleId) ; try &#123; response.setHeader("Content-Disposition", "attachment; filename=appointmentUser.xls"); response.setContentType("application/vnd.ms-excel; charset=utf-8") ; OutputStream out = response.getOutputStream() ; wb.write(out) ; out.flush(); out.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; 其实springMVC和Struts2的原理上是一样的，只是Struts2是才去配置文件的方式。首先是使用createExcel()这个方法来生成Excel并返回，最后利用rresponse即可向前台输出Excel，这种方法是通用的，也可以试用与Servlet、Struts2等。我们只需要在response的头信息中设置相应的输出信息即可。 总结不管是使用Struts2，还是使用SpringMVC究其根本都是使用的response，所以只要我们把response理解透了不管是下载图片、world、Excel还是其他什么文件都是一样的。]]></content>
      <categories>
        <category>日常记录</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>poi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日常记录（一）MySQL被锁解决方案]]></title>
    <url>%2F2016%2F06%2F05%2Fnormal-skill1%2F</url>
    <content type="text"><![CDATA[前言 由于前段时间为了让部署在Linux中的项目访问另一台服务器的MySQL，经过各种折腾就把root用户给弄出问题了，导致死活登不上PS:Linux中的项目还是没有连上。。(这是后话了。)。经过各种查阅资料终于找到解决方法了。 报错如下：Access denied for user &#39;root&#39;@&#39;localhost&#39; (using password:YES) 关闭MySQL服务，修改MySQL初始文件打开MySQL目录下的my-default.ini文件，如图：在最后一行加入skip-grant-tables之后保存。然后重启MySQL服务。 用命令行登录MySQL修改ROOT账号密码用命令行登录MySQL输入mysql -uroot -p,不用输入密码，直接敲回车即可进入。如下图：之后执行以下语句修改ROOT用户密码： use mysql; update user set password=PASSWORD(&quot;你的密码&quot;) where user=&#39;root&#39;; 还原my-default.ini文件最后还原配置文件，之后重启MySQL服务即可正常登录了。]]></content>
      <categories>
        <category>日常记录</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java多线程（二）有返回值的多线程]]></title>
    <url>%2F2016%2F05%2F27%2Fjava-thread2%2F</url>
    <content type="text"><![CDATA[前言之前我们使用多线程要么是继承Thread类，要么是实现Runnable接口，然后重写一下run()方法即可。但是只有的话如果有死锁、对共享资源的访问和随时监控线程状态就不行了，于是在Java5之后就有了Callable接口。 简单的实现有返回值的线程代码如下：CallableFuture类1234567891011121314151617181920212223242526272829303132333435package top.crosssoverjie.study.Thread;import java.util.concurrent.ExecutionException;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.Future;public class CallableFuture &#123; public static void main(String[] args) &#123; //创建一个线程池 ExecutorService pool = Executors.newFixedThreadPool(3) ; //创建三个有返回值的任务 CallableTest2 c1 = new CallableTest2("线程1") ; CallableTest2 c2 = new CallableTest2("线程2") ; CallableTest2 c3 = new CallableTest2("线程3") ; Future f1 = pool.submit(c1) ; Future f2 = pool.submit(c2) ; Future f3 = pool.submit(c3) ; try &#123; System.out.println(f1.get().toString()); System.out.println(f2.get().toString()); System.out.println(f3.get().toString()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125;finally&#123; pool.shutdown(); &#125; &#125;&#125; ·CallableTest2·类：123456789101112131415161718package top.crosssoverjie.study.Thread;import java.util.concurrent.Callable;public class CallableTest2 implements Callable &#123; private String name ; public CallableTest2(String name) &#123; this.name = name; &#125; @Override public Object call() throws Exception &#123; return name+"返回了东西"; &#125; &#125; 运行结果：123线程1返回了东西线程2返回了东西线程3返回了东西 总结以上就是一个简单的例子，需要了解更多详情可以去看那几个类的API。]]></content>
      <categories>
        <category>java多线程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Callable</tag>
        <tag>ExecutorService</tag>
        <tag>Future</tag>
        <tag>Executors</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[让百度和google收录我们的网站]]></title>
    <url>%2F2016%2F05%2F19%2Fbaidu-google%2F</url>
    <content type="text"><![CDATA[前言花了几天时间终于把这个看似高大上的博客搞好了，但是发现只能通过在地址栏输入地址进行访问，这很明显和我装X装到底的性格，于是乎在查阅了嘟爷的博客，和我各种百度终于搞出来了。 让谷歌收录让谷歌收录还是比较简单，首先我们肯定是要翻墙的(这个就不仔细说了，具体百度。)由于我这里突然登不上google账号了，所以下次补充截图。同体来说就是以下步骤： 下载google的html验证文件放到网站的根目录，使google能够访问得到。 在谷歌站长工具里加上自己的站点地图。 创建站点地图站点地图是一种文件，可以通过该文件列出您网站上的网页，从而将您网站内容的组织架构告知Google和其他搜索引擎，以便更加智能的抓取你的网站信息。首先我们要为Hexo安装谷歌和百度的插件(博主是用Hexo来搭建的博客)，如下：123npm install hexo-generator-sitemap --savenpm install hexo-generator-baidu-sitemap --save 在博客的根目录中的_config.yml文件中加入以下内容：之后部署上去之后如果在地址栏后面加上站点地图如下的话表示部署成功： 让百度收录有三种方式可以让百度收录我们的网站。第一种：主动推送我用Java写了一个小程序，可以手工的自己推送地址给百度。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990package top.crossoverjie.post;import java.io.BufferedReader;import java.io.IOException;import java.io.InputStreamReader;import java.io.PrintWriter;import java.net.URL;import java.net.URLConnection;public class Post &#123; public static void main(String[] args) &#123; String url = "http://data.zz.baidu.com/urls?site=crossoverjie.top&amp;token=1002EzhDReuy34dq";// 网站的服务器连接 String[] param = &#123; // 需要推送的网址// "http://crossoverjie.top/tags",// "http://crossoverjie.top/categories", //"http://crossoverjie.top/about/" "http://crossoverjie.top/2016/05/14/java-thread1" &#125;; String json = Post(url, param);// 执行推送方法 System.out.println("结果是" + json); // 打印推送结果 &#125; /** * 百度链接实时推送 * * @param PostUrl * @param Parameters * @return */ public static String Post(String PostUrl, String[] Parameters) &#123; if (null == PostUrl || null == Parameters || Parameters.length == 0) &#123; return null; &#125; String result = ""; PrintWriter out = null; BufferedReader in = null; try &#123; // 建立URL之间的连接 URLConnection conn = new URL(PostUrl).openConnection(); // 设置通用的请求属性 conn.setRequestProperty("Host", "data.zz.baidu.com"); conn.setRequestProperty("User-Agent", "curl/7.12.1"); conn.setRequestProperty("Content-Length", "83"); conn.setRequestProperty("Content-Type", "text/plain"); // 发送POST请求必须设置如下两行 conn.setDoInput(true); conn.setDoOutput(true); // 获取conn对应的输出流 out = new PrintWriter(conn.getOutputStream()); // 发送请求参数 String param = ""; for (String s : Parameters) &#123; param += s + "\n"; &#125; out.print(param.trim()); // 进行输出流的缓冲 out.flush(); // 通过BufferedReader输入流来读取Url的响应 in = new BufferedReader( new InputStreamReader(conn.getInputStream())); String line; while ( (line = in.readLine()) != null) &#123; result += line; &#125; &#125; catch (Exception e) &#123; System.out.println("发送post请求出现异常！" + e); e.printStackTrace(); &#125; finally &#123; try &#123; if (out != null) &#123; out.close(); &#125; if (in != null) &#123; in.close(); &#125; &#125; catch (IOException ex) &#123; ex.printStackTrace(); &#125; &#125; return result; &#125;&#125; 运行之后结果如下：1结果是&#123;"remain":499,"success":1&#125; remain表示还有多少可以推送，我这里表示还有499条。success表示成功推送了多少条链接，我这里表示成功推送了一条链接。 第二种是主动推送，可以按照百度的教程进行配置： 第三种就是配置站点地图了，按照之前将的将站点地图安装到项目中，参照我的配置即可：如果能像我这个一样状态正常，能获取到URL数量就表示成功了。 总结在整个过程中不是我黑百度，百度的效率真是太低了。我头一天在google提交上去第二天就能收到了，百度是我提交了大概一周多才给我收录进去，这当然肯定也和我的内容有关系。]]></content>
      <categories>
        <category>小技巧</category>
      </categories>
      <tags>
        <tag>baidu</tag>
        <tag>google</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java多线程（一）多线程基础]]></title>
    <url>%2F2016%2F05%2F14%2Fjava-thread1%2F</url>
    <content type="text"><![CDATA[前言本文主要讲解java多线程的基础，以及一些常用方法。关于线程同步、ExecutorService框架我会放到后续的文章进行讲解。 进程与线程的区别进程进程简单的来说就是在内存中运行的应用程序，一个进程可以启动多个线程。比如在windows中一个运行EXE文件就是一个进程。 线程同一个线程中的进程共用相同的地址空间，同时共享进程所拥有的内存和其他资源。 线程Demo-继承Thread类首先我们我们继承java.lang.Thread类来创建线程。12345678910111213141516171819202122232425262728293031package top.crosssoverjie.study.Thread;public class TestThread &#123; public static void main(String[] args) &#123; System.out.println("主线程ID是：" + Thread.currentThread().getId()); MyThread my = new MyThread("线程1"); my.start() ; MyThread my2 = new MyThread("线程2") ; /** * 这里直接调用my2的run()方法。 */ my2.run() ; &#125;&#125;class MyThread extends Thread &#123; private String name; public MyThread(String name) &#123; this.name = name; &#125; @Override public void run() &#123; System.out.println("名字：" + name + "的线程ID是=" + Thread.currentThread().getId()); &#125;&#125; 输出结果:123主线程ID是：1名字：线程2的线程ID是=1名字：线程1的线程ID是=9 由输出结果我们可以得出以下结论： my和my2的线程ID不相同，my2和主线程ID相同。说明直接调用run()方法不会创建新的线程，而是在主线程中直接调用的run()方法,和普通的方法调用没有区别。 虽然my的start()方法是在my2的run()方法之前调用，但是却是后输出内容，说明新建的线程并不会影响主线程的执行。 线程Demo-实现Runnable接口除了继承java.lang.Thread类之外，我们还可以实现java.lang.Runnable接口来创建线程。12345678910111213141516171819202122232425262728293031package top.crosssoverjie.study.Thread;public class TestRunnable &#123; public static void main(String[] args) &#123; System.out.println("主线程的线程ID是"+Thread.currentThread().getId()); MyThread2 my = new MyThread2("线程1") ; Thread t = new Thread(my) ; t.start() ; MyThread2 my2 = new MyThread2("线程2") ; Thread t2 = new Thread(my2) ; /** * 方法调用，并不会创建线程，依然是主线程 */ t2.run() ; &#125;&#125;class MyThread2 implements Runnable&#123; private String name ; public MyThread2(String name)&#123; this.name = name ; &#125; @Override public void run() &#123; System.out.println("线程"+name+"的线程ID是"+Thread.currentThread().getId()); &#125; &#125; 输出结果:123主线程的线程ID是1线程线程2的线程ID是1线程线程1的线程ID是9 notes: 实现Runnable的方式需要将实现Runnable接口的类作为参数传递给Thread，然后通过Thread类调用Start()方法来创建线程。 这两种方式都可以来创建线程，至于选择哪一种要看自己的需求。直接继承Thread类的话代码要简洁一些，但是由于java只支持单继承，所以如果要继承其他类的同时需要实现线程那就只能实现Runnable接口了，这里更推荐实现Runnable接口。 实际上如果我们查看Thread类的源码我们会发现Thread是实现了Runnable接口的： 线程中常用的方法 序号 方法 介绍 1 public void start() 使该线程执行，java虚拟机会调用该线程的run()方法。 2 public final void setName(String name) 修改线程名称。 3 public final void setPriority(int privority) 修改线程的优先级。 4 public final void setDaemon(false on) 将该线程标记为守护线程或用户线程，当正在运行线程都是守护线程时，java虚拟机退出，该方法必须在启动线程前调用。 5 public final void join(long mills) 等待该线程的终止时间最长为mills毫秒。 6 public void interrupt() 中断线程。 7 public static boolean isAlive() 测试线程是否处于活动状态。如果该线程已经启动尚未终止，则为活动状态。 8 public static void yield() 暂停当前线程执行的对象，并执行其他线程。 9 public static void sleep(long mills) 在指定毫秒数内，让当前执行的线程休眠(暂停)。 10 public static Thread currentThread() 返回当前线程的引用。 方法详解- public static void sleep(long mills)1234567891011121314151617181920212223242526272829303132333435package top.crosssoverjie.study.Thread;public class TestSleep &#123; private int i = 10 ; private Object ob = new Object() ; public static void main(String[] args) &#123; TestSleep t = new TestSleep() ; MyThread3 thread1 = t.new MyThread3() ; MyThread3 thread2 = t.new MyThread3() ; thread1.start() ; thread2.start() ; &#125; class MyThread3 extends Thread&#123; @Override public void run() &#123; synchronized (ob) &#123; i++ ; System.out.println("i的值："+i); System.out.println("线程："+Thread.currentThread().getName()+"进入休眠状态"); try &#123; Thread.currentThread().sleep(1000) ; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; System.out.println("线程："+Thread.currentThread().getName()+"休眠结束"); i++; System.out.println("i的值&gt;："+i); &#125; &#125; &#125; &#125; 输出结果：12345678i的值：11线程：Thread-0进入休眠状态线程：Thread-0休眠结束i的值&gt;：12i的值：13线程：Thread-1进入休眠状态线程：Thread-1休眠结束i的值&gt;：14 由输出结果我们可以得出： 当Thread0进入休眠状态时，Thread1并没有继续执行，而是等待Thread0休眠结束释放了对象锁，Thread1才继续执行。当调用sleep()方法时，必须捕获异常或者向上层抛出异常。当线程休眠时间满时，并不一定会马上执行，因为此时有可能CPU正在执行其他的任务，所以调用了sleep()方法相当于线程进入了阻塞状态。 方法详解- public static void yield()123456789101112131415161718192021package top.crosssoverjie.study.Thread;public class Testyield &#123; public static void main(String[] args) &#123; MyThread4 my = new MyThread4() ; my.start() ; &#125;&#125;class MyThread4 extends Thread&#123; @Override public void run() &#123; long open = System.currentTimeMillis(); int count= 0 ; for(int i=0 ;i&lt;1000000;i++)&#123; count= count+(i+1);// Thread.yield() ; &#125; long end = System.currentTimeMillis(); System.out.println("用时："+(end-open)+"毫秒"); &#125;&#125; 输出结果:用时：1毫秒如果将 Thread.yield()注释取消掉，输出结果:用时：116毫秒 调用yield()方法是为了让当前线程交出CPU权限，让CPU去执行其他线程。它和sleep()方法类似同样是不会释放锁。但是yield()不能控制具体的交出CUP的时间。并且它只能让相同优先级的线程获得CPU执行时间的机会。 调用yield()方法不会让线程进入阻塞状态，而是进入就绪状态，它只需要等待重新获取CPU的时间，这一点和sleep()方法是不一样的。 方法详解- public final void join()在很多情况下我们需要在子线程中执行大量的耗时任务，但是我们主线程又必须得等待子线程执行完毕之后才能结束，这就需要用到 join()方法了。join()方法的作用是等待线程对象销毁，如果子线程执行了这个方法，那么主线程就要等待子线程执行完毕之后才会销毁，请看下面这个例子：123456789101112131415161718192021222324252627package top.crosssoverjie.study.Thread;public class Testjoin &#123; public static void main(String[] args) throws InterruptedException &#123; new MyThread5("t1").start() ; for (int i = 0; i &lt; 10; i++) &#123; if(i == 5)&#123; MyThread5 my =new MyThread5("t2") ; my.start() ; my.join() ; &#125; System.out.println("main当前线程："+Thread.currentThread().getName()+" "+i); &#125; &#125;&#125;class MyThread5 extends Thread&#123; public MyThread5(String name)&#123; super(name) ; &#125; @Override public void run() &#123; for (int i = 0; i &lt; 5; i++) &#123; System.out.println("当前线程："+Thread.currentThread().getName()+" "+i); &#125; &#125;&#125; 输出结果：1234567891011121314151617181920main当前线程：main 0当前线程：t1 0当前线程：t1 1main当前线程：main 1当前线程：t1 2main当前线程：main 2当前线程：t1 3main当前线程：main 3当前线程：t1 4main当前线程：main 4当前线程：t2 0当前线程：t2 1当前线程：t2 2当前线程：t2 3当前线程：t2 4main当前线程：main 5main当前线程：main 6main当前线程：main 7main当前线程：main 8main当前线程：main 9 如果我们把join()方法注释掉之后：1234567891011121314151617181920main当前线程：main 0当前线程：t1 0main当前线程：main 1当前线程：t1 1main当前线程：main 2当前线程：t1 2main当前线程：main 3当前线程：t1 3main当前线程：main 4当前线程：t1 4main当前线程：main 5main当前线程：main 6main当前线程：main 7main当前线程：main 8main当前线程：main 9当前线程：t2 0当前线程：t2 1当前线程：t2 2当前线程：t2 3当前线程：t2 4 由上我们可以得出以下结论： 在使用了join()方法之后主线程会等待子线程结束之后才会结束。 方法详解- setDaemon(boolean on),getDaemon()用来设置是否为守护线程和判断是否为守护线程。notes： 守护线程依赖于创建他的线程，而用户线程则不需要。如果在main()方法中创建了一个守护线程，那么当main方法执行完毕之后守护线程也会关闭。而用户线程则不会，在JVM中垃圾收集器的线程就是守护线程。 优雅的终止线程有三种方法可以终止线程，如下： 使用退出标识，使线程正常的退出，也就是当run()方法完成后线程终止。 使用stop()方法强行关闭，这个方法现在已经被废弃，不推荐使用 使用interrupt()方法终止线程。 具体的实现代码我将在下一篇博文中将到。。 线程的优先级在操作系统中线程是分优先级的，优先级高的线程CPU将会提供更多的资源，在java中我们可以通过setPriority(int newPriority)方法来更改线程的优先级。在java中分为1~10这个十个优先级，设置不在这个范围内的优先级将会抛出IllegalArgumentException异常。java中有三个预设好的优先级： public final static int MIN_PRIORITY = 1; public final static int NORM_PRIORITY = 5; public final static int MAX_PRIORITY = 10; 参考 如何终止线程 java多线程学习 java多线程思维图 总结以上就是我总结的java多线程基础知识，后续会补充线程关闭、线程状态、线程同步和有返回结果的多线程。]]></content>
      <categories>
        <category>java多线程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>Runnable</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java笔记（一）Java的反射机制]]></title>
    <url>%2F2016%2F05%2F10%2Fjava-reflect%2F</url>
    <content type="text"><![CDATA[前言java反射机制指的是在java运行过程中，对于任意的类都可以知道他的所有属性以及方法，对于任意一个对象都可以任意的调用他的属性和方法，这种动态获取对象信息和动态调用对象方法的功能称为java反射机制，但是反射使用不当会造成很高的成本。 简单实例 反射获取类名称123456789101112131415161718package top.crosssoverjie.study;public class Reflect &#123; public static void main(String[] args) &#123; Class&lt;Reflect&gt; c1 = Reflect.class; System.out.println(c1.getName()); Reflect r1 = new Reflect() ; Class&lt;Reflect&gt; c2 = (Class&lt;Reflect&gt;) r1.getClass() ; System.out.println(c2.getName()); try &#123; Class&lt;Reflect&gt; c3 = (Class&lt;Reflect&gt;) Class.forName("top.crosssoverjie.study.Reflect"); System.out.println(c3.getName()); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 输出结果： 123top.crosssoverjie.study.Reflecttop.crosssoverjie.study.Reflecttop.crosssoverjie.study.Reflect 以上的 c1,c2,c3是完全一样的，他们都有一个统一的名称：叫做Reflect类的类类型。 反射的用处获取成员方法12public Method getDeclaredMethod(String name,Class&lt;?&gt;...parameterTypes)//得到该类的所有方法，但是不包括父类的方法。public Method getMethod(String name,Class&lt;?&gt;...parameterTypes)//获得该类的所有public方法，包括父类的。 通过反射获取成员方法调用的实例:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package top.crosssoverjie.study;import java.lang.reflect.Method;public class Person &#123; private String name="crossover" ; private String msg ; public Person(String name, String msg) &#123; this.name = name; this.msg = msg; System.out.println(name+"的描述是"+msg); &#125; public Person() &#123; super(); &#125; public void say(String name ,String msg)&#123; System.out.println(name+"说："+msg); &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getMsg() &#123; return msg; &#125; public void setMsg(String msg) &#123; this.msg = msg; &#125; public static void main(String[] args) &#123; try &#123; //首先获取类类型 Class c1 = Class.forName("top.crosssoverjie.study.Person") ; //通过newInstance()方法生成一个实例 Object o1 = c1.newInstance() ; //获取该类的say方法 Method m1 = c1.getMethod("say", String.class,String.class) ; //通过invoke方法调用该方法// m1.invoke(o1, "张三","你好啊") ; Method[] methods = c1.getDeclaredMethods() ;// for(Method m : methods)&#123;// System.out.println(m.getName());// &#125; Method[] methods2 = c1.getMethods() ; for (Method method : methods2) &#123; System.out.println(method.getName()); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 输出结果：1张三说：你好啊 所以我们只要知道类的全限定名就可以任意的调用里面的方法。 1234Method[] methods = c1.getDeclaredMethods() ;for(Method m : methods)&#123; System.out.println(m.getName());&#125; 输出结果：123456maingetNamesetNamesaygetMsgsetMsg 使用的还是之前那个Person类，所以这里只写了关键代码。这里输出的是Person的所有public方法。 如果我们调用getMethods()方法会是什么结果呢？1234Method[] methods2 = c1.getMethods() ;for (Method method : methods2) &#123; System.out.println(method.getName());&#125; 输出结果:123456789101112131415maingetNamesetNamesaygetMsgsetMsgwaitwaitwaithashCodegetClassequalstoStringnotifynotifyAll 这时我们会发现这里输出的结果会比刚才多得多，这时因为getMethods()方法返回的是包括父类的所有方法。 获取成员变量我们还可以通过反射来获取类包括父类的成员变量，主要方法如下：12public Field getDeclaredFiled(String name)//获得该类所有的成员变量，但不包括父类的。public Filed getFiled(String name)//获得该类的所有的public变量，包括其父类的。 还是按照之前例子中的Person类举例，他具有两个成员变量：12private String name="crossover" ;private String msg ; 我们可以通过以下方法来获取其中的成员变量：12Class c1 = Class.forName("top.crosssoverjie.study.Person") ;Field field = c1.getDeclaredField("name");//获取该类所有的成员属性 通过以下例子可以获取指定对象上此field的值：123456789101112131415161718192021222324252627282930313233343536package top.crosssoverjie.study;import java.io.File;import java.lang.reflect.Field;public class Reflect &#123; public static void main(String[] args) &#123; try &#123; Class c1 = Class.forName("top.crosssoverjie.study.Person"); Field field = c1.getDeclaredField("name") ; Object o1 = c1.newInstance() ; /** * 由于Person类中的name变量是private修饰的， * 所以需要手动开启允许访问，是public修饰的就不需要设置了 */ field.setAccessible(true); Object name = field.get(o1) ; System.out.println(name); &#125; catch (Exception e) &#123; e.printStackTrace() ; &#125;// Class&lt;Reflect&gt; c1 = Reflect.class;// System.out.println(c1.getName());// // Reflect r1 = new Reflect() ;// Class&lt;Reflect&gt; c2 = (Class&lt;Reflect&gt;) r1.getClass() ;// System.out.println(c2.getName());// // try &#123;// Class&lt;Reflect&gt; c3 = (Class&lt;Reflect&gt;) Class.forName("top.crosssoverjie.study.Reflect");// System.out.println(c3.getName());// &#125; catch (ClassNotFoundException e) &#123;// e.printStackTrace();// &#125; &#125;&#125; 输出结果：1crossover 我们也可以通过方法getDeclaredFieds()方法来获取所有的成员变量，返回是是一个Field[]数组，只需要遍历这个数组即可获所有的成员变量。例子如下： 1234Field[] fields = c1.getDeclaredFields() ;for(Field f :fields)&#123; System.out.println(f.getName());&#125; 输出结果如下：12namemsg 获取构造方法可以通过以下两个方法来获取构造方法：12public Constructor getDeclaredConstructor(Class&lt;?&gt;...parameterTypes)//获取该类的所有构造方法，不包括父类的。public Constructor getConstructor(Class&lt;?&gt;...parameterTypes)//获取该类的所有public修饰的构造方法，包括父类的。 在之前的Person类中有以下的构造方法：1234public Person(String name, String msg) &#123; this.name = name; this.msg = msg;&#125; 我们可以通过以下方法来获取Person类的构造方法：1Constructor dc1 = c1.getDeclaredConstructor(String.class,String.class) ; 具体代码如下：123Constructor dc1 = c1.getDeclaredConstructor(String.class,String.class) ;dc1.setAccessible(true);dc1.newInstance("小明","很帅") ; dc1.newInstance(&quot;小明&quot;,&quot;很帅&quot;);方法调用了Person类中的：12345public Person(String name, String msg) &#123; this.name = name; this.msg = msg; System.out.println(name+"的描述是"+msg);&#125; 这个构造方法，如果不传参数的话，那么调用的就是无参的构造方法。输出结果为:1小明的描述是很帅 通过反射了解集合泛型的本质通过以下例子程序可以看出：1234567891011121314151617181920212223242526272829303132333435363738394041package top.crosssoverjie.study;import java.lang.reflect.Method;import java.util.ArrayList;import java.util.List;public class GenericEssence &#123; public static void main(String[] args) &#123; //声明两个list，一个有泛型，一个没有泛型 List list1 = new ArrayList() ; List&lt;String&gt; list2 = new ArrayList&lt;String&gt;() ; list2.add("你好") ;// list2.add(11) ;加上泛型之后在编译期间只能添加String，不然会报错。 System.out.println("list2的长度是："+list2.size()); Class c1 = list1.getClass(); Class c2 = list2.getClass() ; System.out.print("c1,c2是否相等:"); System.out.println(c1==c2); try &#123; //通过反射绕过编译器动态调用add方法，可能否加入非String类型的元素 Method method = c2.getDeclaredMethod("add", Object.class) ; method.invoke(list2, 123) ;//在这里加入int类型，在上面如果加入int会出现编译报错。 //list2的长度增加了，说明添加成功了 System.out.println("现在list2的长度是:"+list2.size()); /** * 所以可以看出，泛型只是在编译期间起作用，在经过编译进入运行期间是不起作用的。 * 就算是不是泛型要求的类型也是可以插入的。 */ &#125; catch (Exception e) &#123; e.printStackTrace() ; &#125; &#125;&#125; 所以可以看出，泛型只是在编译期间起作用，在经过编译进入运行期间是不起作用的。就算是不是泛型要求的类型也是可以插入的。 反射知识点 总结 泛型的应用比较多： spring的IOC/DI。 JDBC中的中的加载驱动 参考 java中的反射机制 反射机制是什么]]></content>
      <categories>
        <category>Java笔记</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Reflect</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第一次总结]]></title>
    <url>%2F2016%2F05%2F07%2F%E7%AC%AC%E4%B8%80%E6%AC%A1%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[前言 昨天到今天一共花了差不多两天的时间终于把博客搭好了。还买了一个域名，现在就迫不及待的想把这段内容写下来。 感谢 首先非常感谢 嘟爷的帮忙，没有这些资料我可能还得自己研究好一段时间。 过程 我是前天无意间在微博上看到嘟爷的一篇博文，就仔细看了下，发现写的非常好，然后就将他所有的博文大致的浏览了一下。 我很早以前就打算搭一个博客，但是百度了一下发现还是挺麻烦的，加上最近也比较忙所有一直也就没有做，直到看到这篇博文才顺利的搭起了这个博客。中途遇到不少问题也都顺利解决了，真是学到了不少的东西。 熟练了Markdown语法。 真正使用了编辑神器 Sublime。 使用阿里云解析了github和coding里的Pages服务。 hexo和常用的主题配置。 我的配置 Hexo配置 JackMan配置imglogo: enable: true ## display image logo true/false. src: img/logo.gif ## `.svg` and `.png` are recommended,please put image into the theme folder `/jacman/source/img`. favicon: img/favicon.ico ## size:32px*32px,`.ico` is recommended,please put image into the theme folder `/jacman/source/img`. apple_icon: img/jacman.jpg ## size:114px*114px,please put image into the theme folder `/jacman/source/img`. author_img: img/author.jpg ## size:220px*220px.display author avatar picture.if don&apos;t want to display,please don&apos;t set this. banner_img: #img/banner.jpg ## size:1920px*200px+. Banner Picture ### Theme Color theme_color: theme: &apos;#2ca6cb&apos; ##the defaut theme color is blue # 代码高亮主题 # available: default | night highlight_theme: night #### index post is expanding or not index: expand: false ## default is unexpanding,so you can only see the short description of each post. excerpt_link: Read More close_aside: false #close sidebar in post page if true mathjax: false #enable mathjax if true ### Creative Commons License Support, see http://creativecommons.org/ ### you can choose: by , by-nc , by-nc-nd , by-nc-sa , by-nd , by-sa , zero creative_commons: none 结束语以上。。我做这个博客的初衷一是为了记录我的整个程序猿生涯的故事，二是希望能有大神能在过程中指出我的错误，能让我的水平更进一步。]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown小计]]></title>
    <url>%2F2016%2F05%2F06%2FMarkdown%E5%B0%8F%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[# 标题 表示标题 一个#号代表一级标题，以此类推。 * 无序列表 无序列表 &gt; 引用 引用 [http://www.baidu.com](http://www.baidu.com &quot;百度&quot;) 百度 ![艾弗森](http://i.imgur.com/TLnZ2S6.jpg)插入图片]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux（一）常用命令]]></title>
    <url>%2F2016%2F04%2F10%2FLinux-normal%2F</url>
    <content type="text"><![CDATA[前言 由于现在JAVA开发的很多应用都是部署到Linux系统上的，因此了解和掌握一些Linux的常用命令是非常有必要的，以下就是在Java开发过程中一些常用的命令。 常用命令 查找文件find / -name log.txt根据名称查找在 /目录下的 log.txt文件。 find .-name &quot;*.xml&quot;递归查找所有的xml文件。 find .-name &quot;*.xml&quot;|xargs grep &quot;hello&quot;递归查找所有包含hello的xml文件。 ls -l grep &#39;jar&#39;查找当前目录中的所有jar文件。 检查一个文件是否运行ps –ef|grep tomecate检查所有有关tomcat的进程。 终止线程kill -9 19979终止线程号为19979的线程 查看文件，包括隐藏文件。ls -al 查看当前工作目录。pwd 复制文件包括其子文件到指定目录cp -r source target复制source文件到target目录中。 创建一个目录mkdir new创建一个new的目录 删除目录(前提是此目录是空目录)rmdir source删除source目录。 删除文件 包括其子文件rm -rf file删除file文件和其中的子文件。-r表示向下递归，不管有多少目录一律删除-f表示强制删除，不做任何提示。 移动文件mv /temp/movefile /target 切换用户su -username 查看ipifconfig注意是 ifconfig 不是windows中的ipconfig 总结以上就是在Linux下开发Java应用常用的Linux命令，如有遗漏请在评论处补充，我将不定期添加。]]></content>
      <categories>
        <category>Linux笔记</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[个人简历]]></title>
    <url>%2F1994%2F08%2F08%2Fmyresume%2F</url>
    <content type="text"><![CDATA[个人信息 陈杰/男/1994 工作年限：3年 技术博客：https://crossoverjie.top Github：http://github.com/crossoverjie 期望职位：Java 高级工程师 联系方式 手机：18523985794 Email：crossoverJie@gmail.com QQ/微信号：731756881 / chycjj 工作经历亚信科技 （ 2017年05月 ~ 至今 ）IOP 智能营销平台项目描述：根据用户DNA数据、当前位置等信息合理的推送相应的营销活动给用户。主要负责： 短信群发渠道的整个流程。 短信网关:保证 1000W+ 的用户数据安全有效的通过短信网关进行短信下发。 51 营业厅项目描述: 基于云端的进销存系统。主要负责： 支付模块。 财务模块。 线上地址 : https://www.51yyt.com.cn/ 其他项目请求防重组件项目描述 : 对于某些业务要求每次请求保证唯一，如果每个接口都做校验操作的话耦合太高也不利于维护。基于此自定义了 annotation ,通过 Spring 的 AOP 只要给相应的接口加上该注解即可实现请求去重。 开源地址: Spring 版: https://github.com/crossoverJie/SSM-REQUEST-CHECK SpringBoot 版: https://github.com/crossoverJie/springboot-cloud 猪八戒网络有限公司 （ 2016年05月 ~ 2017年05月 ）八戒认证项目描述：为整个猪八戒网提供实名认证服务，主推人脸识别认证。期望打造成一个权威的第三方实名认证平台。分为以下几个模块： Web端人脸识别认证。 移动端人脸识别认证(IOS,Android)。 国内境外企业审核认证。 国内港澳台个人审核认证。 主要负责： 八戒认证核心服务开发。 新老系统数据迁移。 整个主站所依赖的实名查询接口。 线上地址 : https://do.renzheng.zbj.com/fe/page/index 其他项目Dubbo 接口 实现 HTTP 访问组件项目描述 : 由于 Dubbo 接口通常是内部应用之间进行调用，当我们想要排除掉语言的特有性的话最好还是提供一个 HTTP 接口。基于此开发了一个组件可以在不修改原有 Dubbo 接口的前提下实现 HTTP 访问，这在某些特有环境下进行调试是非常方便的。 开源地址 : https://github.com/crossoverJie/SSM-DUBBO-HTTP 重庆驰骅科技 （ 2014年11月 ~ 2016年05月 ）长安马自达内部审计系统 项目描述：该项目为长安马自达财务部门内部使用的一个审计系统，用于升级整个长马公司的风险和管理工作。主要负责： 编写项目过程中的各个里程碑文档。 系统数据库设计。 制定并分配开发任务。 资源共享、系统指南、系统管理、风险管理模块代码的实现。 长安汽车设计成本管控系统项目描述：该项目为重庆长安公司使用成本管控系统，对整个汽车生产所产生的成本进行预估与管理 主要负责： 零部件参数准确率、及时率的开发。 开源项目和作品开源项目 SSM：从 0 构建一套分布式系统。(1.2K star) springboot-cloud：基于 SpringBoot + SpringCloud 搭建的微服务项目 技术文章 基于dubbo的分布式架构 MQ应用 译 你可以用GitHub做的12件 Cool 事情 技能清单以下均为我熟练使用的技能 主力语言：Java 框架：Spring/SpringMVC/Mybatis/SpringBoot/SpringCloud/Dubbo 中间件：Kafka/Zookeeper/配置中心/调度中心 数据库相关：MySQL/Oracle 版本管理、文档和自动化部署工具：Svn/Git/Jenkins 单元测试：Junit/Jacoco/coveralls 服务器 : Linux常用操作，基本的 Shell 脚本编写 致谢感谢您花时间阅读我的简历，期待能有机会和您共事。]]></content>
      <categories>
        <category>resume</category>
      </categories>
      <tags>
        <tag>总结</tag>
      </tags>
  </entry>
</search>
